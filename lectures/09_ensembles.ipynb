{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CPSC 330 Lecture 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Lecture plan\n",
    "\n",
    "- ðŸ‘‹\n",
    "- **Turn on recording**\n",
    "- Announcements (5 min)\n",
    "- Evaluation metrics True/False (10 min)\n",
    "- Introducing some other classifiers (20 min)\n",
    "- Break (5 mins)\n",
    "- Ensembles: averaging (20 min)\n",
    "- Ensembles: stacking (20 min)\n",
    "- Summary\n",
    "\n",
    "Piazza:\n",
    "\n",
    "- Ensembles True/False questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements\n",
    "\n",
    "- hw schedule for the rest of the course posted at https://github.com/UBC-CS/cpsc330#homework-schedule\n",
    "- hw4 posted, due Monday 11:59pm\n",
    "- Evaluation metrics true/false: https://piazza.com/class/kb2e6nwu3uj23?cid=283\n",
    "- Midterm format poll: https://piazza.com/class/kb2e6nwu3uj23?cid=281"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "- todo\n",
    "- todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing some other classifiers (20 min)\n",
    "\n",
    "- SVM?\n",
    "- Random forest\n",
    "- XGB, Catboost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cc_df = pd.read_csv('data/creditcard.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today I will use a smaller data set for speed of the demos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = cc_df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(cc_df, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21360, 31)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['Class'])\n",
    "y_train = df_train['Class']\n",
    "\n",
    "X_test = df_test.drop(columns=['Class'])\n",
    "y_test = df_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.192492\n",
       "score_time     0.004964\n",
       "test_score     0.217096\n",
       "train_score    0.257120\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results = pd.DataFrame(cross_validate(pipe_lr, X_train, y_train, scoring='f1', return_train_score=True)).mean()\n",
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(class_weight='balanced') # scaling not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.110423\n",
       "score_time     0.004105\n",
       "test_score     0.614384\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results = pd.DataFrame(cross_validate(dt, X_train, y_train, scoring='f1', return_train_score=True)).mean()\n",
    "dt_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about some other classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is basically the average of a bunch of random decision trees. \n",
    "- We'll talk about averaging later today!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced') # scaling not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       1.685511\n",
       "score_time     0.034135\n",
       "test_score     0.769991\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results = pd.DataFrame(cross_validate(rf, X_train, y_train, scoring='f1', return_train_score=True)).mean()\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, this gets a way better cross-validation F1 score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>1.685511</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>0.769991</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.110423</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.614384</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.192492</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.217096</td>\n",
       "      <td>0.25712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fit_time  score_time  test_score  train_score\n",
       "random forest        1.685511    0.034135    0.769991      1.00000\n",
       "decision tree        0.110423    0.004105    0.614384      1.00000\n",
       "logistic regression  0.192492    0.004964    0.217096      0.25712"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame([lr_results, dt_results, rf_results], index=[\"logistic regression\", \"decision tree\", \"random forest\"])\n",
    "summary.sort_values(by=[\"test_score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier # todo: figure out class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb_results = pd.DataFrame(cross_validate(xgb, X_train, y_train, scoring='f1', return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.303369\n",
       "score_time     0.015645\n",
       "test_score     0.403891\n",
       "train_score    0.606864\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm_results = pd.DataFrame(cross_validate(lgbm, X_train, y_train, scoring='f1', return_train_score=True)).mean()\n",
    "lgbm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- show the error with class_Weight, compute sample weights manually\n",
    "- or, think more if this is what we really want. we kind of want max precision at a given recall. but we can't do that really, can we? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a loop for all these classifiers, put results in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- this is a great place to add in more classifiers like random forest and SVM, since then we can talk about ensembling them!\n",
    "- it'll be good to show a classifier with multiple meaningful hypers (rf)\n",
    "- and also mention it has predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "visualize random forests with graphviz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "change `StackingRegressor` to `StackingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "models = {'decision tree'      : DecisionTreeClassifier(),\n",
    "          'logistic regression': LogisticRegression(max_iter=300),\n",
    "          'RBF SVM'            : SVC(max_iter=1500), \n",
    "          'random forest'      : RandomForestClassifier(), \n",
    "         }\n",
    "avg_scores = dict()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    scores = cross_validate(model, X_train_scale_ohe, y_train, cv=5, return_train_score=True)\n",
    "    avg_scores[model_name] = pd.DataFrame(scores).drop(columns=['score_time']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(avg_scores).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss these results:\n",
    "\n",
    "- Which methods are overfitting?\n",
    "- Which methods are underfitting?\n",
    "- Which methods are fast/slow?\n",
    "- What is the best method so far?\n",
    "- What hyperparameters should we tune?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'decision tree'      : DecisionTreeClassifier(),\n",
    "          'logistic regression orig': LogisticRegression(max_iter=300),\n",
    "          'logistic regression': LogisticRegression(max_iter=300, C=100),\n",
    "          'random forest orig'      : RandomForestClassifier(), \n",
    "          'random forest simpler'   : RandomForestClassifier(n_estimators=10)\n",
    "         }\n",
    "avg_scores = dict()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    scores = cross_validate(model, X_train_scale_ohe, y_train, cv=5, return_train_score=True)\n",
    "    avg_scores[model_name] = pd.DataFrame(scores).drop(columns=['score_time']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(avg_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              \"n_estimators\"     : [10,100],\n",
    "              \"max_depth\"        : [3, None],\n",
    "              \"max_features\"     : [3, None]\n",
    "             }\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many combinations in total? \n",
    "- $2\\times 2\\times 2=8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.prod(list(map(len, param_grid.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=321)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_transformed, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'param_max_depth', 'param_max_features', 'param_n_estimators', 'mean_fit_time', 'rank_test_score']].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break (5 min)\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: averaging (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time we trained a linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Ridge(alpha=100)\n",
    "lr.fit(X_train_imp_encode, y_train_log);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAPE: 8.72%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training MAPE: %.2f%%\" % mape(y_train, np.exp(lr.predict(X_train_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE: 9.21%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation MAPE: %.2f%%\" % mape(y_valid, np.exp(lr.predict(X_valid_imp_encode))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also tried a random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=123)\n",
    "rf.fit(X_train_imp_encode, y_train_log);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAPE: 3.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training MAPE: %.2f%%\" % mape(y_train, np.exp(rf.predict(X_train_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE: 9.62%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation MAPE: %.2f%%\" % mape(y_valid, np.exp(rf.predict(X_valid_imp_encode))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can try an SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVR()\n",
    "svm.fit(X_train_imp_encode, y_train_log);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAPE: 6.68%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training MAPE: %.2f%%\" % mape(y_train, np.exp(svm.predict(X_train_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE: 8.78%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation MAPE: %.2f%%\" % mape(y_valid, np.exp(svm.predict(X_valid_imp_encode))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: can we combine these models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('ridge', Ridge(alpha=100)),\n",
    "              ('random forest', RandomForestRegressor(random_state=123)),\n",
    "              ('SVM regressor', SVR())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model = VotingRegressor(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `VotingRegressor` will predict the _average_ of its constituent classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model.fit(X_train_imp_encode, y_train_log);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it seems sklearn requires us to actually call `fit` on the `VotingRegressor`, instead of passing in pre-fit models. This is an implementation choice rather than a conceptual limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.228460339812964"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaging_model.predict(X_valid_imp_encode)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.224610958721197"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pred = averaging_model.named_estimators_['ridge'].predict(X_valid_imp_encode)[5]\n",
    "ridge_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.264407940093813"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred = averaging_model.named_estimators_['random forest'].predict(X_valid_imp_encode)[5]\n",
    "rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.196362120623878"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pred = averaging_model.named_estimators_['SVM regressor'].predict(X_valid_imp_encode)[5]\n",
    "svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.228460339812964"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ridge_pred + rf_pred + svm_pred) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above: so, indeed the overall prediction is the average of the 3 predictions.\n",
    "- Below: let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAPE: 5.84%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training MAPE: %.2f%%\" % mape(y_train, np.exp(averaging_model.predict(X_train_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE: 8.41%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation MAPE: %.2f%%\" % mape(y_valid, np.exp(averaging_model.predict(X_valid_imp_encode))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What we did here was _model averaging_. \n",
    "- This is one (very popular) time of ensembling models.\n",
    "- Question: how could the average do better than the best model???\n",
    "  - From the perspective of the best estimator (in this case linear regression), why are you adding on worse estimators??\n",
    "- This is a bit easier to see with classification.\n",
    "- For classification we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `VotingClassifier` takes the majority vote from its constituent classifiers.\n",
    "- Here's how this can work:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Example | LR    | RF     | SVM    | Averaged model |\n",
    "|--------|--------|--------|---------|---------------|\n",
    "|  1     | âœ…    |   âœ…    | âŒ     | âœ…âœ…âŒ=>âœ…  |\n",
    "|  2     | âœ…    |   âŒ    | âœ…     | âœ…âŒâœ…=>âœ…  |\n",
    "|  3     | âŒ    |   âœ…    | âœ…     | âŒâœ…âœ…=>âœ…  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In short, as long as the different models make different mistakes, this can work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is amazing, why not always do this?\n",
    "\n",
    "1. `fit`/`predict` time.\n",
    "2. Reduction in interpretability.\n",
    "3. Reduction in code maintainability (e.g. Netflix prize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to ensembling: when can I do this?\n",
    "\n",
    "- You can comebine completely different estimators, or similar estimators.\n",
    "  - (In fact, a random forest itself is an ensemble of decision trees.)\n",
    "- But you can also try different hyperparameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('ridge', Ridge(alpha=100)),\n",
    "              ('rf 10', RandomForestRegressor(n_estimators=10)),\n",
    "              ('rf 100', RandomForestRegressor(n_estimators=100)),\n",
    "              ('SVM rbf',  SVR(kernel='rbf')),\n",
    "              ('SVM poly', SVR(kernel='poly'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model = VotingRegressor(estimators)\n",
    "averaging_model.fit(X_train_imp_encode, y_train_log);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAPE: 5.28%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training MAPE: %.2f%%\" % mape(y_train, np.exp(averaging_model.predict(X_train_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE: 8.49%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation MAPE: %.2f%%\" % mape(y_valid, np.exp(averaging_model.predict(X_valid_imp_encode))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: stacking (20 min)\n",
    "\n",
    "- Another type of ensemble is stacking.\n",
    "- Instead of averaging the outputs of each estimator, instead use them as inputs to another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {'ridge' : Ridge(alpha=100),\n",
    "              'rf 10' : RandomForestRegressor(n_estimators=10),\n",
    "              'rf 100' : RandomForestRegressor(n_estimators=100),\n",
    "              'SVM rbf' :  SVR(kernel='rbf'),\n",
    "              'SVM poly' : SVR(kernel='poly')\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingRegressor(estimators.items())\n",
    "stacking_model.fit(X_train_imp_encode, y_train_log);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the input features (X) to the meta-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge</th>\n",
       "      <th>rf 10</th>\n",
       "      <th>rf 100</th>\n",
       "      <th>SVM rbf</th>\n",
       "      <th>SVM poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.068502</td>\n",
       "      <td>12.070372</td>\n",
       "      <td>12.073288</td>\n",
       "      <td>12.087978</td>\n",
       "      <td>12.071595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.947864</td>\n",
       "      <td>12.963994</td>\n",
       "      <td>12.973918</td>\n",
       "      <td>12.998336</td>\n",
       "      <td>12.988760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.327807</td>\n",
       "      <td>12.346029</td>\n",
       "      <td>12.356182</td>\n",
       "      <td>12.320548</td>\n",
       "      <td>12.326201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.081258</td>\n",
       "      <td>12.002698</td>\n",
       "      <td>11.987009</td>\n",
       "      <td>12.098965</td>\n",
       "      <td>12.088716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.795430</td>\n",
       "      <td>11.778579</td>\n",
       "      <td>11.817743</td>\n",
       "      <td>11.830349</td>\n",
       "      <td>11.828437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ridge      rf 10     rf 100    SVM rbf   SVM poly\n",
       "0  12.068502  12.070372  12.073288  12.087978  12.071595\n",
       "1  12.947864  12.963994  12.973918  12.998336  12.988760\n",
       "2  12.327807  12.346029  12.356182  12.320548  12.326201\n",
       "3  12.081258  12.002698  11.987009  12.098965  12.088716\n",
       "4  11.795430  11.778579  11.817743  11.830349  11.828437"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.concatenate([estimator.predict(X_train_imp_encode)[:,None] for estimator in stacking_model.estimators_], axis=1)\n",
    "pd.DataFrame(preds, columns=list(estimators.keys())).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column contains the predictions from one of the original estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the meta-model is linear regression (which it is by default), you are taking a _weighted_ average and learning the weights from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAPE: 5.26%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training MAPE: %.2f%%\" % mape(y_train, np.exp(stacking_model.predict(X_train_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE: 8.37%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation MAPE: %.2f%%\" % mape(y_valid, np.exp(stacking_model.predict(X_valid_imp_encode))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the meta-estimator is a linear regression (ridge), so we can look at the coefficients. \n",
    "  - (To be precise, the default uses `RidgeCV`, which automatically tunes `alpha` using cross-validation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12302678, 0.17246328, 0.19786762, 0.39538227, 0.13589923])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It seems that the RBF SVM is \"counting for more\".\n",
    "- We can also try a different final estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model_tree = StackingRegressor(estimators.items(), \n",
    "                                        final_estimator=DecisionTreeRegressor(max_depth=3))\n",
    "stacking_model_tree.fit(X_train_imp_encode, y_train_log);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAPE: 9.41%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training MAPE: %.2f%%\" % mape(y_train, np.exp(stacking_model_tree.predict(X_train_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE: 10.90%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation MAPE: %.2f%%\" % mape(y_valid, np.exp(stacking_model_tree.predict(X_valid_imp_encode))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are pretty terrible. But at least we can look at the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"934pt\" height=\"313pt\"\n",
       " viewBox=\"0.00 0.00 934.00 313.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 309)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-309 930,-309 930,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"508,-305 380,-305 380,-252 508,-252 508,-305\"/>\n",
       "<text text-anchor=\"middle\" x=\"444\" y=\"-289.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">SVM rbf &lt;= 12.073</text>\n",
       "<text text-anchor=\"middle\" x=\"444\" y=\"-274.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1051</text>\n",
       "<text text-anchor=\"middle\" x=\"444\" y=\"-259.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.015</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"424,-216 324,-216 324,-163 424,-163 424,-216\"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ridge &lt;= 11.59</text>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 600</text>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-170.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 11.756</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M422.9977,-251.7971C416.1453,-243.0847 408.4358,-233.2826 401.1958,-224.0775\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"403.9207,-221.8805 394.9875,-216.1841 398.4186,-226.208 403.9207,-221.8805\"/>\n",
       "<text text-anchor=\"middle\" x=\"392.0212\" y=\"-237.3075\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"616,-216 488,-216 488,-163 616,-163 616,-216\"/>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">SVM rbf &lt;= 12.426</text>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 451</text>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-170.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.361</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M476.4036,-251.7971C487.5098,-242.6447 500.0753,-232.2898 511.7275,-222.6875\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"514.1279,-225.2447 519.6193,-216.1841 509.6762,-219.8427 514.1279,-225.2447\"/>\n",
       "<text text-anchor=\"middle\" x=\"517.2193\" y=\"-237.3686\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"218,-127 118,-127 118,-74 218,-74 218,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ridge &lt;= 11.31</text>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 119</text>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-81.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 11.388</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M323.8701,-167.842C294.8371,-155.2985 258.1148,-139.4331 227.6075,-126.2528\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.9227,-123.0083 218.3547,-122.2552 226.1464,-129.4343 228.9227,-123.0083\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"442.5,-127 305.5,-127 305.5,-74 442.5,-74 442.5,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">SVM poly &lt;= 11.847</text>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 481</text>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-81.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 11.846</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M374,-162.7971C374,-154.7887 374,-145.8597 374,-137.3198\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"377.5001,-137.1841 374,-127.1841 370.5001,-137.1841 377.5001,-137.1841\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"100,-38 0,-38 0,0 100,0 100,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 18</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 10.968</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M129.3624,-73.8139C115.4469,-64.2027 99.8089,-53.4019 86.1167,-43.945\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.0929,-41.0563 77.8756,-38.2531 84.1147,-46.816 88.0929,-41.0563\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"218,-38 118,-38 118,0 218,0 218,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 101</text>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 11.463</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M168,-73.8139C168,-65.6535 168,-56.6354 168,-48.3105\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.5001,-48.253 168,-38.2531 164.5001,-48.2531 171.5001,-48.253\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"336,-38 236,-38 236,0 336,0 336,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 256</text>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 11.742</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M345.1855,-73.8139C335.2974,-64.6561 324.243,-54.4182 314.3889,-45.292\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"316.5037,-42.4801 306.7886,-38.2531 311.7472,-47.6159 316.5037,-42.4801\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"454,-38 354,-38 354,0 454,0 454,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"404\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 225</text>\n",
       "<text text-anchor=\"middle\" x=\"404\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 11.966</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M383.8231,-73.8139C386.8937,-65.4721 390.2942,-56.2342 393.4148,-47.7566\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"396.7431,-48.8465 396.913,-38.2531 390.174,-46.4284 396.7431,-48.8465\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"605.5,-127 498.5,-127 498.5,-74 605.5,-74 605.5,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ridge &lt;= 12.276</text>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 314</text>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-81.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.224</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M552,-162.7971C552,-154.7887 552,-145.8597 552,-137.3198\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"555.5001,-137.1841 552,-127.1841 548.5001,-137.1841 555.5001,-137.1841\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"826.5,-127 689.5,-127 689.5,-74 826.5,-74 826.5,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"758\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">SVM poly &lt;= 12.775</text>\n",
       "<text text-anchor=\"middle\" x=\"758\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 137</text>\n",
       "<text text-anchor=\"middle\" x=\"758\" y=\"-81.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.675</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M613.5278,-162.9176C636.6584,-152.9243 663.139,-141.4837 687.0577,-131.1498\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"688.6418,-134.2782 696.4336,-127.0991 685.8655,-127.8523 688.6418,-134.2782\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"572,-38 472,-38 472,0 572,0 572,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 211</text>\n",
       "<text text-anchor=\"middle\" x=\"522\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.155</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M542.1769,-73.8139C539.1063,-65.4721 535.7058,-56.2342 532.5852,-47.7566\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"535.826,-46.4284 529.087,-38.2531 529.2569,-48.8465 535.826,-46.4284\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"690,-38 590,-38 590,0 690,0 690,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"640\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 103</text>\n",
       "<text text-anchor=\"middle\" x=\"640\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.366</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M580.8145,-73.8139C590.7026,-64.6561 601.757,-54.4182 611.6111,-45.292\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"614.2528,-47.6159 619.2114,-38.2531 609.4963,-42.4801 614.2528,-47.6159\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"808,-38 708,-38 708,0 808,0 808,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"758\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 101</text>\n",
       "<text text-anchor=\"middle\" x=\"758\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.579</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M758,-73.8139C758,-65.6535 758,-56.6354 758,-48.3105\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"761.5001,-48.253 758,-38.2531 754.5001,-48.2531 761.5001,-48.253\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"926,-38 826,-38 826,0 926,0 926,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"876\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 36</text>\n",
       "<text text-anchor=\"middle\" x=\"876\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.945</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M796.6376,-73.8139C810.5531,-64.2027 826.1911,-53.4019 839.8833,-43.945\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"841.8853,-46.816 848.1244,-38.2531 837.9071,-41.0563 841.8853,-46.816\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a10f77d10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(export_graphviz(stacking_model_tree.final_estimator_,\n",
    "                                out_file=None,\n",
    "                                feature_names=list(estimators.keys()),\n",
    "                                impurity=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out our results on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAPE: 9.31%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test MAPE: %.2f%%\" % mape(y_test, np.exp(lr.predict(X_test_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAPE: 8.52%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test MAPE: %.2f%%\" % mape(y_test, np.exp(averaging_model.predict(X_test_imp_encode))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAPE: 8.65%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test MAPE: %.2f%%\" % mape(y_test, np.exp(stacking_model.predict(X_test_imp_encode))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- From H2O AutoML talk: use Random Search, then Stack all the models. Apparently works super well as a general rule of thumb.\n",
    "- For random forests, can visualize the sub-trees with graphviz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "- a\n",
    "- b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## True/False questions (Piazza)\n",
    "\n",
    "1. I can decide to average different models even _after_ I (or someone else) have already trained them.\n",
    "2. Let estimators A, B, and C have scores of 90%, 70%, and 70%, respectively. Then, the maximum score of an ensemble is 90%. \n",
    "3. Let estimators A, B, and C have scores of 70%, 70%, and 70%, respectively. Then, the minimum score of an ensemble is 70%.\n",
    "4. Ensembling often increase your score but they also increase the time spent fitting and predicting.\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
