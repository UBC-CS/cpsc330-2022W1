{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 Lecture 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "\n",
    "- Announcements\n",
    "- Gradient boosted trees, `Catboost` (15 min)\n",
    "- Model comparison (15 min)\n",
    "- Break (5 min)\n",
    "- Big data sets: `SGDClassifier` and `SGDRegressor` (10 min)\n",
    "- Combining multiple tables (10 min)\n",
    "- True/False questions (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder to self: **turn on recording!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These next 3 cells could just be replaced with `import load_process_data`.\n",
    "- But this way I can make changes to that file and not need to restart my kernel each time.\n",
    "- So it's convenient for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport load_process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_classifier import plot_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "\n",
    "- this year we already introduced these in lecture 9\n",
    "- but we still shoud talk about how CatBoost handles categoricals? And some other details below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores_factory(X_train, y_train, X_test, y_test):\n",
    "    def show_scores(model, **fit_kwargs):\n",
    "        model.fit(X_train, y_train, **fit_kwargs);\n",
    "        return model.score(X_test, y_test)\n",
    "    return show_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements\n",
    "\n",
    "Same as last class:\n",
    "\n",
    "- hw7 has been posted, due Sunday evening.\n",
    "  - I tried to make it shorter than previous assignments.\n",
    "- Tutorials are still happening as scheduled, on Collaborate Ultra.\n",
    "- Change to course grading scheme per Dean's directive; see [here](https://piazza.com/class/k1gx4b3djbv3ph?cid=319)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's class:\n",
    "\n",
    "- A bunch of random things I wanted to cover at some point.\n",
    "- Next week: communication and ethics (hopefully)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted trees (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently a lot of the winning models have been one of the following:\n",
    "\n",
    "|  Name   |  GitHub |  web/docs | Year | GitHub stars |\n",
    "|---------|---------|---------|---------|--------------|\n",
    "|  XGBoost | [link](https://github.com/dmlc/xgboost) | [link](https://xgboost.ai/) | 2016 | 19k\n",
    "| LightGBM |  [link](https://github.com/microsoft/LightGBM) | [link](https://lightgbm.readthedocs.io/en/latest/) |  2017 | 11k |\n",
    "| CatBoost | [link](https://github.com/catboost/catboost) | [link](https://catboost.ai/) | 2017 | 5k |\n",
    "\n",
    "When I checked, all repos updated in the last 24 hrs (i.e., active development)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All of these implement [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting), which is beyond the scope of the course.\n",
    "  - And not covered in 340, but it probably should be!\n",
    "- These 3 packages are fairly similar. Today I'll focus on CatBoost.\n",
    "- I believe CatBoost and LightGBM seems to be performing better than XGBoost these days, but they are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I avoided these earlier in the course because I thought they'd be hard to install.\n",
    "- It seems a lot of issues were solved since I tried XGBoost 1-2 years ago - it was easy!\n",
    "- I think next time I might put these a lot earlier and use CatBoost instead of sklearn random forests everywhere, because I think it's a better choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variables\n",
    "\n",
    "- Of these 3, CatBoost is special because of how it handles categorical variables - hence \"Cat\".\n",
    "- Thinking back to decision trees, we talked about splits like `Humidity > 1.2` or `Longitude > 90`. \n",
    "- Because we OHE categorical variables, it will give splits like `Location_Sydney > 0.5`, where that number 0.5 could be anywhere between 0 and 1. \n",
    "- (First off, there is no reason sklearn's decision trees or random forests need to require OHE; they could have easily learned rules like `Location == 'Sydney'`, which is equivalent to `Location_Sydney > 0.5` after OHE. I believe they didn't do this to be consistent with other sklearn estimators. However, I wonder if this makes performance worse, in particular for random forests.)\n",
    "- However, is OHE the best encoding? Do we want 100 columns if there are 100 categories? What about `drop='first'` and `handle_error='ignore'`. It seems like a lot of hassle.\n",
    "- CatBoost uses a more sophisticated encoding from categorical to numeric; see [here](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html#algorithm-main-stages_cat-to-numberic).\n",
    "  - From the documentation: \"Before each split is selected in the tree (see Choosing the tree structure), categorical features are transformed to numerical. This is done using various statistics on combinations of categorical features and combinations of categorical and numerical features.\"\n",
    "  - This makes me think the conversion is done separately _at each split_.\n",
    "  - So we can't just do this transformation in advance, it is entangled deeply with the algorithm. \n",
    "  - And also this makes sense, since the popularity of each value will change as your split the data.\n",
    "  - Importantly, if there are 100 possible categories, you may not end up with 100 columns.\n",
    "  - (From my reading of the documentation it looks like you end up with some smaller number of columns, depending on the type of _targets_: one per class for classification, and for regression this is controlled by a hyperparameter $k$.)\n",
    "  - (Interestingly, the number of columns does not seem to depend on the number of possible categories of the categorical variable!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_housing, X_valid_housing, X_test_housing, y_train_housing, y_valid_housing, y_test_housing = load_process_data.load_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>Functional_Maj2</th>\n",
       "      <th>Functional_Min1</th>\n",
       "      <th>Functional_Min2</th>\n",
       "      <th>Functional_Mod</th>\n",
       "      <th>Functional_Typ</th>\n",
       "      <th>Fence_?</th>\n",
       "      <th>Fence_GdPrv</th>\n",
       "      <th>Fence_GdWo</th>\n",
       "      <th>Fence_MnPrv</th>\n",
       "      <th>Fence_MnWw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>-0.165978</td>\n",
       "      <td>0.338699</td>\n",
       "      <td>-0.062802</td>\n",
       "      <td>-0.505587</td>\n",
       "      <td>1.048406</td>\n",
       "      <td>0.927764</td>\n",
       "      <td>-0.577947</td>\n",
       "      <td>0.791412</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>-0.622612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-0.026237</td>\n",
       "      <td>-0.354633</td>\n",
       "      <td>-0.764983</td>\n",
       "      <td>-1.415471</td>\n",
       "      <td>-0.731683</td>\n",
       "      <td>-1.679272</td>\n",
       "      <td>0.294327</td>\n",
       "      <td>-0.544487</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>-0.120404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1.464330</td>\n",
       "      <td>-0.133037</td>\n",
       "      <td>-0.062802</td>\n",
       "      <td>-0.505587</td>\n",
       "      <td>-0.328644</td>\n",
       "      <td>-1.099931</td>\n",
       "      <td>1.074497</td>\n",
       "      <td>-0.149451</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>0.336963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-0.259139</td>\n",
       "      <td>-0.354322</td>\n",
       "      <td>-0.764983</td>\n",
       "      <td>-0.505587</td>\n",
       "      <td>0.242328</td>\n",
       "      <td>-0.279197</td>\n",
       "      <td>-0.577947</td>\n",
       "      <td>-0.937398</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>-1.295212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>-0.026237</td>\n",
       "      <td>0.084927</td>\n",
       "      <td>-0.062802</td>\n",
       "      <td>0.404297</td>\n",
       "      <td>0.175155</td>\n",
       "      <td>-0.375754</td>\n",
       "      <td>-0.577947</td>\n",
       "      <td>0.691592</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>-0.306490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "1341    -0.165978  0.338699    -0.062802    -0.505587   1.048406   \n",
       "459     -0.026237 -0.354633    -0.764983    -1.415471  -0.731683   \n",
       "367      1.464330 -0.133037    -0.062802    -0.505587  -0.328644   \n",
       "894     -0.259139 -0.354322    -0.764983    -0.505587   0.242328   \n",
       "672     -0.026237  0.084927    -0.062802     0.404297   0.175155   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "1341      0.927764   -0.577947    0.791412   -0.284437  -0.622612  ...   \n",
       "459      -1.679272    0.294327   -0.544487   -0.284437  -0.120404  ...   \n",
       "367      -1.099931    1.074497   -0.149451   -0.284437   0.336963  ...   \n",
       "894      -0.279197   -0.577947   -0.937398   -0.284437  -1.295212  ...   \n",
       "672      -0.375754   -0.577947    0.691592   -0.284437  -0.306490  ...   \n",
       "\n",
       "      Functional_Maj2  Functional_Min1  Functional_Min2  Functional_Mod  \\\n",
       "1341              0.0              0.0              0.0             0.0   \n",
       "459               0.0              0.0              0.0             0.0   \n",
       "367               0.0              0.0              0.0             0.0   \n",
       "894               0.0              0.0              0.0             0.0   \n",
       "672               0.0              0.0              0.0             0.0   \n",
       "\n",
       "      Functional_Typ  Fence_?  Fence_GdPrv  Fence_GdWo  Fence_MnPrv  \\\n",
       "1341             1.0      1.0          0.0         0.0          0.0   \n",
       "459              1.0      1.0          0.0         0.0          0.0   \n",
       "367              1.0      1.0          0.0         0.0          0.0   \n",
       "894              1.0      1.0          0.0         0.0          0.0   \n",
       "672              1.0      1.0          0.0         0.0          0.0   \n",
       "\n",
       "      Fence_MnWw  \n",
       "1341         0.0  \n",
       "459          0.0  \n",
       "367          0.0  \n",
       "894          0.0  \n",
       "672          0.0  \n",
       "\n",
       "[5 rows x 288 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_housing_log = np.log(y_train_housing)\n",
    "y_valid_housing_log = np.log(y_valid_housing)\n",
    "y_test_housing_log  = np.log(y_test_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_housing = show_scores_factory(X_train_housing, y_train_housing_log, X_valid_housing, y_valid_housing_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771971926959883"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_housing(Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8451189779530107"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_housing(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8720378299606011"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_housing(xgb.XGBRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8642147899492177"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_housing(lgb.LGBMRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9051122179357415"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_housing(CatBoostRegressor(), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we try with proper handling of categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_housing_cat, X_valid_housing_cat, X_test_housing_cat, y_train_housing, y_valid_housing, y_test_housing, categorical_features = load_process_data.load_housing(ohe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>-0.165978</td>\n",
       "      <td>0.338699</td>\n",
       "      <td>-0.0628021</td>\n",
       "      <td>-0.505587</td>\n",
       "      <td>1.04841</td>\n",
       "      <td>0.927764</td>\n",
       "      <td>-0.577947</td>\n",
       "      <td>0.791412</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>-0.622612</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>WD</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-0.0262374</td>\n",
       "      <td>-0.354633</td>\n",
       "      <td>-0.764983</td>\n",
       "      <td>-1.41547</td>\n",
       "      <td>-0.731683</td>\n",
       "      <td>-1.67927</td>\n",
       "      <td>0.294327</td>\n",
       "      <td>-0.544487</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>-0.120404</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>WD</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>No</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1.46433</td>\n",
       "      <td>-0.133037</td>\n",
       "      <td>-0.0628021</td>\n",
       "      <td>-0.505587</td>\n",
       "      <td>-0.328644</td>\n",
       "      <td>-1.09993</td>\n",
       "      <td>1.0745</td>\n",
       "      <td>-0.149451</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>0.336963</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>WD</td>\n",
       "      <td>Tar&amp;Grv</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Gd</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-0.259139</td>\n",
       "      <td>-0.354322</td>\n",
       "      <td>-0.764983</td>\n",
       "      <td>-0.505587</td>\n",
       "      <td>0.242328</td>\n",
       "      <td>-0.279197</td>\n",
       "      <td>-0.577947</td>\n",
       "      <td>-0.937398</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>-1.29521</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>WD</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>-0.0262374</td>\n",
       "      <td>0.0849273</td>\n",
       "      <td>-0.0628021</td>\n",
       "      <td>0.404297</td>\n",
       "      <td>0.175155</td>\n",
       "      <td>-0.375754</td>\n",
       "      <td>-0.577947</td>\n",
       "      <td>0.691592</td>\n",
       "      <td>-0.284437</td>\n",
       "      <td>-0.30649</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>WD</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotFrontage    LotArea OverallQual OverallCond YearBuilt YearRemodAdd  \\\n",
       "1341   -0.165978   0.338699  -0.0628021   -0.505587   1.04841     0.927764   \n",
       "459   -0.0262374  -0.354633   -0.764983    -1.41547 -0.731683     -1.67927   \n",
       "367      1.46433  -0.133037  -0.0628021   -0.505587 -0.328644     -1.09993   \n",
       "894    -0.259139  -0.354322   -0.764983   -0.505587  0.242328    -0.279197   \n",
       "672   -0.0262374  0.0849273  -0.0628021    0.404297  0.175155    -0.375754   \n",
       "\n",
       "     MasVnrArea BsmtFinSF1 BsmtFinSF2 BsmtUnfSF  ... MSSubClass MoSold  \\\n",
       "1341  -0.577947   0.791412  -0.284437 -0.622612  ...         20      7   \n",
       "459    0.294327  -0.544487  -0.284437 -0.120404  ...         50      7   \n",
       "367      1.0745  -0.149451  -0.284437  0.336963  ...         80     12   \n",
       "894   -0.577947  -0.937398  -0.284437  -1.29521  ...         90      6   \n",
       "672   -0.577947   0.691592  -0.284437  -0.30649  ...         20      6   \n",
       "\n",
       "     SaleType RoofMatl LandContour BsmtExposure BsmtFinType1 BsmtFinType2  \\\n",
       "1341       WD  CompShg         Lvl           No          GLQ          Unf   \n",
       "459        WD  CompShg         Bnk           No          LwQ          Unf   \n",
       "367        WD  Tar&Grv         Lvl           Gd          GLQ          Unf   \n",
       "894        WD  CompShg         Bnk            ?            ?            ?   \n",
       "672        WD  CompShg         Lvl           No          ALQ          Unf   \n",
       "\n",
       "     Functional Fence  \n",
       "1341        Typ     ?  \n",
       "459         Typ     ?  \n",
       "367         Typ     ?  \n",
       "894         Typ     ?  \n",
       "672         Typ     ?  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_housing_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>...</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>Y</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>None</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>1Story</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>WD</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Y</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Y</td>\n",
       "      <td>BrkSide</td>\n",
       "      <td>BrkCmn</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>WD</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>No</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Y</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Basment</td>\n",
       "      <td>Y</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>RFn</td>\n",
       "      <td>GasA</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>WD</td>\n",
       "      <td>Tar&amp;Grv</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Gd</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Y</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>None</td>\n",
       "      <td>Duplex</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>1Story</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>WD</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Y</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Y</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>None</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>RFn</td>\n",
       "      <td>GasA</td>\n",
       "      <td>1Story</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>WD</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Typ</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CentralAir Utilities GarageType PavedDrive Neighborhood MasVnrType  \\\n",
       "1341          Y    AllPub     Detchd          Y      SawyerW       None   \n",
       "459           Y    AllPub     Detchd          Y      BrkSide     BrkCmn   \n",
       "367           Y    AllPub    Basment          Y        NAmes    BrkFace   \n",
       "894           Y    AllPub     Attchd          Y      SawyerW       None   \n",
       "672           Y    AllPub     Attchd          Y      Veenker       None   \n",
       "\n",
       "     BldgType GarageFinish Heating HouseStyle  ... MSSubClass MoSold SaleType  \\\n",
       "1341     1Fam          Unf    GasA     1Story  ...         20      7       WD   \n",
       "459      1Fam          Unf    GasA     1.5Fin  ...         50      7       WD   \n",
       "367      1Fam          RFn    GasA       SLvl  ...         80     12       WD   \n",
       "894    Duplex          Unf    GasA     1Story  ...         90      6       WD   \n",
       "672      1Fam          RFn    GasA     1Story  ...         20      6       WD   \n",
       "\n",
       "     RoofMatl LandContour BsmtExposure BsmtFinType1 BsmtFinType2 Functional  \\\n",
       "1341  CompShg         Lvl           No          GLQ          Unf        Typ   \n",
       "459   CompShg         Bnk           No          LwQ          Unf        Typ   \n",
       "367   Tar&Grv         Lvl           Gd          GLQ          Unf        Typ   \n",
       "894   CompShg         Bnk            ?            ?            ?        Typ   \n",
       "672   CompShg         Lvl           No          ALQ          Unf        Typ   \n",
       "\n",
       "     Fence  \n",
       "1341     ?  \n",
       "459      ?  \n",
       "367      ?  \n",
       "894      ?  \n",
       "672      ?  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_housing_cat[categorical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CentralAir, Utilities, GarageType, PavedDrive, Neighborhood, MasVnrType, BldgType, GarageFinish, Heating, HouseStyle, LotShape, LotConfig, Electrical, KitchenAbvGr, Condition1, MiscFeature, Street, Alley, LandSlope, RoofStyle, Exterior2nd, Condition2, Exterior1st, MSZoning, SaleCondition, BedroomAbvGr, Foundation, MSSubClass, MoSold, SaleType, RoofMatl, LandContour, BsmtExposure, BsmtFinType1, BsmtFinType2, Functional, Fence\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.039377\n",
      "0:\tlearn: 0.3951997\ttotal: 46.5ms\tremaining: 46.5s\n",
      "100:\tlearn: 0.1249415\ttotal: 5.66s\tremaining: 50.4s\n",
      "200:\tlearn: 0.1002285\ttotal: 11.7s\tremaining: 46.5s\n",
      "300:\tlearn: 0.0892388\ttotal: 18.7s\tremaining: 43.5s\n",
      "400:\tlearn: 0.0809382\ttotal: 23.7s\tremaining: 35.4s\n",
      "500:\tlearn: 0.0736061\ttotal: 30.2s\tremaining: 30.1s\n",
      "600:\tlearn: 0.0665125\ttotal: 38.5s\tremaining: 25.6s\n",
      "700:\tlearn: 0.0609587\ttotal: 44.1s\tremaining: 18.8s\n",
      "800:\tlearn: 0.0561925\ttotal: 50.1s\tremaining: 12.4s\n",
      "900:\tlearn: 0.0522277\ttotal: 56.7s\tremaining: 6.23s\n",
      "999:\tlearn: 0.0483357\ttotal: 1m 1s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostRegressor(cat_features=categorical_features)\n",
    "cat.fit(X_train_housing_cat, y_train_housing_log, verbose=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034631808902006"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.score(X_valid_housing_cat, y_valid_housing_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the code ran slower and it didn't seem to help, but I suspect it will in some cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The syntax for getting feature importances is a bit clunky.\n",
    "- You first need to create a `catboost.Pool` object storing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pool = Pool(X_train_housing_cat, y_train_housing_log, cat_features=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can get feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = cat.get_feature_importance(train_data_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can display them as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>17.132160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>15.718205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>6.045116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterQual</th>\n",
       "      <td>3.995476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>3.933389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street</th>\n",
       "      <td>0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Importance\n",
       "OverallQual    17.132160\n",
       "GrLivArea      15.718205\n",
       "TotalBsmtSF     6.045116\n",
       "ExterQual       3.995476\n",
       "GarageCars      3.933389\n",
       "...                  ...\n",
       "Street          0.003121\n",
       "LowQualFinSF    0.001376\n",
       "BsmtHalfBath    0.000309\n",
       "PoolQC          0.000113\n",
       "Utilities       0.000019\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame(data=importances, index=X_train_housing_cat.columns, columns=[\"Importance\"])\n",
    "importances.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CentralAir, Utilities, GarageType, PavedDrive, Neighborhood, MasVnrType, BldgType, GarageFinish, Heating, HouseStyle, LotShape, LotConfig, Electrical, KitchenAbvGr, Condition1, MiscFeature, Street, Alley, LandSlope, RoofStyle, Exterior2nd, Condition2, Exterior1st, MSZoning, SaleCondition, BedroomAbvGr, Foundation, MSSubClass, MoSold, SaleType, RoofMatl, LandContour, BsmtExposure, BsmtFinType1, BsmtFinType2, Functional, Fence\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(categorical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also get SHAP values, both through the SHAP package or built-in to CatBoost.\n",
    "- With proper handling of categorical variables, we can see an importance for the entire categorical variable, not just one possible value of it, which is kind of nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very rough rule of thumb, when working on a problem with **tabular data**, try the following, in order: \n",
    "\n",
    "1. `DummyRegressor` or `DummyClassifer`\n",
    "2. `HuberRegressor` or `LogisticRegression`\n",
    "3. `CatBoostRegressor` or `CatBoostClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now do a \"bake-off\" between different models and different datasets in the course, following the outlier scavenger hunt from L19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Census data (lecture 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 100)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_adult, y_train_adult, X_test_adult, y_test_adult, _ = load_process_data.load_adult()\n",
    "X_train_adult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native.country_Portugal</th>\n",
       "      <th>native.country_Puerto-Rico</th>\n",
       "      <th>native.country_Scotland</th>\n",
       "      <th>native.country_South</th>\n",
       "      <th>native.country_Taiwan</th>\n",
       "      <th>native.country_Thailand</th>\n",
       "      <th>native.country_Trinadad&amp;Tobago</th>\n",
       "      <th>native.country_United-States</th>\n",
       "      <th>native.country_Vietnam</th>\n",
       "      <th>native.country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>-1.364769</td>\n",
       "      <td>-0.745073</td>\n",
       "      <td>-0.027403</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.845065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>-1.217915</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>3.204805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>0.911476</td>\n",
       "      <td>1.397806</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>0.451354</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>1.058330</td>\n",
       "      <td>-0.736111</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.440078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>0.984903</td>\n",
       "      <td>-1.316034</td>\n",
       "      <td>1.138922</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.179870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "17064 -1.364769 -0.745073      -0.027403     -0.146669     -0.216807   \n",
       "18434 -1.217915  0.708967      -0.416178     -0.146669     -0.216807   \n",
       "3294   0.911476  1.397806      -0.416178      0.451354     -0.216807   \n",
       "31317  1.058330 -0.736111       1.138922     -0.146669     -0.216807   \n",
       "4770   0.984903 -1.316034       1.138922     -0.146669     -0.216807   \n",
       "\n",
       "       hours.per.week  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "17064       -0.845065                    0.0                  0.0   \n",
       "18434        3.204805                    0.0                  0.0   \n",
       "3294         1.179870                    0.0                  0.0   \n",
       "31317       -0.440078                    0.0                  0.0   \n",
       "4770         1.179870                    0.0                  0.0   \n",
       "\n",
       "       workclass_Never-worked  workclass_Private  ...  \\\n",
       "17064                     0.0                1.0  ...   \n",
       "18434                     0.0                1.0  ...   \n",
       "3294                      0.0                1.0  ...   \n",
       "31317                     0.0                1.0  ...   \n",
       "4770                      0.0                0.0  ...   \n",
       "\n",
       "       native.country_Portugal  native.country_Puerto-Rico  \\\n",
       "17064                      0.0                         0.0   \n",
       "18434                      0.0                         0.0   \n",
       "3294                       0.0                         0.0   \n",
       "31317                      0.0                         0.0   \n",
       "4770                       0.0                         0.0   \n",
       "\n",
       "       native.country_Scotland  native.country_South  native.country_Taiwan  \\\n",
       "17064                      0.0                   0.0                    0.0   \n",
       "18434                      0.0                   0.0                    0.0   \n",
       "3294                       0.0                   0.0                    0.0   \n",
       "31317                      0.0                   0.0                    0.0   \n",
       "4770                       0.0                   0.0                    0.0   \n",
       "\n",
       "       native.country_Thailand  native.country_Trinadad&Tobago  \\\n",
       "17064                      0.0                             0.0   \n",
       "18434                      0.0                             0.0   \n",
       "3294                       0.0                             0.0   \n",
       "31317                      0.0                             0.0   \n",
       "4770                       0.0                             0.0   \n",
       "\n",
       "       native.country_United-States  native.country_Vietnam  \\\n",
       "17064                           1.0                     0.0   \n",
       "18434                           1.0                     0.0   \n",
       "3294                            1.0                     0.0   \n",
       "31317                           1.0                     0.0   \n",
       "4770                            1.0                     0.0   \n",
       "\n",
       "       native.country_Yugoslavia  \n",
       "17064                        0.0  \n",
       "18434                        0.0  \n",
       "3294                         0.0  \n",
       "31317                        0.0  \n",
       "4770                         0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_adult = show_scores_factory(X_train_adult, y_train_adult, X_test_adult, y_test_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7538768616612928"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_adult(DummyClassifier(strategy=\"prior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8510670965760786"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_adult(LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8711807154920927"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_adult(xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8745585751573776"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_adult(lgb.LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8730231844004299"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_adult(CatBoostClassifier(), verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adult_cat, y_train_adult, X_test_adult_cat, y_test_adult, cat_features_adult = load_process_data.load_adult(ohe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17064</th>\n",
       "      <td>-1.36477</td>\n",
       "      <td>-0.745073</td>\n",
       "      <td>-0.0274029</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.845065</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18434</th>\n",
       "      <td>-1.21791</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>3.2048</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>0.911476</td>\n",
       "      <td>1.39781</td>\n",
       "      <td>-0.416178</td>\n",
       "      <td>0.451354</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.17987</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>1.05833</td>\n",
       "      <td>-0.736111</td>\n",
       "      <td>1.13892</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>-0.440078</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>0.984903</td>\n",
       "      <td>-1.31603</td>\n",
       "      <td>1.13892</td>\n",
       "      <td>-0.146669</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>1.17987</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt education.num capital.gain capital.loss  \\\n",
       "17064  -1.36477 -0.745073    -0.0274029    -0.146669    -0.216807   \n",
       "18434  -1.21791  0.708967     -0.416178    -0.146669    -0.216807   \n",
       "3294   0.911476   1.39781     -0.416178     0.451354    -0.216807   \n",
       "31317   1.05833 -0.736111       1.13892    -0.146669    -0.216807   \n",
       "4770   0.984903  -1.31603       1.13892    -0.146669    -0.216807   \n",
       "\n",
       "      hours.per.week     workclass     education      marital.status  \\\n",
       "17064      -0.845065       Private  Some-college       Never-married   \n",
       "18434         3.2048       Private       HS-grad       Never-married   \n",
       "3294         1.17987       Private       HS-grad  Married-civ-spouse   \n",
       "31317      -0.440078       Private     Bachelors  Married-civ-spouse   \n",
       "4770         1.17987  Self-emp-inc     Bachelors  Married-civ-spouse   \n",
       "\n",
       "            occupation relationship                race     sex native.country  \n",
       "17064     Adm-clerical    Own-child  Asian-Pac-Islander  Female  United-States  \n",
       "18434    Other-service    Own-child               Black    Male  United-States  \n",
       "3294   Exec-managerial      Husband               White    Male  United-States  \n",
       "31317    Other-service      Husband               White    Male  United-States  \n",
       "4770             Sales      Husband               White    Male  United-States  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_adult_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.041445\n",
      "0:\tlearn: 0.6486984\ttotal: 80.6ms\tremaining: 1m 20s\n",
      "100:\tlearn: 0.2916250\ttotal: 16.4s\tremaining: 2m 25s\n",
      "200:\tlearn: 0.2780044\ttotal: 29.3s\tremaining: 1m 56s\n",
      "300:\tlearn: 0.2681981\ttotal: 38.4s\tremaining: 1m 29s\n",
      "400:\tlearn: 0.2609732\ttotal: 45.9s\tremaining: 1m 8s\n",
      "500:\tlearn: 0.2558415\ttotal: 54.1s\tremaining: 53.9s\n",
      "600:\tlearn: 0.2517539\ttotal: 1m 9s\tremaining: 46s\n",
      "700:\tlearn: 0.2480964\ttotal: 1m 20s\tremaining: 34.5s\n",
      "800:\tlearn: 0.2447137\ttotal: 1m 28s\tremaining: 22s\n",
      "900:\tlearn: 0.2418840\ttotal: 1m 36s\tremaining: 10.6s\n",
      "999:\tlearn: 0.2387305\ttotal: 1m 43s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(cat_features=cat_features_adult)\n",
    "cat.fit(X_train_adult_cat, y_train_adult, verbose=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728696453247351"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.score(X_test_adult_cat, y_test_adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "compare on AUC as well, accuracy might not be as meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie review data (lecture 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2699)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imdb, y_train_imdb, X_test_imdb, y_test_imdb = load_process_data.load_movie()\n",
    "X_train_imdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_movie = show_scores_factory(X_train_imdb, y_train_imdb, X_test_imdb, y_test_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4935"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_movie(DummyClassifier(strategy=\"prior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_movie(LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8415"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_movie(xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM seems to kill my kernel in this case... too many features?? Or maybe it can't handle sparse matrices as input? That seems surprising though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_scores_movie(lgb.LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.025035\n",
      "0:\tlearn: 0.6858406\ttotal: 125ms\tremaining: 2m 4s\n",
      "100:\tlearn: 0.4950686\ttotal: 11.6s\tremaining: 1m 43s\n",
      "200:\tlearn: 0.4394911\ttotal: 22.5s\tremaining: 1m 29s\n",
      "300:\tlearn: 0.4038004\ttotal: 33.2s\tremaining: 1m 17s\n",
      "400:\tlearn: 0.3718700\ttotal: 42.8s\tremaining: 1m 3s\n",
      "500:\tlearn: 0.3415765\ttotal: 52.7s\tremaining: 52.5s\n",
      "600:\tlearn: 0.3163704\ttotal: 1m 5s\tremaining: 43.2s\n",
      "700:\tlearn: 0.2956700\ttotal: 1m 13s\tremaining: 31.6s\n",
      "800:\tlearn: 0.2776943\ttotal: 1m 24s\tremaining: 20.9s\n",
      "900:\tlearn: 0.2614404\ttotal: 1m 33s\tremaining: 10.2s\n",
      "999:\tlearn: 0.2472331\ttotal: 1m 49s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8595"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_movie(CatBoostClassifier(), verbose=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no categorical features here (they are all word counts), so no need to do another experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rain in Australia data (lecture 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107502, 125)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rain, y_train_rain, X_test_rain, y_test_rain, _ = load_process_data.load_rain()\n",
    "X_train_rain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores_rain = show_scores_factory(X_train_rain, y_train_rain, X_test_rain, y_test_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7781845435415525"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_rain(DummyClassifier(strategy=\"prior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8454354155256406"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_rain(LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8550632728949872"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_rain(xgb.XGBClassifier(verbosity=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8536219768816119"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_rain(lgb.LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.075919\n",
      "0:\tlearn: 0.6417575\ttotal: 52.8ms\tremaining: 52.7s\n",
      "100:\tlearn: 0.3397858\ttotal: 6.78s\tremaining: 1m\n",
      "200:\tlearn: 0.3249774\ttotal: 14.3s\tremaining: 57s\n",
      "300:\tlearn: 0.3139556\ttotal: 21.8s\tremaining: 50.6s\n",
      "400:\tlearn: 0.3049408\ttotal: 28.3s\tremaining: 42.3s\n",
      "500:\tlearn: 0.2972943\ttotal: 36.2s\tremaining: 36s\n",
      "600:\tlearn: 0.2904276\ttotal: 44.7s\tremaining: 29.7s\n",
      "700:\tlearn: 0.2841649\ttotal: 51.3s\tremaining: 21.9s\n",
      "800:\tlearn: 0.2783169\ttotal: 1m\tremaining: 15s\n",
      "900:\tlearn: 0.2727251\ttotal: 1m 8s\tremaining: 7.51s\n",
      "999:\tlearn: 0.2675276\ttotal: 1m 14s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8593006831743103"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_rain(CatBoostClassifier(), verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107502, 26)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rain_cat, _, X_test_rain_cat, _, cat_features_rain = load_process_data.load_rain(ohe=False)\n",
    "X_train_rain_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Rainfall_lag1</th>\n",
       "      <th>Rainfall_lag2</th>\n",
       "      <th>Rainfall_lag3</th>\n",
       "      <th>Humidity3pm_lag1</th>\n",
       "      <th>Location</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.204302</td>\n",
       "      <td>-0.0271117</td>\n",
       "      <td>-0.205323</td>\n",
       "      <td>-0.140641</td>\n",
       "      <td>0.160729</td>\n",
       "      <td>0.298612</td>\n",
       "      <td>0.666166</td>\n",
       "      <td>0.599894</td>\n",
       "      <td>0.115428</td>\n",
       "      <td>-1.43351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274971</td>\n",
       "      <td>-0.274913</td>\n",
       "      <td>-0.274905</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>Albury</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.741037</td>\n",
       "      <td>0.287031</td>\n",
       "      <td>-0.275008</td>\n",
       "      <td>-0.140641</td>\n",
       "      <td>0.160729</td>\n",
       "      <td>0.298612</td>\n",
       "      <td>-1.12562</td>\n",
       "      <td>0.373275</td>\n",
       "      <td>-1.31493</td>\n",
       "      <td>-1.288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205283</td>\n",
       "      <td>-0.274913</td>\n",
       "      <td>-0.274905</td>\n",
       "      <td>-1.43362</td>\n",
       "      <td>Albury</td>\n",
       "      <td>WNW</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125523</td>\n",
       "      <td>0.372706</td>\n",
       "      <td>-0.275008</td>\n",
       "      <td>-0.140641</td>\n",
       "      <td>0.160729</td>\n",
       "      <td>0.450132</td>\n",
       "      <td>0.55418</td>\n",
       "      <td>0.826513</td>\n",
       "      <td>-1.63279</td>\n",
       "      <td>-1.04548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274971</td>\n",
       "      <td>-0.205215</td>\n",
       "      <td>-0.274905</td>\n",
       "      <td>-1.28808</td>\n",
       "      <td>Albury</td>\n",
       "      <td>WSW</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.457435</td>\n",
       "      <td>0.701128</td>\n",
       "      <td>-0.275008</td>\n",
       "      <td>-0.140641</td>\n",
       "      <td>0.160729</td>\n",
       "      <td>-1.2166</td>\n",
       "      <td>-0.341712</td>\n",
       "      <td>-1.09975</td>\n",
       "      <td>-1.26195</td>\n",
       "      <td>-1.72454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274971</td>\n",
       "      <td>-0.274913</td>\n",
       "      <td>-0.205207</td>\n",
       "      <td>-1.04552</td>\n",
       "      <td>Albury</td>\n",
       "      <td>NE</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.850283</td>\n",
       "      <td>1.31513</td>\n",
       "      <td>-0.158867</td>\n",
       "      <td>-0.140641</td>\n",
       "      <td>0.160729</td>\n",
       "      <td>0.0713304</td>\n",
       "      <td>-0.789657</td>\n",
       "      <td>0.146656</td>\n",
       "      <td>0.698167</td>\n",
       "      <td>-0.899969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274971</td>\n",
       "      <td>-0.274913</td>\n",
       "      <td>-0.274905</td>\n",
       "      <td>-1.72469</td>\n",
       "      <td>Albury</td>\n",
       "      <td>W</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MinTemp    MaxTemp  Rainfall Evaporation  Sunshine WindGustSpeed  \\\n",
       "0  0.204302 -0.0271117 -0.205323   -0.140641  0.160729      0.298612   \n",
       "1 -0.741037   0.287031 -0.275008   -0.140641  0.160729      0.298612   \n",
       "2  0.125523   0.372706 -0.275008   -0.140641  0.160729      0.450132   \n",
       "3 -0.457435   0.701128 -0.275008   -0.140641  0.160729       -1.2166   \n",
       "4  0.850283    1.31513 -0.158867   -0.140641  0.160729     0.0713304   \n",
       "\n",
       "  WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm  ... Rainfall_lag1  \\\n",
       "0     0.666166     0.599894    0.115428    -1.43351  ...     -0.274971   \n",
       "1     -1.12562     0.373275    -1.31493      -1.288  ...     -0.205283   \n",
       "2      0.55418     0.826513    -1.63279    -1.04548  ...     -0.274971   \n",
       "3    -0.341712     -1.09975    -1.26195    -1.72454  ...     -0.274971   \n",
       "4    -0.789657     0.146656    0.698167   -0.899969  ...     -0.274971   \n",
       "\n",
       "  Rainfall_lag2 Rainfall_lag3 Humidity3pm_lag1 Location WindGustDir  \\\n",
       "0     -0.274913     -0.274905         0.021742   Albury           W   \n",
       "1     -0.274913     -0.274905         -1.43362   Albury         WNW   \n",
       "2     -0.205215     -0.274905         -1.28808   Albury         WSW   \n",
       "3     -0.274913     -0.205207         -1.04552   Albury          NE   \n",
       "4     -0.274913     -0.274905         -1.72469   Albury           W   \n",
       "\n",
       "  WindDir9am WindDir3pm RainToday Month  \n",
       "0          W        WNW        No    12  \n",
       "1        NNW        WSW        No    12  \n",
       "2          W        WSW        No    12  \n",
       "3         SE          E        No    12  \n",
       "4        ENE         NW        No    12  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rain_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.143349\n",
      "0:\tlearn: 0.5970566\ttotal: 336ms\tremaining: 2m 47s\n",
      "50:\tlearn: 0.3339990\ttotal: 15.8s\tremaining: 2m 18s\n",
      "100:\tlearn: 0.3198865\ttotal: 28.8s\tremaining: 1m 53s\n",
      "150:\tlearn: 0.3101000\ttotal: 41.6s\tremaining: 1m 36s\n",
      "200:\tlearn: 0.3027833\ttotal: 54.8s\tremaining: 1m 21s\n",
      "250:\tlearn: 0.2968515\ttotal: 1m 47s\tremaining: 1m 47s\n",
      "300:\tlearn: 0.2914525\ttotal: 1m 58s\tremaining: 1m 18s\n",
      "350:\tlearn: 0.2869166\ttotal: 2m 9s\tremaining: 55.1s\n",
      "400:\tlearn: 0.2821816\ttotal: 2m 23s\tremaining: 35.5s\n",
      "450:\tlearn: 0.2779684\ttotal: 2m 46s\tremaining: 18.1s\n",
      "499:\tlearn: 0.2739957\ttotal: 3m 17s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=500, cat_features=cat_features_rain)\n",
    "cat.fit(X_train_rain_cat, y_train_rain, verbose=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8617508863970482"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.score(X_test_rain_cat, y_test_rain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "- Overall CatBoost looks like a good bet. \n",
    "- We didn't do any hyperparameter tuning, this might change the results. Maybe they just have better defaults.\n",
    "  - In fact, we did not discuss hyperparameters at all for these fancy models.\n",
    "  - There are a ton of them!\n",
    "  - For CatBoost, a main hyperparameter controlling the fundamental tradeoff is `iterations`. \n",
    "    - This is similar to `n_estimators` in the sklearn random forests: larger = more complex models.\n",
    "  - Another main hyperparameter is `learning_rate` but its interpretation is a bit beyond our scope.\n",
    "  - These models should all be compatible with `RandomizedSearchCV`, etc.\n",
    "  - But CatBoost, at least, does not work out of the box for feature selection with `RFE`/`RFECV`\n",
    "- But I think it's pretty good. A bit slow though.\n",
    "  - Now that speed is an issue, we should note that increasing complexity via `iterations` also increases runtime.\n",
    "  - This is not always true, e.g. `gamma` in SVM and (for the most part) `C` in `LogisticRegression`.\n",
    "  - But in fact often we did get increased runtime with more complexity, e.g. more features from `CountVectorizer`. \n",
    "- I'm surprising that feeding in the raw categorical features doesn't seem to help in many cases. \n",
    "  - Isn't that the point of CatBoost?!\n",
    "  - It does seem to help with the Rain data.\n",
    "  - I will need to look into this more at some point.\n",
    "    - Maybe the code needs to be run for longer in these cases?\n",
    "    - Hyperparameter tuning should be done in each case, at least a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big data sets: `SGDClassifier` and `SGDRegressor` (10 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Something we haven't discussed in this course is huge data sets.\n",
    "- There could be a couple problems arising from huge data sets:\n",
    "\n",
    "1. The code is too slow.\n",
    "2. The dataset doesn't fit in memory - I can't even load it with `pd.read_csv`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"SGD\" (stochastic gradient descent) can help with both of these problems.\n",
    "- But we'll focus on using it to solve problem (1).\n",
    "- There is a fancy way to implement `fit` that can be a lot faster for big data sets.\n",
    "  - You can think of it as quickly finding \"approximately\" the best coefficients when calling `fit`.\n",
    "  - That is not quite true but it may be a useful way of thinking.\n",
    "  - Much more on this in CPSC 340 and much, much more on this in CPSC 440/540."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SGD can be used in many contexts.\n",
    "- In sklearn, it's built in as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `SGDRegressor` is basically equivalent to `Ridge`.\n",
    "- `SGDRegressor(loss='huber')` is basically equivalent to `HuberRegressor`.\n",
    "- `SGDClassifier(loss='log')` is basically equivalent to `LogisticRegression`, except the parameter is called `alpha` instead of `C` (like `Ridge`).\n",
    "- With other settings they are equivalent to other models, but this is good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For regular sized datasets, use the original functions, as these ones can be a bit more finicky. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the [Sentiment140 dataset](http://help.sentiment140.com/home), which contains tweets labeled with sentiment associated with a brand, product, or topic. (I don't think we've looked at this dataset before - using it here because it's large.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('data/training.1600000.processed.noemoticon.csv', \n",
    "                        encoding = \"ISO-8859-1\",\n",
    "                        names=[\"label\",\"id\", \"date\", \"no_query\", \"name\", \"text\"])\n",
    "tweets_df['label'] = tweets_df['label'].map({0: 'neg', 4: 'pos'})\n",
    "tweets_df = tweets_df[tweets_df['label'].str.startswith(('pos','neg'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_train, tweets_df_test = train_test_split(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>no_query</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>623519</th>\n",
       "      <td>neg</td>\n",
       "      <td>2229582799</td>\n",
       "      <td>Thu Jun 18 15:55:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Asmcqu01</td>\n",
       "      <td>@mcquage Yep I'm coming home...what's sad thou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210683</th>\n",
       "      <td>pos</td>\n",
       "      <td>1989074133</td>\n",
       "      <td>Mon Jun 01 00:15:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DaWaBZ94</td>\n",
       "      <td>@bb_nation Hi 9h in paris, started gravity - w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385171</th>\n",
       "      <td>pos</td>\n",
       "      <td>2052722086</td>\n",
       "      <td>Sat Jun 06 01:46:04 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Desmond_Ong</td>\n",
       "      <td>@ianternet haha...play online games ian.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488275</th>\n",
       "      <td>pos</td>\n",
       "      <td>2068458374</td>\n",
       "      <td>Sun Jun 07 14:06:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWendyHouse</td>\n",
       "      <td>Evening all! That didn't take long did it? Ha ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306867</th>\n",
       "      <td>pos</td>\n",
       "      <td>2012075176</td>\n",
       "      <td>Tue Jun 02 20:01:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sarasmile13</td>\n",
       "      <td>@nakeddmblauren I will go back to my self-pity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label          id                          date  no_query  \\\n",
       "623519    neg  2229582799  Thu Jun 18 15:55:25 PDT 2009  NO_QUERY   \n",
       "1210683   pos  1989074133  Mon Jun 01 00:15:38 PDT 2009  NO_QUERY   \n",
       "1385171   pos  2052722086  Sat Jun 06 01:46:04 PDT 2009  NO_QUERY   \n",
       "1488275   pos  2068458374  Sun Jun 07 14:06:50 PDT 2009  NO_QUERY   \n",
       "1306867   pos  2012075176  Tue Jun 02 20:01:44 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  name                                               text  \n",
       "623519        Asmcqu01  @mcquage Yep I'm coming home...what's sad thou...  \n",
       "1210683       DaWaBZ94  @bb_nation Hi 9h in paris, started gravity - w...  \n",
       "1385171    Desmond_Ong          @ianternet haha...play online games ian.   \n",
       "1488275  TheWendyHouse  Evening all! That didn't take long did it? Ha ...  \n",
       "1306867    sarasmile13  @nakeddmblauren I will go back to my self-pity...  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200000, 6)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holy cow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train = vec.fit_transform(tweets_df_train['text']) \n",
    "y_train = tweets_df_train['label']\n",
    "\n",
    "X_test = vec.transform(tweets_df_test['text']) \n",
    "y_test = tweets_df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200000, 563585)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the fraction of elements that are nonzero. Having a sparse matrix really helps!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2346648390807657e-05"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.nnz/np.prod(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a classifier. I'll use `time` instead of `%timeit` because I want to keep the output, and it gets lost with `%timeit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 2.53 s, total: 1min 5s\n",
      "Wall time: 54.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgelbart/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8160875"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7780825"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sgd = SGDClassifier(loss=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.71 s, sys: 125 ms, total: 5.84 s\n",
      "Wall time: 6.97 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_sgd.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_sgd.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7695383333333333"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_sgd.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76628"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_sgd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `SGDClassifier` was about 10x faster than `LogisticRegression`, but the accuracy is slightly lower.\n",
    "- In fact, we can control the speed vs. _train_ accuracy tradeoff in both cases using the hyperparameters.\n",
    "  - The main ones are `max_iter` (higher is slower) and/or `tol` (lower is slower)\n",
    "  - (This is the same for both `LogisticRegression` and `SGDClassifier`)\n",
    "- In general, `LogisticRegression` will get slightly higher _train_ accuracy (may or may not correspond to better validation/test)\n",
    "- But in some cases your dataset is so big that `LogisticRegression` is not feasible, and then `SGDClassifier` can save the day.\n",
    "\n",
    "Random comment: last time I tried this was with sklearn 0.21.3 and scipy 1.3.1 a few months ago, now with skearln 0.22.1 and scipy 1.4.1. I wonder if `LogisticRegression`, or the underlying optimizer in scipy, was improved at all in these recent upgrades, because it seems to be faster now than last time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining multiple tables (10 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a look at the [Formula 1 race data set](https://www.kaggle.com/cjgdev/formula-1-race-data-19502017) from Kaggle. \n",
    "- The dataset contains **multiple CSV files**.\n",
    "- Let's read in one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>position</th>\n",
       "      <th>positionText</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>laps</th>\n",
       "      <th>time</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>fastestLap</th>\n",
       "      <th>rank</th>\n",
       "      <th>fastestLapTime</th>\n",
       "      <th>fastestLapSpeed</th>\n",
       "      <th>statusId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resultId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58</td>\n",
       "      <td>34:50.6</td>\n",
       "      <td>5690616.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>01:27.5</td>\n",
       "      <td>218.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>58</td>\n",
       "      <td>5.478</td>\n",
       "      <td>5696094.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>01:27.7</td>\n",
       "      <td>217.586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58</td>\n",
       "      <td>8.163</td>\n",
       "      <td>5698779.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>01:28.1</td>\n",
       "      <td>216.719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58</td>\n",
       "      <td>17.181</td>\n",
       "      <td>5707797.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>01:28.6</td>\n",
       "      <td>215.464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>58</td>\n",
       "      <td>18.014</td>\n",
       "      <td>5708630.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01:27.4</td>\n",
       "      <td>218.385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23777</th>\n",
       "      <td>988</td>\n",
       "      <td>842</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>01:43.8</td>\n",
       "      <td>192.542</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23778</th>\n",
       "      <td>988</td>\n",
       "      <td>828</td>\n",
       "      <td>15</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>01:43.6</td>\n",
       "      <td>193.057</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23779</th>\n",
       "      <td>988</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>01:42.3</td>\n",
       "      <td>195.402</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23780</th>\n",
       "      <td>988</td>\n",
       "      <td>832</td>\n",
       "      <td>4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>01:43.4</td>\n",
       "      <td>193.41</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23781</th>\n",
       "      <td>988</td>\n",
       "      <td>817</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>01:42.8</td>\n",
       "      <td>194.579</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          raceId  driverId  constructorId  number  grid  position  \\\n",
       "resultId                                                            \n",
       "1             18         1              1    22.0     1       1.0   \n",
       "2             18         2              2     3.0     5       2.0   \n",
       "3             18         3              3     7.0     7       3.0   \n",
       "4             18         4              4     5.0    11       4.0   \n",
       "5             18         5              1    23.0     3       5.0   \n",
       "...          ...       ...            ...     ...   ...       ...   \n",
       "23777        988       842              5    10.0    17      16.0   \n",
       "23778        988       828             15     9.0    19      17.0   \n",
       "23779        988       840              3    18.0    15      18.0   \n",
       "23780        988       832              4    55.0    12       NaN   \n",
       "23781        988       817              9     3.0     4       NaN   \n",
       "\n",
       "         positionText  positionOrder  points  laps     time  milliseconds  \\\n",
       "resultId                                                                    \n",
       "1                   1              1    10.0    58  34:50.6     5690616.0   \n",
       "2                   2              2     8.0    58    5.478     5696094.0   \n",
       "3                   3              3     6.0    58    8.163     5698779.0   \n",
       "4                   4              4     5.0    58   17.181     5707797.0   \n",
       "5                   5              5     4.0    58   18.014     5708630.0   \n",
       "...               ...            ...     ...   ...      ...           ...   \n",
       "23777              16             16     0.0    54      NaN           NaN   \n",
       "23778              17             17     0.0    54      NaN           NaN   \n",
       "23779              18             18     0.0    54      NaN           NaN   \n",
       "23780               R             19     0.0    31      NaN           NaN   \n",
       "23781               R             20     0.0    20      NaN           NaN   \n",
       "\n",
       "          fastestLap  rank fastestLapTime fastestLapSpeed  statusId  \n",
       "resultId                                                             \n",
       "1               39.0   2.0        01:27.5           218.3         1  \n",
       "2               41.0   3.0        01:27.7         217.586         1  \n",
       "3               41.0   5.0        01:28.1         216.719         1  \n",
       "4               58.0   7.0        01:28.6         215.464         1  \n",
       "5               43.0   1.0        01:27.4         218.385         1  \n",
       "...              ...   ...            ...             ...       ...  \n",
       "23777           33.0  16.0        01:43.8         192.542        11  \n",
       "23778           36.0  15.0        01:43.6         193.057        11  \n",
       "23779           52.0   6.0        01:42.3         195.402        11  \n",
       "23780           26.0  14.0        01:43.4          193.41        36  \n",
       "23781           13.0  12.0        01:42.8         194.579         9  \n",
       "\n",
       "[23777 rows x 17 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "racing_results_df = pd.read_csv(\"data/formula-1-race-data-19502017/results.csv\", index_col=0)\n",
    "racing_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's say we want to predict the `milliseconds` column, namely the total length of time it takes a driver to finish a race. \n",
    "- In that case, we should not have access to most of these other columns. \n",
    "- But we would have the `raceId` and `driverId`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>milliseconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resultId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5690616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5696094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>5698779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>5707797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>5708630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23777</th>\n",
       "      <td>988</td>\n",
       "      <td>842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23778</th>\n",
       "      <td>988</td>\n",
       "      <td>828</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23779</th>\n",
       "      <td>988</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23780</th>\n",
       "      <td>988</td>\n",
       "      <td>832</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23781</th>\n",
       "      <td>988</td>\n",
       "      <td>817</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          raceId  driverId  milliseconds\n",
       "resultId                                \n",
       "1             18         1     5690616.0\n",
       "2             18         2     5696094.0\n",
       "3             18         3     5698779.0\n",
       "4             18         4     5707797.0\n",
       "5             18         5     5708630.0\n",
       "...          ...       ...           ...\n",
       "23777        988       842           NaN\n",
       "23778        988       828           NaN\n",
       "23779        988       840           NaN\n",
       "23780        988       832           NaN\n",
       "23781        988       817           NaN\n",
       "\n",
       "[23777 rows x 3 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "racing_results_df_subset = racing_results_df[['raceId', 'driverId', 'milliseconds']]\n",
    "racing_results_df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>milliseconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resultId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5690616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23745</th>\n",
       "      <td>987</td>\n",
       "      <td>1</td>\n",
       "      <td>5491730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22089</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "      <td>5984506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20611</th>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>5344268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23115</th>\n",
       "      <td>957</td>\n",
       "      <td>1</td>\n",
       "      <td>5695831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23675</th>\n",
       "      <td>983</td>\n",
       "      <td>842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23776</th>\n",
       "      <td>988</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23714</th>\n",
       "      <td>985</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23758</th>\n",
       "      <td>987</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>986</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          raceId  driverId  milliseconds\n",
       "resultId                                \n",
       "1             18         1     5690616.0\n",
       "23745        987         1     5491730.0\n",
       "22089        898         1     5984506.0\n",
       "20611        349         1     5344268.0\n",
       "23115        957         1     5695831.0\n",
       "...          ...       ...           ...\n",
       "23675        983       842           NaN\n",
       "23776        988       843           NaN\n",
       "23714        985       843           NaN\n",
       "23758        987       843           NaN\n",
       "23739        986       843           NaN\n",
       "\n",
       "[23777 rows x 3 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "racing_results_df_subset.sort_values(by=\"driverId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "for fun, try to predict milliseconds just based on raceId and driverId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we need some features to predict the race time. \n",
    "- Enter the other tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driverRef</th>\n",
       "      <th>number</th>\n",
       "      <th>code</th>\n",
       "      <th>forename</th>\n",
       "      <th>surname</th>\n",
       "      <th>dob</th>\n",
       "      <th>nationality</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driverId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hamilton</td>\n",
       "      <td>44.0</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Lewis_Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heidfeld</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEI</td>\n",
       "      <td>Nick</td>\n",
       "      <td>Heidfeld</td>\n",
       "      <td>1977-10-05</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Nick_Heidfeld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rosberg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ROS</td>\n",
       "      <td>Nico</td>\n",
       "      <td>Rosberg</td>\n",
       "      <td>1985-06-27</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Nico_Rosberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alonso</td>\n",
       "      <td>14.0</td>\n",
       "      <td>ALO</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>1981-07-29</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Fernando_Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kovalainen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KOV</td>\n",
       "      <td>Heikki</td>\n",
       "      <td>Kovalainen</td>\n",
       "      <td>1981-10-19</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Heikki_Kovalainen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>vandoorne</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VAN</td>\n",
       "      <td>Stoffel</td>\n",
       "      <td>Vandoorne</td>\n",
       "      <td>1992-03-26</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Stoffel_Vandoorne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>ocon</td>\n",
       "      <td>31.0</td>\n",
       "      <td>OCO</td>\n",
       "      <td>Esteban</td>\n",
       "      <td>Ocon</td>\n",
       "      <td>1996-09-17</td>\n",
       "      <td>French</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Esteban_Ocon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>stroll</td>\n",
       "      <td>18.0</td>\n",
       "      <td>STR</td>\n",
       "      <td>Lance</td>\n",
       "      <td>Stroll</td>\n",
       "      <td>1998-10-29</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Lance_Stroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>giovinazzi</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GIO</td>\n",
       "      <td>Antonio</td>\n",
       "      <td>Giovinazzi</td>\n",
       "      <td>1993-12-14</td>\n",
       "      <td>Italian</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Antonio_Giovinazzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>brendon_hartley</td>\n",
       "      <td>39.0</td>\n",
       "      <td>HAR</td>\n",
       "      <td>Brendon</td>\n",
       "      <td>Hartley</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Brendon_Hartley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>842 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                driverRef  number code  forename     surname        dob  \\\n",
       "driverId                                                                  \n",
       "1                hamilton    44.0  HAM     Lewis    Hamilton 1985-07-01   \n",
       "2                heidfeld     NaN  HEI      Nick    Heidfeld 1977-10-05   \n",
       "3                 rosberg     6.0  ROS      Nico     Rosberg 1985-06-27   \n",
       "4                  alonso    14.0  ALO  Fernando      Alonso 1981-07-29   \n",
       "5              kovalainen     NaN  KOV    Heikki  Kovalainen 1981-10-19   \n",
       "...                   ...     ...  ...       ...         ...        ...   \n",
       "838             vandoorne     2.0  VAN   Stoffel   Vandoorne 1992-03-26   \n",
       "839                  ocon    31.0  OCO   Esteban        Ocon 1996-09-17   \n",
       "840                stroll    18.0  STR     Lance      Stroll 1998-10-29   \n",
       "841            giovinazzi    36.0  GIO   Antonio  Giovinazzi 1993-12-14   \n",
       "843       brendon_hartley    39.0  HAR   Brendon     Hartley 1989-10-11   \n",
       "\n",
       "            nationality                                              url  \n",
       "driverId                                                                  \n",
       "1               British      http://en.wikipedia.org/wiki/Lewis_Hamilton  \n",
       "2                German       http://en.wikipedia.org/wiki/Nick_Heidfeld  \n",
       "3                German        http://en.wikipedia.org/wiki/Nico_Rosberg  \n",
       "4               Spanish     http://en.wikipedia.org/wiki/Fernando_Alonso  \n",
       "5               Finnish   http://en.wikipedia.org/wiki/Heikki_Kovalainen  \n",
       "...                 ...                                              ...  \n",
       "838             Belgian   http://en.wikipedia.org/wiki/Stoffel_Vandoorne  \n",
       "839              French        http://en.wikipedia.org/wiki/Esteban_Ocon  \n",
       "840            Canadian        http://en.wikipedia.org/wiki/Lance_Stroll  \n",
       "841             Italian  http://en.wikipedia.org/wiki/Antonio_Giovinazzi  \n",
       "843       New Zealander     http://en.wikipedia.org/wiki/Brendon_Hartley  \n",
       "\n",
       "[842 rows x 8 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "racing_drivers_df = pd.read_csv(\"data/formula-1-race-data-19502017/drivers.csv\", \n",
    "                                encoding='latin-1', index_col=0,\n",
    "                               parse_dates=['dob'])\n",
    "racing_drivers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can we use the driver's nationality and age as features?\n",
    "- `pd.merge` can take care of this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>number</th>\n",
       "      <th>code</th>\n",
       "      <th>forename</th>\n",
       "      <th>surname</th>\n",
       "      <th>dob</th>\n",
       "      <th>nationality</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5690616.0</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>44.0</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Lewis_Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5525103.0</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>44.0</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Lewis_Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>44.0</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Lewis_Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5903238.0</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>44.0</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Lewis_Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5213230.0</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>44.0</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Lewis_Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23772</th>\n",
       "      <td>988</td>\n",
       "      <td>842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gasly</td>\n",
       "      <td>10.0</td>\n",
       "      <td>GAS</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>Gasly</td>\n",
       "      <td>1996-07-02</td>\n",
       "      <td>French</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Pierre_Gasly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23773</th>\n",
       "      <td>985</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brendon_hartley</td>\n",
       "      <td>39.0</td>\n",
       "      <td>HAR</td>\n",
       "      <td>Brendon</td>\n",
       "      <td>Hartley</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Brendon_Hartley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23774</th>\n",
       "      <td>986</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brendon_hartley</td>\n",
       "      <td>39.0</td>\n",
       "      <td>HAR</td>\n",
       "      <td>Brendon</td>\n",
       "      <td>Hartley</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Brendon_Hartley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23775</th>\n",
       "      <td>987</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brendon_hartley</td>\n",
       "      <td>39.0</td>\n",
       "      <td>HAR</td>\n",
       "      <td>Brendon</td>\n",
       "      <td>Hartley</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Brendon_Hartley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23776</th>\n",
       "      <td>988</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brendon_hartley</td>\n",
       "      <td>39.0</td>\n",
       "      <td>HAR</td>\n",
       "      <td>Brendon</td>\n",
       "      <td>Hartley</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Brendon_Hartley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       raceId  driverId  milliseconds        driverRef  number code forename  \\\n",
       "0          18         1     5690616.0         hamilton    44.0  HAM    Lewis   \n",
       "1          19         1     5525103.0         hamilton    44.0  HAM    Lewis   \n",
       "2          20         1           NaN         hamilton    44.0  HAM    Lewis   \n",
       "3          21         1     5903238.0         hamilton    44.0  HAM    Lewis   \n",
       "4          22         1     5213230.0         hamilton    44.0  HAM    Lewis   \n",
       "...       ...       ...           ...              ...     ...  ...      ...   \n",
       "23772     988       842           NaN            gasly    10.0  GAS   Pierre   \n",
       "23773     985       843           NaN  brendon_hartley    39.0  HAR  Brendon   \n",
       "23774     986       843           NaN  brendon_hartley    39.0  HAR  Brendon   \n",
       "23775     987       843           NaN  brendon_hartley    39.0  HAR  Brendon   \n",
       "23776     988       843           NaN  brendon_hartley    39.0  HAR  Brendon   \n",
       "\n",
       "        surname        dob    nationality  \\\n",
       "0      Hamilton 1985-07-01        British   \n",
       "1      Hamilton 1985-07-01        British   \n",
       "2      Hamilton 1985-07-01        British   \n",
       "3      Hamilton 1985-07-01        British   \n",
       "4      Hamilton 1985-07-01        British   \n",
       "...         ...        ...            ...   \n",
       "23772     Gasly 1996-07-02         French   \n",
       "23773   Hartley 1989-10-11  New Zealander   \n",
       "23774   Hartley 1989-10-11  New Zealander   \n",
       "23775   Hartley 1989-10-11  New Zealander   \n",
       "23776   Hartley 1989-10-11  New Zealander   \n",
       "\n",
       "                                                url  \n",
       "0       http://en.wikipedia.org/wiki/Lewis_Hamilton  \n",
       "1       http://en.wikipedia.org/wiki/Lewis_Hamilton  \n",
       "2       http://en.wikipedia.org/wiki/Lewis_Hamilton  \n",
       "3       http://en.wikipedia.org/wiki/Lewis_Hamilton  \n",
       "4       http://en.wikipedia.org/wiki/Lewis_Hamilton  \n",
       "...                                             ...  \n",
       "23772     http://en.wikipedia.org/wiki/Pierre_Gasly  \n",
       "23773  http://en.wikipedia.org/wiki/Brendon_Hartley  \n",
       "23774  http://en.wikipedia.org/wiki/Brendon_Hartley  \n",
       "23775  http://en.wikipedia.org/wiki/Brendon_Hartley  \n",
       "23776  http://en.wikipedia.org/wiki/Brendon_Hartley  \n",
       "\n",
       "[23777 rows x 11 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(racing_results_df_subset, racing_drivers_df, on=\"driverId\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `on` keyword told it which column to use to match up the rows of the two dataframes.\n",
    "- Note that the first 5 rows have the same `driverId`, so they pulled the same data from `racing_drivers_df`.\n",
    "- Now we could keep only the columns we plan to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>dob</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5690616.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5525103.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5903238.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5213230.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23772</th>\n",
       "      <td>988</td>\n",
       "      <td>842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-07-02</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23773</th>\n",
       "      <td>985</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23774</th>\n",
       "      <td>986</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23775</th>\n",
       "      <td>987</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23776</th>\n",
       "      <td>988</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       raceId  driverId  milliseconds        dob    nationality\n",
       "0          18         1     5690616.0 1985-07-01        British\n",
       "1          19         1     5525103.0 1985-07-01        British\n",
       "2          20         1           NaN 1985-07-01        British\n",
       "3          21         1     5903238.0 1985-07-01        British\n",
       "4          22         1     5213230.0 1985-07-01        British\n",
       "...       ...       ...           ...        ...            ...\n",
       "23772     988       842           NaN 1996-07-02         French\n",
       "23773     985       843           NaN 1989-10-11  New Zealander\n",
       "23774     986       843           NaN 1989-10-11  New Zealander\n",
       "23775     987       843           NaN 1989-10-11  New Zealander\n",
       "23776     988       843           NaN 1989-10-11  New Zealander\n",
       "\n",
       "[23777 rows x 5 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_subset = merged_df[['raceId', 'driverId', 'milliseconds', 'dob', 'nationality']]\n",
    "merged_df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can process the `dob` column to get age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>dob</th>\n",
       "      <th>nationality</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5690616.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>34.760290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5525103.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>34.760290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>34.760290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5903238.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>34.760290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5213230.0</td>\n",
       "      <td>1985-07-01</td>\n",
       "      <td>British</td>\n",
       "      <td>34.760290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23772</th>\n",
       "      <td>988</td>\n",
       "      <td>842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-07-02</td>\n",
       "      <td>French</td>\n",
       "      <td>23.749331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23773</th>\n",
       "      <td>985</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>30.478098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23774</th>\n",
       "      <td>986</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>30.478098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23775</th>\n",
       "      <td>987</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>30.478098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23776</th>\n",
       "      <td>988</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989-10-11</td>\n",
       "      <td>New Zealander</td>\n",
       "      <td>30.478098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       raceId  driverId  milliseconds        dob    nationality        age\n",
       "0          18         1     5690616.0 1985-07-01        British  34.760290\n",
       "1          19         1     5525103.0 1985-07-01        British  34.760290\n",
       "2          20         1           NaN 1985-07-01        British  34.760290\n",
       "3          21         1     5903238.0 1985-07-01        British  34.760290\n",
       "4          22         1     5213230.0 1985-07-01        British  34.760290\n",
       "...       ...       ...           ...        ...            ...        ...\n",
       "23772     988       842           NaN 1996-07-02         French  23.749331\n",
       "23773     985       843           NaN 1989-10-11  New Zealander  30.478098\n",
       "23774     986       843           NaN 1989-10-11  New Zealander  30.478098\n",
       "23775     987       843           NaN 1989-10-11  New Zealander  30.478098\n",
       "23776     988       843           NaN 1989-10-11  New Zealander  30.478098\n",
       "\n",
       "[23777 rows x 6 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = (pd.Timestamp.now() - merged_df_subset[\"dob\"]).apply(lambda x: x.total_seconds()/3600/24/365)\n",
    "merged_df_age = merged_df_subset.assign(age=ages)\n",
    "merged_df_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So far we got information for each driver.\n",
    "- Likewise, we can get information about the races, and use those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>round</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raceId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2009-03-29</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2009_Australian_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Malaysian Grand Prix</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2009_Malaysian_Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>Chinese Grand Prix</td>\n",
       "      <td>2009-04-19</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2009_Chinese_Gran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>2009-04-26</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2009_Bahrain_Gran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Spanish Grand Prix</td>\n",
       "      <td>2009-05-10</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2009_Spanish_Gran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2018</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>Japanese Grand Prix</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2018_Japanese_Gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "      <td>69</td>\n",
       "      <td>United States Grand Prix</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2018_United_State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2018</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>Mexican Grand Prix</td>\n",
       "      <td>2018-10-28</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2018_Mexican_Gran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>2018</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2018_Brazilian_Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>Abu Dhabi Grand Prix</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2018_Abu_Dhabi_Gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  round  circuitId                      name        date  \\\n",
       "raceId                                                                 \n",
       "1       2009      1          1     Australian Grand Prix  2009-03-29   \n",
       "2       2009      2          2      Malaysian Grand Prix  2009-04-05   \n",
       "3       2009      3         17        Chinese Grand Prix  2009-04-19   \n",
       "4       2009      4          3        Bahrain Grand Prix  2009-04-26   \n",
       "5       2009      5          4        Spanish Grand Prix  2009-05-10   \n",
       "...      ...    ...        ...                       ...         ...   \n",
       "1005    2018     17         22       Japanese Grand Prix  2018-10-07   \n",
       "1006    2018     18         69  United States Grand Prix  2018-10-21   \n",
       "1007    2018     19         32        Mexican Grand Prix  2018-10-28   \n",
       "1008    2018     20         18      Brazilian Grand Prix  2018-11-11   \n",
       "1009    2018     21         24      Abu Dhabi Grand Prix  2018-11-25   \n",
       "\n",
       "            time                                                url  \n",
       "raceId                                                               \n",
       "1       06:00:00  http://en.wikipedia.org/wiki/2009_Australian_G...  \n",
       "2       09:00:00  http://en.wikipedia.org/wiki/2009_Malaysian_Gr...  \n",
       "3       07:00:00  http://en.wikipedia.org/wiki/2009_Chinese_Gran...  \n",
       "4       12:00:00  http://en.wikipedia.org/wiki/2009_Bahrain_Gran...  \n",
       "5       12:00:00  http://en.wikipedia.org/wiki/2009_Spanish_Gran...  \n",
       "...          ...                                                ...  \n",
       "1005    05:00:00  http://en.wikipedia.org/wiki/2018_Japanese_Gra...  \n",
       "1006    19:00:00  http://en.wikipedia.org/wiki/2018_United_State...  \n",
       "1007    19:00:00  http://en.wikipedia.org/wiki/2018_Mexican_Gran...  \n",
       "1008    16:00:00  http://en.wikipedia.org/wiki/2018_Brazilian_Gr...  \n",
       "1009    13:00:00  http://en.wikipedia.org/wiki/2018_Abu_Dhabi_Gr...  \n",
       "\n",
       "[997 rows x 7 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "racing_races_df = pd.read_csv(\"data/formula-1-race-data-19502017/races.csv\", encoding='latin-1', index_col=0)\n",
    "racing_races_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For those who have taken CPSC 304 or some have other database training, you'll recognize this type of multi-table situation, with foreign keys connecting the tables.\n",
    "- `pd.merge` supports several types of joins, see the documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mleft_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Merge DataFrame or named Series objects with a database-style join.\n",
       "\n",
       "The join is done on columns or indexes. If joining columns on\n",
       "columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
       "on indexes or indexes on a column or columns, the index will be passed on.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "left : DataFrame\n",
       "right : DataFrame or named Series\n",
       "    Object to merge with.\n",
       "how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
       "    Type of merge to be performed.\n",
       "\n",
       "    * left: use only keys from left frame, similar to a SQL left outer join;\n",
       "      preserve key order.\n",
       "    * right: use only keys from right frame, similar to a SQL right outer join;\n",
       "      preserve key order.\n",
       "    * outer: use union of keys from both frames, similar to a SQL full outer\n",
       "      join; sort keys lexicographically.\n",
       "    * inner: use intersection of keys from both frames, similar to a SQL inner\n",
       "      join; preserve the order of the left keys.\n",
       "on : label or list\n",
       "    Column or index level names to join on. These must be found in both\n",
       "    DataFrames. If `on` is None and not merging on indexes then this defaults\n",
       "    to the intersection of the columns in both DataFrames.\n",
       "left_on : label or list, or array-like\n",
       "    Column or index level names to join on in the left DataFrame. Can also\n",
       "    be an array or list of arrays of the length of the left DataFrame.\n",
       "    These arrays are treated as if they are columns.\n",
       "right_on : label or list, or array-like\n",
       "    Column or index level names to join on in the right DataFrame. Can also\n",
       "    be an array or list of arrays of the length of the right DataFrame.\n",
       "    These arrays are treated as if they are columns.\n",
       "left_index : bool, default False\n",
       "    Use the index from the left DataFrame as the join key(s). If it is a\n",
       "    MultiIndex, the number of keys in the other DataFrame (either the index\n",
       "    or a number of columns) must match the number of levels.\n",
       "right_index : bool, default False\n",
       "    Use the index from the right DataFrame as the join key. Same caveats as\n",
       "    left_index.\n",
       "sort : bool, default False\n",
       "    Sort the join keys lexicographically in the result DataFrame. If False,\n",
       "    the order of the join keys depends on the join type (how keyword).\n",
       "suffixes : tuple of (str, str), default ('_x', '_y')\n",
       "    Suffix to apply to overlapping column names in the left and right\n",
       "    side, respectively. To raise an exception on overlapping columns use\n",
       "    (False, False).\n",
       "copy : bool, default True\n",
       "    If False, avoid copy if possible.\n",
       "indicator : bool or str, default False\n",
       "    If True, adds a column to output DataFrame called \"_merge\" with\n",
       "    information on the source of each row.\n",
       "    If string, column with information on source of each row will be added to\n",
       "    output DataFrame, and column will be named value of string.\n",
       "    Information column is Categorical-type and takes on a value of \"left_only\"\n",
       "    for observations whose merge key only appears in 'left' DataFrame,\n",
       "    \"right_only\" for observations whose merge key only appears in 'right'\n",
       "    DataFrame, and \"both\" if the observation's merge key is found in both.\n",
       "\n",
       "validate : str, optional\n",
       "    If specified, checks if merge is of specified type.\n",
       "\n",
       "    * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
       "      left and right datasets.\n",
       "    * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
       "      dataset.\n",
       "    * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
       "      dataset.\n",
       "    * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
       "\n",
       "    .. versionadded:: 0.21.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    A DataFrame of the two merged objects.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "merge_ordered : Merge with optional filling/interpolation.\n",
       "merge_asof : Merge on nearest keys.\n",
       "DataFrame.join : Similar method using indices.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Support for specifying index levels as the `on`, `left_on`, and\n",
       "`right_on` parameters was added in version 0.23.0\n",
       "Support for merging named Series objects was added in version 0.24.0\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       ">>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
       "...                     'value': [1, 2, 3, 5]})\n",
       ">>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
       "...                     'value': [5, 6, 7, 8]})\n",
       ">>> df1\n",
       "    lkey value\n",
       "0   foo      1\n",
       "1   bar      2\n",
       "2   baz      3\n",
       "3   foo      5\n",
       ">>> df2\n",
       "    rkey value\n",
       "0   foo      5\n",
       "1   bar      6\n",
       "2   baz      7\n",
       "3   foo      8\n",
       "\n",
       "Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
       "the default suffixes, _x and _y, appended.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
       "  lkey  value_x rkey  value_y\n",
       "0  foo        1  foo        5\n",
       "1  foo        1  foo        8\n",
       "2  foo        5  foo        5\n",
       "3  foo        5  foo        8\n",
       "4  bar        2  bar        6\n",
       "5  baz        3  baz        7\n",
       "\n",
       "Merge DataFrames df1 and df2 with specified left and right suffixes\n",
       "appended to any overlapping columns.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
       "...           suffixes=('_left', '_right'))\n",
       "  lkey  value_left rkey  value_right\n",
       "0  foo           1  foo            5\n",
       "1  foo           1  foo            8\n",
       "2  foo           5  foo            5\n",
       "3  foo           5  foo            8\n",
       "4  bar           2  bar            6\n",
       "5  baz           3  baz            7\n",
       "\n",
       "Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
       "any overlapping columns.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
       "Traceback (most recent call last):\n",
       "...\n",
       "ValueError: columns overlap but no suffix specified:\n",
       "    Index(['value'], dtype='object')\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd.merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True/False questions (15 min)\n",
    "\n",
    "1. `CatBoost` is effective because, when increasing `iterations`, you lower the training error and the approximation error. \n",
    "2. `CatBoost` is likely to be popular in 10 years.\n",
    "3. The primary motivation for using `SGDClassifier` or `SGDRegressor` is speed.\n",
    "4. In multi-class logistic regression, if the coefficient for feature 10, class 2 is positive, that means increasing the value of feature 10 _decreases_ the predicted probability of class 1 (a different class).\n",
    "5. If we are dealing with data from multiple sources, our strategy is to first combine them as a preprocessing step, and then build a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course review (15 min)\n",
    "\n",
    "#### Learning objectives\n",
    "\n",
    "Here are the course learning outcomes I came up with when proposing this new course:\n",
    "\n",
    "1. Identify problems that may be addressed with machine learning.\n",
    "2. Select the appropriate machine learning tool for a problem.\n",
    "3. Transform data of various types into usable features.\n",
    "4. Apply standard tools implementing supervised and unsupervised learning techniques.\n",
    "5. Describe core differences between training, validation, and testing regimes.\n",
    "6. Effectively communicate the results of a machine learning pipeline.\n",
    "7. Be realistic about the limitations of individual approaches and machine learning as a whole. \n",
    "8. Create reproducible workflows and pipelines.\n",
    "\n",
    "- How did we do? \n",
    "- Hopefully OK, except we skipped the last point (that will likely be its own new course).\n",
    "- I would also add:\n",
    "\n",
    "9. Identify and avoid scenarios in which training and testing data are accidentally mixed (the \"Golden Rule\").\n",
    "10. Employ good habits for applying ML, such as starting an analysis with a baseline estimator.\n",
    "\n",
    "because I think they are important enough to make it to the course-level list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What did we cover?\n",
    "\n",
    "I see the course roughly like this (not in order):\n",
    "\n",
    "Part 1: Supervised learning on tabular data\n",
    "\n",
    "- Overfitting, train/validation/test/deployment, cross-validation\n",
    "- Feature preprocessing, pipelines, imputation, OHE, etc\n",
    "- The Golden Rule, various ways to accidentally violate it\n",
    "- Classification metrics: confusion matrix, precision/recall, ROC, AUC\n",
    "- Regression metrics: MSE, MAPE\n",
    "- Regression: transforming the targets\n",
    "- Feature importances, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Other data types (non-tabular)\n",
    "\n",
    "- Time series\n",
    "- Right-censored data / survival analysis\n",
    "- Computer vision with deep learning\n",
    "- Language data, text preprocessing\n",
    "- Ratings data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Other stuff\n",
    "\n",
    "- Some Python (numpy, pandas, scipy sparse matrices)\n",
    "- Hyperparameter optimization\n",
    "- Ensembles\n",
    "- Outlier detection\n",
    "- Clustering\n",
    "- A bunch of models: \n",
    "  - Dummy*\n",
    "  - linear models (ridge, lasso, huber, logistic regression, SGD*)\n",
    "  - tree-based models (random forest, gradient boosted trees)\n",
    "  - KNN classifier/regressor\n",
    "  - pre-trained deep learning models\n",
    "- Communicating your results (including visualizations)\n",
    "- ML skepticism\n",
    "- Ethics for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would I do differently?\n",
    "\n",
    "Lots of things, of course! Here are some important ones:\n",
    "\n",
    "- Introduce `Pipeline` earlier.\n",
    "- Throughout the course, default to cross-validation instead of train/valid split.\n",
    "- Find a dataset with multi-class classification for a section of the course.\n",
    "- Spend more time on quantifying the uncertainty in one's results (scores, predictions, feature importances, etc).\n",
    "- Add a lecture on deploying a trained model.\n",
    "- Skip some of the content on text preprocessing.\n",
    "- Skip some of the content on SVMs.\n",
    "- Skip `Lasso`?\n",
    "\n",
    "I'm sure you have other suggestions - feel free to drop me an email, submit my contact form anonymously at mikegelbart.com, or drop them in the course evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 330 vs. 340\n",
    "\n",
    "- Just talked about it - see recording.\n",
    "\n",
    "# TODO - add this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was not covered\n",
    "\n",
    "- Deployment\n",
    "- Big data, distributed computing\n",
    "- How ML methods work (CPSC 340)\n",
    "- Probabilistic methods\n",
    "- A lot of unsupervised learning, semi-supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsolicited advice: working with others (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I sometimes end my courses with \"unsolicited life advice\".\n",
    "- I won't repeat myself here because some of you took CPSC 340 with me. But if you're interested [it's on YouTube](https://www.youtube.com/watch?v=_7zYxpzrKmQ&list=PLWmXHcz_53Q02ZLeAxigki1JZFfCO6M-b&index=34&t=0s).\n",
    "- Instead of general life advice I'll try a different topic this time: unsolicited advice on _working with others_.\n",
    "- These are just my opinions. They not be complete, or correct. Follow my advice at your own risk!\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't lead with blame - investigate first\n",
    "\n",
    "Leading with blame:\n",
    "\n",
    "> Hey Malcolm, you were supposed to submit this form by the deadline - why didn't you?\n",
    "\n",
    "Instead, try this:\n",
    "\n",
    "> Hey Malcolm, from my end it looks like the form hasn't been submitted - can you shed some light on the situation?\n",
    "\n",
    "- Blaming others is very embarrassing and damaging if the blame is not deserved.\n",
    "- And also not great if the blame _is_ deserved.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fundamental attribution error\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Fundamental_attribution_error\n",
    "- If you miss a deadline: “I was too busy moving apartments.”\n",
    "- If your teammate misses a deadline: “They are incompetent.”\n",
    "- This is a known psychological phenomenon, so try to correct for this. Are you sure you know why they missed the deadline?\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't procrastinate on disappointing others\n",
    "\n",
    "- This can be highly damaging, and is a serious form of procrastination.\n",
    "- If you need to break a commitment, communicate this right away. \n",
    " - Can't get your work done on time.\n",
    " - Need to pull out of a project.\n",
    " - Need to move your organization to another city.\n",
    "- Consider how much better this is for the person being disappointed.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your opinion is not special\n",
    "\n",
    "- If you disagree with someone, why do you think you're more likely to be right than the other person?\n",
    "  - After all, there's a symmetry to the situation.\n",
    "- I think most people are in denial about this.\n",
    "  - That is, if you take an issue (e.g. \"will lowering taxes improve the economy?\", or religious beliefs), the credence of opposing sides are likely both above 50%. \n",
    "- A good question to ask yourself: is there data? E.g. if you are always on time and your co-worker is always late, then OK to trust your opinion on scheduling.\n",
    "- My approach:\n",
    "  - For critical decisions: try to \"average\" different opinions, including my own, based on trustworthiness.\n",
    "  - For most decisions: do it my way because life is more fun that way.\n",
    "  \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That's all, folks! Thank you for your active participation and supportive attitude."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
