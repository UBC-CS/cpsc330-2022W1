{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Lecture 11: Ensembles\n",
    "\n",
    "UBC 2020-21\n",
    "\n",
    "Instructor: Varada Kolhatkar\n",
    "\n",
    "<blockquote>\n",
    "The interests of truth require a diversity of opinions.    \n",
    "    \n",
    "by John Stuart Mill\n",
    "</blockquote>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, announcements, LOs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import string\n",
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"code/.\")\n",
    "\n",
    "from plotting_functions import *\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- HW4 deadline is extended. Due on Friday at 11:59pm.\n",
    "- HW5 will be released tomorrow. It'll be due Monday, October 31st. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Lecture learning objectives\n",
    "\n",
    "From this lecture, you will be able to \n",
    "\n",
    "- Use `scikit-learn`'s `RandomForestClassifier` and explain its main hyperparameters. \n",
    "- Explain randomness in random forest algorithm. \n",
    "- Use other tree-based models such as as `XGBoost` and `LGBM`.  \n",
    "- Employ ensemble classifier approaches, in particular model averaging and stacking.\n",
    "- Explain voting and stacking and the differences between them.\n",
    "- Use `scikit-learn` implementations of these ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ensembles** are models that combine multiple machine learning models to create more powerful models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Netflix prize\n",
    "\n",
    "![](img/netflix.png)\n",
    "\n",
    "[Source](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Most of the winning solutions for Kaggle competitions involve some kind of ensembling. For example: \n",
    "\n",
    "![](img/fraud_detection_kaggle.png)\n",
    "\n",
    "<!-- <img src=\"img/fraud_detection_kaggle.png\" width=\"600\" height=\"600\"> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Key idea: Groups can often make better decisions than individuals, especially when group members are diverse enough. \n",
    "\n",
    "[The Wisdom of Crowds](http://wisdomofcrowds.blogspot.com/2009/12/introduction-part-i.html)\n",
    "\n",
    "![](img/wisdom_of_crowds.jpg)\n",
    "\n",
    "<!-- <img src=\"img/wisdom_of_crowds.jpg\" width=\"300\" height=\"300\"> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tree-based ensemble models \n",
    "- A number of ensemble models in ML literature.\n",
    "- Most successful ones on a variety of datasets are tree-based models. \n",
    "- We'll briefly talk about two such models: \n",
    "    - Random forests\n",
    "    - Gradient boosted trees\n",
    "- We'll also talk about averaging and stacking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tree-based models \n",
    "\n",
    "- Decision trees models are \n",
    "    - Interpretable \n",
    "    - They can capture non-linear relationships\n",
    "    - They don't require scaling of the data and theoretically can work with categorical features. \n",
    "- But with a single decision trees are likely to overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Key idea: Combine multiple trees to build stronger models.\n",
    "- These kinds of models are extremely popular in industry and machine learning competitions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data\n",
    "\n",
    "- Let's work with [the adult census data set](https://www.kaggle.com/uciml/adult-census-income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>359131</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>7298</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6850</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78255</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>102771</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>145434</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23438</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>210945</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt   education  education.num      marital.status  \\\n",
       "2729    35   Private  359131   Bachelors             13  Married-civ-spouse   \n",
       "6850    40       NaN   78255     HS-grad              9            Divorced   \n",
       "414     46   Private  102771     Masters             14  Married-civ-spouse   \n",
       "7887    33   Private  145434        11th              7       Never-married   \n",
       "23438   28   Private  210945  Assoc-acdm             12  Married-civ-spouse   \n",
       "\n",
       "           occupation   relationship   race     sex  capital.gain  \\\n",
       "2729   Prof-specialty           Wife  White  Female          7298   \n",
       "6850              NaN  Not-in-family  White    Male             0   \n",
       "414      Tech-support        Husband  White    Male             0   \n",
       "7887     Craft-repair      Own-child  White    Male             0   \n",
       "23438    Adm-clerical           Wife  Black  Female             0   \n",
       "\n",
       "       capital.loss  hours.per.week native.country income  \n",
       "2729              0               8            NaN   >50K  \n",
       "6850              0              25  United-States  <=50K  \n",
       "414            1977              40  United-States   >50K  \n",
       "7887              0              40  United-States  <=50K  \n",
       "23438             0              35          Haiti  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df_large = pd.read_csv(\"data/adult.csv\")\n",
    "train_df, test_df = train_test_split(adult_df_large, test_size=0.6, random_state=42)\n",
    "train_df_nan = train_df.replace(\"?\", np.NaN)\n",
    "test_df_nan = test_df.replace(\"?\", np.NaN)\n",
    "train_df_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = [\"age\", \"fnlwgt\", \"capital.gain\", \"capital.loss\", \"hours.per.week\"]\n",
    "categorical_features = [\n",
    "    \"workclass\",\n",
    "    \"marital.status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"native.country\",\n",
    "]\n",
    "ordinal_features = [\"education\"]\n",
    "binary_features = [\"sex\"]\n",
    "drop_features = [\"race\", \"education.num\"]\n",
    "target_column = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "education_levels = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Prof-school\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Some-college\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Doctorate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert set(education_levels) == set(train_df[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "ordinal_transformer = make_pipeline(\n",
    "    OrdinalEncoder(categories=[education_levels], dtype=int)\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(drop=\"if_binary\", dtype=int),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(columns=[target_column])\n",
    "y_train = train_df_nan[target_column]\n",
    "\n",
    "X_test = test_df_nan.drop(columns=[target_column])\n",
    "y_test = test_df_nan[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Do we have class imbalance? \n",
    "\n",
    "- There is class imbalance. But without any context, both classes seem equally important. \n",
    "- Let's use accuracy as our metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    0.75906\n",
       ">50K     0.24094\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan[\"income\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "scoring_metric = \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's store all the results in a dictionary called `results`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `DummyClassifier` baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"stratified\")\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `DecisionTreeClassifier` baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Let's try decision tree classifier on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.003 (+/- 0.001)</td>\n",
       "      <td>0.002 (+/- 0.000)</td>\n",
       "      <td>0.640 (+/- 0.011)</td>\n",
       "      <td>0.633 (+/- 0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.066 (+/- 0.010)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>0.811 (+/- 0.002)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fit_time         score_time         test_score  \\\n",
       "Dummy          0.003 (+/- 0.001)  0.002 (+/- 0.000)  0.640 (+/- 0.011)   \n",
       "Decision tree  0.066 (+/- 0.010)  0.007 (+/- 0.000)  0.811 (+/- 0.002)   \n",
       "\n",
       "                     train_score  \n",
       "Dummy          0.633 (+/- 0.004)  \n",
       "Decision tree  1.000 (+/- 0.000)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=123))\n",
    "results[\"Decision tree\"] = mean_std_cross_val_scores(\n",
    "    pipe_dt, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree is clearly overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random forests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General idea\n",
    "\n",
    "- A single decision tree is likely to overfit\n",
    "- Use a collection of diverse decision trees\n",
    "- Each tree overfits on some part of the data but we can reduce overfitting by averaging the results \n",
    "    - can be shown mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `RandomForestClassifier` \n",
    "\n",
    "- Before understanding the details let's first try it out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.003 (+/- 0.001)</td>\n",
       "      <td>0.002 (+/- 0.000)</td>\n",
       "      <td>0.640 (+/- 0.011)</td>\n",
       "      <td>0.633 (+/- 0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.066 (+/- 0.010)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>0.811 (+/- 0.002)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forests</th>\n",
       "      <td>0.539 (+/- 0.321)</td>\n",
       "      <td>0.029 (+/- 0.002)</td>\n",
       "      <td>0.852 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fit_time         score_time         test_score  \\\n",
       "Dummy           0.003 (+/- 0.001)  0.002 (+/- 0.000)  0.640 (+/- 0.011)   \n",
       "Decision tree   0.066 (+/- 0.010)  0.007 (+/- 0.000)  0.811 (+/- 0.002)   \n",
       "Random forests  0.539 (+/- 0.321)  0.029 (+/- 0.002)  0.852 (+/- 0.004)   \n",
       "\n",
       "                      train_score  \n",
       "Dummy           0.633 (+/- 0.004)  \n",
       "Decision tree   1.000 (+/- 0.000)  \n",
       "Random forests  1.000 (+/- 0.000)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(random_state=123, n_jobs=-1)\n",
    ")\n",
    "results[\"Random forests\"] = mean_std_cross_val_scores(\n",
    "    pipe_rf, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The validation scores are better although it seems likes we are still overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do they work? \n",
    "\n",
    "- Decide how many decision trees we want to build\n",
    "    - can control with `n_estimators` hyperparameter \n",
    "- `fit` a diverse set of that many decision trees by **injecting randomness** in the classifier construction\n",
    "- `predict` by voting (classification) or averaging (regression) of predictions given by individual models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inject randomness in the classifier construction\n",
    "\n",
    "To ensure that the trees in the random forest are different we inject randomness in two ways:  \n",
    "\n",
    "1. Data: **Build each tree on a bootstrap sample** (i.e., a sample drawn **with replacement** from the training set)\n",
    "2. Features: **At each node, select a random subset of features** (controlled by `max_features` in `scikit-learn`) and look for the best possible test involving one of these features   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An example of a bootstrap samples\n",
    "Suppose this is your original dataset: [1,2,3,4]\n",
    "- a sample drawn with replacement: [1,1,3,4]\n",
    "- a sample drawn with replacement: [3,2,2,2]\n",
    "- a sample drawn with replacement: [1,2,4,4]\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{seealso}\n",
    "There is also something called [`ExtraTreesClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html), where we add more randomness by consider a random subset of features at each split and **random threshold**. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The random forests classifier \n",
    "\n",
    "- Create a collection (ensemble) of trees. Grow each tree on an independent bootstrap sample from the data.\n",
    "- At each node:\n",
    "    - Randomly select a subset of features out of all features (independently for each node).\n",
    "    - Find the best split on the selected features. \n",
    "    - Grow the trees to maximum depth.\n",
    "    \n",
    "- Prediction time    \n",
    "    - Vote the trees to get predictions for new example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example \n",
    "\n",
    "- Let's create a random forest with 3 estimators. \n",
    "- I'm using `max_depth=2` for easy visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pipe_rf_demo = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(max_depth=2, n_estimators=3, random_state=123)\n",
    ")\n",
    "pipe_rf_demo.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's get the feature names of transformed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'fnlwgt',\n",
       " 'capital.gain',\n",
       " 'capital.loss',\n",
       " 'hours.per.week',\n",
       " 'education',\n",
       " 'sex',\n",
       " 'x0_Federal-gov',\n",
       " 'x0_Local-gov',\n",
       " 'x0_Never-worked']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = (\n",
    "    numeric_features\n",
    "    + ordinal_features\n",
    "    + binary_features\n",
    "    + list(\n",
    "        pipe_rf_demo.named_steps[\"columntransformer\"]\n",
    "        .named_transformers_[\"pipeline-4\"]\n",
    "        .named_steps[\"onehotencoder\"]\n",
    "        .get_feature_names_out()\n",
    "    )\n",
    ")\n",
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's sample a test example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  ['<=50K' '>50K']\n",
      "Prediction by random forest:  ['<=50K']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-1.069147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>-0.009885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital.gain</th>\n",
       "      <td>-0.146334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital.loss</th>\n",
       "      <td>-0.216958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours.per.week</th>\n",
       "      <td>-0.042543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_Trinadad&amp;Tobago</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_United-States</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_Vietnam</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_Yugoslavia</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_missing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "age                -1.069147\n",
       "fnlwgt             -0.009885\n",
       "capital.gain       -0.146334\n",
       "capital.loss       -0.216958\n",
       "hours.per.week     -0.042543\n",
       "...                      ...\n",
       "x4_Trinadad&Tobago  0.000000\n",
       "x4_United-States    1.000000\n",
       "x4_Vietnam          0.000000\n",
       "x4_Yugoslavia       0.000000\n",
       "x4_missing          0.000000\n",
       "\n",
       "[86 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = X_test.sample(1)\n",
    "print(\"Classes: \", pipe_rf_demo.classes_)\n",
    "print(\"Prediction by random forest: \", pipe_rf_demo.predict(test_example))\n",
    "transformed_example = preprocessor.transform(test_example)\n",
    "pd.DataFrame(data=transformed_example.flatten(), index=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We can look at different trees created by random forest. \n",
    "- Note that each tree looks at different set of features and slightly different data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tree 1\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"638pt\" height=\"224pt\"\n",
       " viewBox=\"0.00 0.00 638.00 224.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 220)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-220 634,-220 634,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"415.5,-216 218.5,-216 218.5,-163 415.5,-163 415.5,-216\"/>\n",
       "<text text-anchor=\"middle\" x=\"317\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x1_Married&#45;civ&#45;spouse &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"317\" y=\"-185.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [9951, 3073]</text>\n",
       "<text text-anchor=\"middle\" x=\"317\" y=\"-170.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"304,-127 136,-127 136,-74 304,-74 304,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x1_Never&#45;married &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [6570, 384]</text>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-81.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.42,-162.87C278.35,-153.83 266.89,-143.55 256.26,-134.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"258.49,-131.32 248.71,-127.25 253.82,-136.53 258.49,-131.32\"/>\n",
       "<text text-anchor=\"middle\" x=\"250.07\" y=\"-148.51\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"505.5,-127 322.5,-127 322.5,-74 505.5,-74 505.5,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"414\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x2_Exec&#45;managerial &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"414\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [3381, 2689]</text>\n",
       "<text text-anchor=\"middle\" x=\"414\" y=\"-81.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M345.58,-162.87C355.65,-153.83 367.11,-143.55 377.74,-134.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"380.18,-136.53 385.29,-127.25 375.51,-131.32 380.18,-136.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"383.93\" y=\"-148.51\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-38 0,-38 0,0 140,0 140,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [2582, 257]</text>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.71,-73.91C152.96,-63.97 131.64,-52.67 113.38,-42.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"114.89,-39.83 104.41,-38.24 111.61,-46.01 114.89,-39.83\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"298,-38 158,-38 158,0 298,0 298,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [3988, 127]</text>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.58,-73.91C223.4,-65.74 224.31,-56.65 225.15,-48.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.65,-48.54 226.16,-38.24 221.68,-47.84 228.65,-48.54\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"479.5,-38 332.5,-38 332.5,0 479.5,0 479.5,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"406\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [3053, 2000]</text>\n",
       "<text text-anchor=\"middle\" x=\"406\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M411.42,-73.91C410.6,-65.74 409.69,-56.65 408.85,-48.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"412.32,-47.84 407.84,-38.24 405.35,-48.54 412.32,-47.84\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"630,-38 498,-38 498,0 630,0 630,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"564\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [328, 689]</text>\n",
       "<text text-anchor=\"middle\" x=\"564\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462.29,-73.91C481.04,-63.97 502.36,-52.67 520.62,-42.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"522.39,-46.01 529.59,-38.24 519.11,-39.83 522.39,-46.01\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x14af4d990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [0.]\n",
      "\n",
      "\n",
      "Tree 2\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"616pt\" height=\"224pt\"\n",
       " viewBox=\"0.00 0.00 615.50 224.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 220)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-220 611.5,-220 611.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"374,-216 227,-216 227,-163 374,-163 374,-216\"/>\n",
       "<text text-anchor=\"middle\" x=\"300.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">education &lt;= 12.5</text>\n",
       "<text text-anchor=\"middle\" x=\"300.5\" y=\"-185.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [9841, 3183]</text>\n",
       "<text text-anchor=\"middle\" x=\"300.5\" y=\"-170.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"292,-127 145,-127 145,-74 292,-74 292,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"218.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x1_Separated &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"218.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [8247, 1746]</text>\n",
       "<text text-anchor=\"middle\" x=\"218.5\" y=\"-81.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.34,-162.87C267.99,-154.01 258.51,-143.95 249.68,-134.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252.18,-132.13 242.77,-127.25 247.08,-136.93 252.18,-132.13\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.03\" y=\"-148.54\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"457,-127 310,-127 310,-74 457,-74 457,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x3_Husband &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [1594, 1437]</text>\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-81.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M324.95,-162.87C333.41,-154.01 343,-143.95 351.94,-134.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"354.56,-136.9 358.93,-127.25 349.5,-132.07 354.56,-136.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"359.52\" y=\"-148.54\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"147,-38 0,-38 0,0 147,0 147,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [7895, 1738]</text>\n",
       "<text text-anchor=\"middle\" x=\"73.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.82,-73.91C153.77,-64.01 133.27,-52.77 115.67,-43.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.22,-39.98 106.77,-38.24 113.85,-46.12 117.22,-39.98\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"282,-38 165,-38 165,0 282,0 282,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [352, 8]</text>\n",
       "<text text-anchor=\"middle\" x=\"223.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M220.11,-73.91C220.62,-65.74 221.2,-56.65 221.72,-48.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.22,-48.44 222.35,-38.24 218.23,-48 225.22,-48.44\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"449.5,-38 309.5,-38 309.5,0 449.5,0 449.5,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"379.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [1191, 378]</text>\n",
       "<text text-anchor=\"middle\" x=\"379.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M382.21,-73.91C381.8,-65.74 381.34,-56.65 380.92,-48.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"384.42,-48.05 380.42,-38.24 377.42,-48.4 384.42,-48.05\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"607.5,-38 467.5,-38 467.5,0 607.5,0 607.5,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"537.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [403, 1059]</text>\n",
       "<text text-anchor=\"middle\" x=\"537.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M433.07,-73.91C452.42,-63.92 474.42,-52.56 493.22,-42.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"494.89,-45.94 502.17,-38.24 491.68,-39.72 494.89,-45.94\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x106262cb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [0.]\n",
      "\n",
      "\n",
      "Tree 3\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"631pt\" height=\"224pt\"\n",
       " viewBox=\"0.00 0.00 631.00 224.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 220)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-220 627,-220 627,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"400,-216 232,-216 232,-163 400,-163 400,-216\"/>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x1_Never&#45;married &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-185.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [9890, 3134]</text>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-170.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"321.5,-127 124.5,-127 124.5,-74 321.5,-74 321.5,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"223\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x1_Married&#45;civ&#45;spouse &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"223\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [5928, 2976]</text>\n",
       "<text text-anchor=\"middle\" x=\"223\" y=\"-81.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.6,-162.87C279.04,-153.92 268.17,-143.75 258.07,-134.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"260.22,-131.53 250.53,-127.25 255.44,-136.64 260.22,-131.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.36\" y=\"-148.54\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"480,-127 340,-127 340,-74 480,-74 480,-127\"/>\n",
       "<text text-anchor=\"middle\" x=\"410\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x0_Private &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"410\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [3962, 158]</text>\n",
       "<text text-anchor=\"middle\" x=\"410\" y=\"-81.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M343.69,-162.87C353.36,-153.92 364.35,-143.75 374.56,-134.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"377.22,-136.61 382.18,-127.25 372.46,-131.47 377.22,-136.61\"/>\n",
       "<text text-anchor=\"middle\" x=\"381.21\" y=\"-148.53\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140,-38 0,-38 0,0 140,0 140,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [2509, 239]</text>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M173.75,-73.91C154.53,-63.92 132.67,-52.56 113.99,-42.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.59,-39.74 105.1,-38.24 112.36,-45.96 115.59,-39.74\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"305.5,-38 158.5,-38 158.5,0 305.5,0 305.5,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"232\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [3419, 2737]</text>\n",
       "<text text-anchor=\"middle\" x=\"232\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M225.9,-73.91C226.82,-65.74 227.85,-56.65 228.8,-48.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"232.29,-48.57 229.94,-38.24 225.33,-47.78 232.29,-48.57\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"464.5,-38 339.5,-38 339.5,0 464.5,0 464.5,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"402\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [908, 52]</text>\n",
       "<text text-anchor=\"middle\" x=\"402\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M407.42,-73.91C406.6,-65.74 405.69,-56.65 404.85,-48.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"408.32,-47.84 403.84,-38.24 401.35,-48.54 408.32,-47.84\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"623,-38 483,-38 483,0 623,0 623,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"553\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">counts = [3054, 106]</text>\n",
       "<text text-anchor=\"middle\" x=\"553\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M456.03,-73.91C473.83,-64.01 494.05,-52.77 511.41,-43.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"513.15,-46.16 520.19,-38.24 509.75,-40.04 513.15,-46.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x14af4dd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [0.]\n"
     ]
    }
   ],
   "source": [
    "for i, tree in enumerate(\n",
    "    pipe_rf_demo.named_steps[\"randomforestclassifier\"].estimators_\n",
    "):\n",
    "    print(\"\\n\\nTree\", i + 1)\n",
    "    display(display_tree(feature_names, tree, counts=True))\n",
    "    print(\"prediction\", tree.predict(preprocessor.transform(test_example)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some important hyperparameters:\n",
    "\n",
    "- `n_estimators`: number of decision trees (higher = more complexity)\n",
    "- `max_depth`: max depth of each decision tree (higher = more complexity)\n",
    "- `max_features`: the number of features you get to look at each split (higher = more complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Random forests: number of trees (`n_estimators`) and the fundamental tradeoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_num_tree_plot(\n",
    "    preprocessor, X_train, y_train, X_test, y_test, [1, 5, 10, 25, 50, 100, 200, 500]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Number of trees and fundamental trade-off\n",
    "\n",
    "- Above: seems like we're beating the fundamental \"tradeoff\" by increasing training score and not decreasing validation score much.\n",
    "- This is the promise of ensembles, though it's not guaranteed to work so nicely.\n",
    "\n",
    "More trees are always better! We pick less trees for speed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Strengths and weaknesses\n",
    "\n",
    "- Usually one of the best performing off-the-shelf classifiers without heavy tuning of hyperparameters\n",
    "- Don't require scaling of data \n",
    "- Less likely to overfit \n",
    "- Slower than decision trees because we are fitting multiple trees but can easily parallelize training because all trees are independent of each other (that said, sklearn implementation is kind of slow)\n",
    "- In general, able to capture a much broader picture of the data compared to a single decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Weaknesses\n",
    "\n",
    "- Require more memory \n",
    "- Hard to interpret\n",
    "- Tend not to perform well on high dimensional sparse data such as text data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{important}\n",
    "Make sure to set the `random_state` for reproducibility. Changing the `random_state` can have a big impact on the model and the results due to the random nature of these models. Having more trees can get you a more robust estimate. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{seealso}\n",
    "[The original random forests paper](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf) by Leo Breiman. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## â“â“ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (iClicker) Exercise 11.1 \n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/3DP5H**\n",
    "\n",
    "**Select all of the following statements which are TRUE.**\n",
    "\n",
    "- (A) Every tree in a random forest uses a different bootstrap sample of the training set.\n",
    "- (B) To train a tree in a random forest, we first randomly select a subset of features. The tree is then restricted to only using those features.\n",
    "- (C) A reasonable implementation of `predict_proba` for random forests would be for each tree to \"vote\" and then normalize these vote counts into probabilities.\n",
    "- (D) Increasing the hyperparameter max_features (the number of features to consider for a split) makes the model more complex and moves the fundamental tradeoff toward lower training error. \n",
    "- (E) A random forest with only one tree is likely to get a higher training error than a decision tree of the same depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How would you carry out \"soft voting\" with `predict_proba` output instead of hard voting for random forests? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient boosted trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another popular and effective class of tree-based models is gradient boosted trees. \n",
    "\n",
    "- No randomization.\n",
    "- The key idea is combining many simple models called weak learners to create a strong learner. \n",
    "- They combine multiple shallow (depth 1 to 5) decision trees  \n",
    "- They build trees in a serial manner, where each tree tries to correct the mistakes of the previous one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important hyperparameters\n",
    "\n",
    "- `n_estimators`\n",
    "    - control the number of trees to build\n",
    "- `learning_rate`\n",
    "    - controls how strongly each tree tries to correct the mistakes of the previous trees\n",
    "    - higher learning rate means each tree can make stronger corrections, which means more complex model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll not go into the details. We'll look at brief examples of using the following three gradient boosted tree models. \n",
    "\n",
    "- [XGBoost](https://xgboost.readthedocs.io/en/latest/)\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)\n",
    "- [CatBoost](https://catboost.ai/docs/concepts/python-quickstart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [XGBoost](https://xgboost.ai/about) \n",
    "\n",
    "- Not part of `sklearn` but has similar interface. \n",
    "- Install it in your conda environment: `conda install -c conda-forge xgboost`\n",
    "- Supports missing values\n",
    "- GPU training, networked parallel training\n",
    "- Supports sparse data\n",
    "- Typically better scores than random forests    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [LightGBM](https://lightgbm.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not part of `sklearn` but has similar interface. \n",
    "- Install it in your conda environment: `conda install -c conda-forge lightgbm`\n",
    "- Small model size\n",
    "- Faster \n",
    "- Typically better scores than random forests    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [CatBoost](https://catboost.ai/)\n",
    "\n",
    "- Not part of `sklearn` but has similar interface. \n",
    "- Install it in your conda environment: `conda install -c conda-forge catboost`\n",
    "- Usually better scores but slower compared to `XGBoost` and `LightGBM`     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvarada/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe_lr = make_pipeline(\n",
    "    preprocessor, LogisticRegression(max_iter=2000, random_state=123)\n",
    ")\n",
    "pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=123))\n",
    "pipe_rf = make_pipeline(preprocessor, RandomForestClassifier(random_state=123))\n",
    "# pipe_xgb = make_pipeline(\n",
    "#     preprocessor, XGBClassifier(random_state=123, eval_metric=\"logloss\", verbosity=0)\n",
    "# )\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMClassifier(random_state=123))\n",
    "pipe_catboost = make_pipeline(\n",
    "    preprocessor, CatBoostClassifier(verbose=0, random_state=123)\n",
    ")\n",
    "classifiers = {\n",
    "    \"logistic regression\": pipe_lr,\n",
    "    \"decision tree\": pipe_dt,\n",
    "    \"random forest\": pipe_rf,\n",
    "    #\"XGBoost\": pipe_xgb,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_catboost,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"stratified\")\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for (name, model) in classifiers.items():\n",
    "    results[name] = mean_std_cross_val_scores(\n",
    "        model, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.004 (+/- 0.002)</td>\n",
       "      <td>0.003 (+/- 0.001)</td>\n",
       "      <td>0.632 (+/- 0.010)</td>\n",
       "      <td>0.636 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.388 (+/- 0.038)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>0.849 (+/- 0.004)</td>\n",
       "      <td>0.851 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.065 (+/- 0.003)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>0.811 (+/- 0.002)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.549 (+/- 0.035)</td>\n",
       "      <td>0.037 (+/- 0.001)</td>\n",
       "      <td>0.852 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.113 (+/- 0.007)</td>\n",
       "      <td>0.012 (+/- 0.001)</td>\n",
       "      <td>0.868 (+/- 0.003)</td>\n",
       "      <td>0.907 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>2.832 (+/- 0.052)</td>\n",
       "      <td>0.039 (+/- 0.001)</td>\n",
       "      <td>0.870 (+/- 0.001)</td>\n",
       "      <td>0.906 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fit_time         score_time         test_score  \\\n",
       "Dummy                0.004 (+/- 0.002)  0.003 (+/- 0.001)  0.632 (+/- 0.010)   \n",
       "logistic regression  0.388 (+/- 0.038)  0.007 (+/- 0.000)  0.849 (+/- 0.004)   \n",
       "decision tree        0.065 (+/- 0.003)  0.007 (+/- 0.000)  0.811 (+/- 0.002)   \n",
       "random forest        0.549 (+/- 0.035)  0.037 (+/- 0.001)  0.852 (+/- 0.004)   \n",
       "LightGBM             0.113 (+/- 0.007)  0.012 (+/- 0.001)  0.868 (+/- 0.003)   \n",
       "CatBoost             2.832 (+/- 0.052)  0.039 (+/- 0.001)  0.870 (+/- 0.001)   \n",
       "\n",
       "                           train_score  \n",
       "Dummy                0.636 (+/- 0.003)  \n",
       "logistic regression  0.851 (+/- 0.001)  \n",
       "decision tree        1.000 (+/- 0.000)  \n",
       "random forest        1.000 (+/- 0.000)  \n",
       "LightGBM             0.907 (+/- 0.002)  \n",
       "CatBoost             0.906 (+/- 0.001)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Some observations**\n",
    "- Keep in mind that all these results are with default hyperparameters\n",
    "- Ideally we would carry out hyperparameter optimization for all of them and then compare the results. \n",
    "- We are using a particular scoring metric (accuracy in this case)\n",
    "- We are scaling numeric features but it shouldn't matter for these tree-based models. \n",
    "- Look at the std. Doesn't look very high. \n",
    "    - The scores look more or less stable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.004 (+/- 0.002)</td>\n",
       "      <td>0.003 (+/- 0.001)</td>\n",
       "      <td>0.632 (+/- 0.010)</td>\n",
       "      <td>0.636 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.388 (+/- 0.038)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>0.849 (+/- 0.004)</td>\n",
       "      <td>0.851 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.065 (+/- 0.003)</td>\n",
       "      <td>0.007 (+/- 0.000)</td>\n",
       "      <td>0.811 (+/- 0.002)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.549 (+/- 0.035)</td>\n",
       "      <td>0.037 (+/- 0.001)</td>\n",
       "      <td>0.852 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.113 (+/- 0.007)</td>\n",
       "      <td>0.012 (+/- 0.001)</td>\n",
       "      <td>0.868 (+/- 0.003)</td>\n",
       "      <td>0.907 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>2.832 (+/- 0.052)</td>\n",
       "      <td>0.039 (+/- 0.001)</td>\n",
       "      <td>0.870 (+/- 0.001)</td>\n",
       "      <td>0.906 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fit_time         score_time         test_score  \\\n",
       "Dummy                0.004 (+/- 0.002)  0.003 (+/- 0.001)  0.632 (+/- 0.010)   \n",
       "logistic regression  0.388 (+/- 0.038)  0.007 (+/- 0.000)  0.849 (+/- 0.004)   \n",
       "decision tree        0.065 (+/- 0.003)  0.007 (+/- 0.000)  0.811 (+/- 0.002)   \n",
       "random forest        0.549 (+/- 0.035)  0.037 (+/- 0.001)  0.852 (+/- 0.004)   \n",
       "LightGBM             0.113 (+/- 0.007)  0.012 (+/- 0.001)  0.868 (+/- 0.003)   \n",
       "CatBoost             2.832 (+/- 0.052)  0.039 (+/- 0.001)  0.870 (+/- 0.001)   \n",
       "\n",
       "                           train_score  \n",
       "Dummy                0.636 (+/- 0.003)  \n",
       "logistic regression  0.851 (+/- 0.001)  \n",
       "decision tree        1.000 (+/- 0.000)  \n",
       "random forest        1.000 (+/- 0.000)  \n",
       "LightGBM             0.907 (+/- 0.002)  \n",
       "CatBoost             0.906 (+/- 0.001)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Decision trees and random forests overfit\n",
    "    - Other models do not seem to overfit much. \n",
    "- Fit times\n",
    "    - Decision trees are fast but not very accurate\n",
    "    - LightGBM is faster than decision trees and more accurate! \n",
    "    - CatBoost fit time is highest followed by random forests.  \n",
    "    - There is not much difference between the validation scores of XGBoost, LightGBM, and CatBoost but it is about 48x slower than LightGBM!\n",
    "    - XGBoost and LightGBM are faster and more accurate than random forest!    \n",
    "- Scores times  \n",
    "    - Prediction times are much smaller in all cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What classifier should I use?\n",
    "\n",
    "**Simple answer**\n",
    "- Whichever gets the highest CV score making sure that you're not overusing the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Interpretability**\n",
    "- This is an area of growing interest and concern in ML.\n",
    "- How important is interpretability for you? \n",
    "- In the next class we'll talk about interpretability of non-linear models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Speed/code maintenance**\n",
    "- Other considerations could be speed (fit and/or predict), maintainability of the code.\n",
    "\n",
    "Finally, you could use all of them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Averaging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Earlier we looked at a bunch of classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use all these models and let them vote during prediction time? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "averaging_model = VotingClassifier(\n",
    "    list(classifiers.items()), voting=\"soft\"\n",
    ")  # need the list() here for cross_val to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")  # global setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "averaging_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `VotingClassifier` will take a _vote_ using the predictions of the constituent classifier pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Main parameter: `voting`\n",
    "- `voting='hard'` \n",
    "    - it uses the output of `predict` and actually votes.\n",
    "- `voting='soft'`\n",
    "    - with `voting='soft'` it averages the output of `predict_proba` and then thresholds / takes the larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The choice depends on whether you trust `predict_proba` from your base classifiers - if so, it's nice to access that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "averaging_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What happens when you `fit` a `VotingClassifier`?\n",
    "    - It will fit all constituent models.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "It seems sklearn requires us to actually call `fit` on the `VotingClassifier`, instead of passing in pre-fit models. This is an implementation choice rather than a conceptual limitation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at particular test examples where `income` is \">50k\" (y=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g50k = (\n",
    "    test_df.query(\"income == '>50K'\").sample(4, random_state=2).drop(columns=[\"income\"])\n",
    ")\n",
    "test_l50k = (\n",
    "    test_df.query(\"income == '<=50K'\")\n",
    "    .sample(4, random_state=2)\n",
    "    .drop(columns=[\"income\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = {\"Voting classifier\": averaging_model.predict(test_l50k)}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For hard voting, these are the votes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "r1 = {\n",
    "    name: classifier.predict(test_l50k)\n",
    "    for name, classifier in averaging_model.named_estimators_.items()\n",
    "}\n",
    "data.update(r1)\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For soft voting, these are the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = {\n",
    "    name: classifier.predict_proba(test_l50k)\n",
    "    for name, classifier in averaging_model.named_estimators_.items()\n",
    "}\n",
    "r1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Aside: the probability scores from `DecisionTreeClassifier` are pretty bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "results[\"Voting\"] = mean_std_cross_val_scores(averaging_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that here we didn't do much better than our best classifier :(. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try removing decision tree classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_ndt = classifiers.copy()\n",
    "del classifiers_ndt[\"decision tree\"]\n",
    "averaging_model_ndt = VotingClassifier(\n",
    "    list(classifiers_ndt.items()), voting=\"soft\"\n",
    ")  # need the list() here for cross_val to work!\n",
    "\n",
    "results[\"Voting_ndt\"] = mean_std_cross_val_scores(\n",
    "    averaging_model_ndt,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    return_train_score=True,\n",
    "    scoring=scoring_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still the results are not better than the best performing model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- It didn't happen here but how could the average do better than the best model???\n",
    "  - From the perspective of the best estimator (in this case CatBoost), why are you adding on worse estimators??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's how this can work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Example | log reg    | rand forest    | cat boost    | Averaged model |\n",
    "|--------|--------|--------|---------|---------------|\n",
    "|  1     | âœ…    |   âœ…    | âŒ     | âœ…âœ…âŒ=>âœ…  |\n",
    "|  2     | âœ…    |   âŒ    | âœ…     | âœ…âŒâœ…=>âœ…  |\n",
    "|  3     | âŒ    |   âœ…    | âœ…     | âŒâœ…âœ…=>âœ…  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, as long as the different models make different mistakes, this can work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why not always do this?\n",
    "\n",
    "1. `fit`/`predict` time.\n",
    "2. Reduction in interpretability.\n",
    "3. Reduction in code maintainability (e.g. Netflix prize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What kind of estimators can we combine? \n",
    "\n",
    "- You can combine \n",
    "    - completely different estimators, or similar estimators.\n",
    "    - estimators trained on different samples.\n",
    "    - estimators with different hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- Another type of ensemble is stacking.\n",
    "- Instead of averaging the outputs of each estimator, instead use their outputs as _inputs to another model_.\n",
    "- By default for classification, it uses logistic regression.\n",
    "  - We don't need a complex model here necessarily, more of a weighted average.\n",
    "  - The features going into the logistic regression are the classifier outputs, _not_ the original features!\n",
    "  - So the number of coefficients = the number of base estimators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code starts to get too slow here; so we'll remove CatBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_nocat = classifiers.copy()\n",
    "del classifiers_nocat[\"CatBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingClassifier(list(classifiers_nocat.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacking_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What's going on in here? \n",
    "\n",
    "- It is doing cross-validation by itself by default (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html))\n",
    "  - It is fitting the base estimators on the training fold\n",
    "  - And the predicting on the validation fold\n",
    "  - And then fitting the meta-estimator on that output (on the validation fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " > Note that estimators_ are fitted on the full X while final_estimator_ is trained using cross-validated predictions of the base estimators using cross_val_predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is the input features (X) to the meta-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sample = train_df.sample(4, random_state=2).drop(columns=[\"income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = {\n",
    "    name: pipe.predict_proba(valid_sample)\n",
    "    for (name, pipe) in stacking_model.named_estimators_.items()\n",
    "}\n",
    "r3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Our meta-model is logistic regression (which it is by default).\n",
    "- Let's look at the learned coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=stacking_model.final_estimator_.coef_[0],\n",
    "    index=classifiers_nocat.keys(),\n",
    "    columns=[\"Coefficient\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model.final_estimator_.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It seems that the LightGBM is being trusted the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacking_model.predict(test_g50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model.predict_proba(test_g50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This is the `predict_proba` from logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "results[\"Stacking_nocat\"] = mean_std_cross_val_scores(\n",
    "    stacking_model, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The situation here is a bit mind-boggling.\n",
    "- On each fold of cross-validation it is doing cross-validation.\n",
    "- This is really loops within loops within loops within loops..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We can also try a different final estimator:\n",
    "- Let's `DecisionTreeClassifier` as a final estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "stacking_model_tree = StackingClassifier(\n",
    "    list(classifiers_nocat.items()), final_estimator=DecisionTreeClassifier(max_depth=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not very good. But we can look at the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacking_model_tree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "display_tree(list(classifiers_nocat.keys()), stacking_model_tree.final_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### An effective strategy\n",
    "\n",
    "- Randomly generate a bunch of models with different hyperparameter configurations, and then stack all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What is an advantage of ensembling multiple models as opposed to just choosing one of them?\n",
    "    - You may get a better score.\n",
    "- What is an disadvantage of ensembling multiple models as opposed to just choosing one of them?\n",
    "    - Slower, more code maintenance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "\n",
    "- You have a number of models in your toolbox now.  \n",
    "- Ensembles are usually pretty effective.\n",
    "  - Tree-based classifiers are particularly popular and effective on a wide range of problems. \n",
    "  - But they trade off code complexity and speed for prediction accuracy.\n",
    "  - Don't forget that hyperparameter optimization multiplies the slowness of the code!\n",
    "- Stacking is a bit slower than voting, but generally higher accuracy.\n",
    "  - As a bonus, you get to see the coefficients for each base classifier.\n",
    "- All the above models have equivalent regression models.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Relevant papers\n",
    "\n",
    "- [Fernandez-Delgado et al. 2014](http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf) compared 179 classifiers on 121 datasets:\n",
    "    - First best class of methods was Random Forest and second best class of methods was (RBF) SVMs.\n",
    "\n",
    "- If you like to read original papers [here](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf) is the original paper on Random Forests by Leo Breiman. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
