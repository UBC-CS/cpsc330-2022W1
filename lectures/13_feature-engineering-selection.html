
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Lecture 13: Feature engineering and feature selection &#8212; CPSC 330 Applied Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Attributions" href="../attribution.html" />
    <link rel="prev" title="Lecture 12: Feature importances" href="12_feat-importances.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/UBC-CS-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">CPSC 330 Applied Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Things you should know
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../docs/README.html">
   CPSC 330 Documents
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_intro.html">
   Lecture 1: Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_decision-trees.html">
   Lecture 2: Terminology, Baselines, Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_ml-fundamentals.html">
   Lecture 3: Machine Learning Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_kNNs-SVM-RBF.html">
   Lecture 4:
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Nearest Neighbours and SVM RBFs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_preprocessing-pipelines.html">
   Lecture 5: Preprocessing and
   <code class="docutils literal notranslate">
    <span class="pre">
     sklearn
    </span>
   </code>
   pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_column-transformer-text-feats.html">
   Lecture 6:
   <code class="docutils literal notranslate">
    <span class="pre">
     sklearn
    </span>
   </code>
   <code class="docutils literal notranslate">
    <span class="pre">
     ColumnTransformer
    </span>
   </code>
   and Text Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_linear-models.html">
   Lecture 7: Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_hyperparameter-optimization.html">
   Lecture 8: Hyperparameter Optimization and Optimization Bias
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_classification-metrics.html">
   Lecture 9: Classification Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_regression-metrics.html">
   Lecture 10: Regression Evaluation Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_ensembles.html">
   Lecture 11: Ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12_feat-importances.html">
   Lecture 12: Feature importances
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Lecture 13: Feature engineering and feature selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Attribution
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../attribution.html">
   Attributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../LICENSE.html">
   LICENSE
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Varada Kolhatkar, CPSC 330 2022-23<br>Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/UBC-CS/cpsc330/master?urlpath=tree/lectures/13_feature-engineering-selection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/lectures/13_feature-engineering-selection.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-outcomes">
   Learning outcomes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-engineering-motivation">
   Feature engineering: Motivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-feature-engineering">
     What is feature engineering?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-quotes-on-feature-engineering">
     Some quotes on feature engineering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#better-features-usually-help-more-than-a-better-model">
     Better features usually help more than a better model.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-best-features-may-be-dependent-on-the-model-you-use">
     The best features may be dependent on the model you use.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#domain-specific-transformations">
       Domain-specific transformations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-engineering-for-text-data">
   Feature engineering for text data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dummy-classifier">
     Dummy classifier
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words-model">
     Bag-of-words model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#is-it-possible-to-further-improve-the-scores">
     Is it possible to further improve the scores?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spacy">
     spaCy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#an-example-from-a-project">
     An example from a project
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-feature-engineering-for-our-problem">
   Simple feature engineering for our problem.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-features-used-in-text-classification">
   Common features used in text classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words">
     Bag of words
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-label-personalized-important-e-mails">
     Example: Label “Personalized” Important E-mails:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-learning-behind-gmail-priority-inbox">
     The Learning Behind Gmail Priority Inbox
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#feature-engineering-examples-automatically-identifying-good-conversations-online">
       Feature engineering examples: Automatically Identifying Good Conversations Online
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-term-weighing-tf-idf">
     (Optional) Term weighing (TF-IDF)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-grams">
     N-grams
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aside-google-n-gram-viewer">
     ASIDE: Google n-gram viewer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Aside: Google n-gram viewer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Aside: Google n-gram viewer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#part-of-speech-features">
     Part-of-speech features
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#part-of-speech-pos-in-english">
       Part-of-speech (POS) in English
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#part-of-speech-pos-features">
     Part-of-speech (POS) features
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     An example from a project
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#penn-treebank-part-of-speech-tags-bonus">
     Penn Treebank part-of-speech tags (bonus)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interim-summary">
     Interim summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-engineering">
     Feature engineering
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#break-5-min">
   Break (5 min)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection-introduction-and-motivation">
   Feature selection: Introduction and motivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-feature-selection">
     What is feature selection?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-feature-selection">
     Why feature selection?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-carry-out-feature-selection">
     How do we carry out feature selection?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-based-selection">
     Model-based selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recursive-feature-elimination-rfe">
     Recursive feature elimination (RFE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rfe-algorithm">
     RFE algorithm
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-and-score">
     Search and score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-idea-of-search-and-score-methods">
     General idea of search and score methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#forward-or-backward-selection">
     Forward or backward selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-ways-to-search">
     Other ways to search
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#warnings-about-feature-selection">
     Warnings about feature selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iclicker-exercise-13-1">
     (iClicker) Exercise 13.1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-problems-with-feature-selection">
     (Optional) Problems with feature selection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-is-relevance-clearly-defined">
       Example: Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#is-relevance-clearly-defined">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       Warnings about feature selection
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#general-advice-on-finding-relevant-features">
       General advice on finding relevant features
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#relevant-resources">
       Relevant resources
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Lecture 13: Feature engineering and feature selection</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-outcomes">
   Learning outcomes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-engineering-motivation">
   Feature engineering: Motivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-feature-engineering">
     What is feature engineering?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-quotes-on-feature-engineering">
     Some quotes on feature engineering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#better-features-usually-help-more-than-a-better-model">
     Better features usually help more than a better model.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-best-features-may-be-dependent-on-the-model-you-use">
     The best features may be dependent on the model you use.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#domain-specific-transformations">
       Domain-specific transformations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-engineering-for-text-data">
   Feature engineering for text data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dummy-classifier">
     Dummy classifier
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words-model">
     Bag-of-words model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#is-it-possible-to-further-improve-the-scores">
     Is it possible to further improve the scores?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spacy">
     spaCy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#an-example-from-a-project">
     An example from a project
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-feature-engineering-for-our-problem">
   Simple feature engineering for our problem.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-features-used-in-text-classification">
   Common features used in text classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words">
     Bag of words
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-label-personalized-important-e-mails">
     Example: Label “Personalized” Important E-mails:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-learning-behind-gmail-priority-inbox">
     The Learning Behind Gmail Priority Inbox
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#feature-engineering-examples-automatically-identifying-good-conversations-online">
       Feature engineering examples: Automatically Identifying Good Conversations Online
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-term-weighing-tf-idf">
     (Optional) Term weighing (TF-IDF)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#n-grams">
     N-grams
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aside-google-n-gram-viewer">
     ASIDE: Google n-gram viewer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Aside: Google n-gram viewer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Aside: Google n-gram viewer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#part-of-speech-features">
     Part-of-speech features
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#part-of-speech-pos-in-english">
       Part-of-speech (POS) in English
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#part-of-speech-pos-features">
     Part-of-speech (POS) features
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     An example from a project
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#penn-treebank-part-of-speech-tags-bonus">
     Penn Treebank part-of-speech tags (bonus)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interim-summary">
     Interim summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feature-engineering">
     Feature engineering
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#break-5-min">
   Break (5 min)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection-introduction-and-motivation">
   Feature selection: Introduction and motivation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-feature-selection">
     What is feature selection?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-feature-selection">
     Why feature selection?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-carry-out-feature-selection">
     How do we carry out feature selection?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-based-selection">
     Model-based selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recursive-feature-elimination-rfe">
     Recursive feature elimination (RFE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rfe-algorithm">
     RFE algorithm
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#search-and-score">
     Search and score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-idea-of-search-and-score-methods">
     General idea of search and score methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#forward-or-backward-selection">
     Forward or backward selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-ways-to-search">
     Other ways to search
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#warnings-about-feature-selection">
     Warnings about feature selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iclicker-exercise-13-1">
     (iClicker) Exercise 13.1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-problems-with-feature-selection">
     (Optional) Problems with feature selection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-is-relevance-clearly-defined">
       Example: Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#is-relevance-clearly-defined">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       Is “Relevance” clearly defined?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       Warnings about feature selection
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#general-advice-on-finding-relevant-features">
       General advice on finding relevant features
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#relevant-resources">
       Relevant resources
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><img alt="" src="../_images/330-banner.png" /></p>
<section class="tex2jax_ignore mathjax_ignore" id="lecture-13-feature-engineering-and-feature-selection">
<h1>Lecture 13: Feature engineering and feature selection<a class="headerlink" href="#lecture-13-feature-engineering-and-feature-selection" title="Permalink to this headline">#</a></h1>
<p>UBC 2022-23</p>
<p>Instructor: Varada Kolhatkar</p>
<section id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ColumnTransformer</span><span class="p">,</span>
    <span class="n">TransformedTargetRegressor</span><span class="p">,</span>
    <span class="n">make_column_transformer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span><span class="p">,</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">RidgeCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">OrdinalEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="learning-outcomes">
<h2>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Permalink to this headline">#</a></h2>
<p>From this lecture, students are expected to be able to:</p>
<ul class="simple">
<li><p>Explain what feature engineering is and the importance of feature engineering in building machine learning models.</p></li>
<li><p>Carry out preliminary feature engineering on text data.</p></li>
<li><p>Explain the general concept of feature selection.</p></li>
<li><p>Discuss and compare different feature selection methods at a high level.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s implementation of recursive feature elimination (<code class="docutils literal notranslate"><span class="pre">RFE</span></code>) and forward and backward selection (<code class="docutils literal notranslate"><span class="pre">SequentialFeatureSelector</span></code>).</p></li>
</ul>
</section>
<section id="feature-engineering-motivation">
<h2>Feature engineering: Motivation<a class="headerlink" href="#feature-engineering-motivation" title="Permalink to this headline">#</a></h2>
<section id="what-is-feature-engineering">
<h3>What is feature engineering?<a class="headerlink" href="#what-is-feature-engineering" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Better features: more flexibility, higher score, we can get by with simple and more interpretable models.</p></li>
<li><p>If your features, i.e., representation is bad, whatever fancier model you build is not going to help.</p></li>
</ul>
<blockquote>
<b>Feature engineering</b> is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.<br> 
- Jason Brownlee    
</blockquote>    
</section>
<section id="some-quotes-on-feature-engineering">
<h3>Some quotes on feature engineering<a class="headerlink" href="#some-quotes-on-feature-engineering" title="Permalink to this headline">#</a></h3>
<p>A quote by Pedro Domingos <a class="reference external" href="https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf">A Few Useful Things to Know About Machine Learning</a></p>
<blockquote>
... At the end of the day, some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used. 
</blockquote>
<p>A quote by Andrew Ng, <a class="reference external" href="https://ai.stanford.edu/~ang/slides/DeepLearning-Mar2013.pptx">Machine Learning and AI via Brain simulations</a></p>
<blockquote>
Coming up with features is difficult, time-consuming, requires expert knowledge. "Applied machine learning" is basically feature engineering.
</blockquote></section>
<section id="better-features-usually-help-more-than-a-better-model">
<h3>Better features usually help more than a better model.<a class="headerlink" href="#better-features-usually-help-more-than-a-better-model" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Good features would ideally:</p>
<ul>
<li><p>capture most important aspects of the problem</p></li>
<li><p>allow learning with few examples</p></li>
<li><p>generalize to new scenarios.</p></li>
</ul>
</li>
<li><p>There is a trade-off between simple and expressive features:</p>
<ul>
<li><p>With simple features overfitting risk is low, but scores might be low.</p></li>
<li><p>With complicated features scores can be high, but so is overfitting risk.</p></li>
</ul>
</li>
</ul>
</section>
<section id="the-best-features-may-be-dependent-on-the-model-you-use">
<h3>The best features may be dependent on the model you use.<a class="headerlink" href="#the-best-features-may-be-dependent-on-the-model-you-use" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Examples:</p>
<ul>
<li><p>For counting-based methods like decision trees separate relevant groups of variable values</p>
<ul>
<li><p>Discretization makes sense</p></li>
</ul>
</li>
<li><p>For distance-based methods like KNN, we want different class labels to be “far”.</p>
<ul>
<li><p>Standardization</p></li>
</ul>
</li>
<li><p>For regression-based methods like linear regression, we want targets to have a linear dependency on features.</p></li>
</ul>
</li>
</ul>
<section id="domain-specific-transformations">
<h4>Domain-specific transformations<a class="headerlink" href="#domain-specific-transformations" title="Permalink to this headline">#</a></h4>
<p>In some domains there are natural transformations to do:</p>
<ul class="simple">
<li><p>Spectrograms (sound data)</p></li>
<li><p>Wavelets (image data)</p></li>
<li><p>Convolutions</p></li>
</ul>
<p><img alt="" src="../_images/spectogram.png" /></p>
<!-- <img src="img/spectogram.png" width="800" height="800"> -->
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Spectrogram">Source</a></p>
<p>In this lecture, I’ll show you an example of feature engineering on text data.</p>
<p><br><br><br><br></p>
</section>
</section>
</section>
<section id="feature-engineering-for-text-data">
<h2>Feature engineering for text data<a class="headerlink" href="#feature-engineering-for-text-data" title="Permalink to this headline">#</a></h2>
<p>We will be using <a class="reference external" href="https://www.kaggle.com/code/kerneler/starter-covid-19-nlp-text-d3a3baa6-e/data">Covid tweets</a> dataset for this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/Corona_NLP_test.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Sentiment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Negative              1041
Positive               947
Neutral                619
Extremely Positive     599
Extremely Negative     592
Name: Sentiment, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UserName</th>
      <th>ScreenName</th>
      <th>Location</th>
      <th>TweetAt</th>
      <th>OriginalTweet</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1927</th>
      <td>1928</td>
      <td>46880</td>
      <td>Seattle, WA</td>
      <td>13-03-2020</td>
      <td>While I don't like all of Amazon's choices, to...</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>1068</th>
      <td>1069</td>
      <td>46021</td>
      <td>NaN</td>
      <td>13-03-2020</td>
      <td>Me: shit buckets, its time to do the weekly s...</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>803</th>
      <td>804</td>
      <td>45756</td>
      <td>The Outer Limits</td>
      <td>12-03-2020</td>
      <td>@SecPompeo @realDonaldTrump You mean the plan ...</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>2846</th>
      <td>2847</td>
      <td>47799</td>
      <td>Flagstaff, AZ</td>
      <td>15-03-2020</td>
      <td>@lauvagrande People who are sick arent panic ...</td>
      <td>Extremely Negative</td>
    </tr>
    <tr>
      <th>3768</th>
      <td>3769</td>
      <td>48721</td>
      <td>Montreal, Canada</td>
      <td>16-03-2020</td>
      <td>Coronavirus Panic: Toilet Paper Is the People...</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1122</th>
      <td>1123</td>
      <td>46075</td>
      <td>NaN</td>
      <td>13-03-2020</td>
      <td>Photos of our local grocery store shelveswher...</td>
      <td>Extremely Positive</td>
    </tr>
    <tr>
      <th>1346</th>
      <td>1347</td>
      <td>46299</td>
      <td>Toronto</td>
      <td>13-03-2020</td>
      <td>Just went to the the grocery store (Highland F...</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>3454</th>
      <td>3455</td>
      <td>48407</td>
      <td>Houston, TX</td>
      <td>16-03-2020</td>
      <td>Real talk though. Am I the only one spending h...</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>3437</th>
      <td>3438</td>
      <td>48390</td>
      <td>Washington, DC</td>
      <td>16-03-2020</td>
      <td>The supermarket business is booming! #COVID2019</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>3582</th>
      <td>3583</td>
      <td>48535</td>
      <td>St James' Park, Newcastle</td>
      <td>16-03-2020</td>
      <td>Evening All Here s the story on the and the im...</td>
      <td>Positive</td>
    </tr>
  </tbody>
</table>
<p>3038 rows × 6 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;UserName&#39;, &#39;ScreenName&#39;, &#39;Location&#39;, &#39;TweetAt&#39;, &#39;OriginalTweet&#39;,
       &#39;Sentiment&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Location&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>United States                     63
London, England                   37
Los Angeles, CA                   30
New York, NY                      29
Washington, DC                    29
                                  ..
Suburb of Chicago                  1
philippines                        1
Dont ask for freedom, take it.     1
Windsor Heights, IA                1
St James&#39; Park, Newcastle          1
Name: Location, Length: 1441, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[[</span><span class="s1">&#39;OriginalTweet&#39;</span><span class="p">,</span> <span class="s1">&#39;Location&#39;</span><span class="p">]],</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Sentiment&#39;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">&#39;OriginalTweet&#39;</span><span class="p">,</span> <span class="s1">&#39;Location&#39;</span><span class="p">]],</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;Sentiment&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Negative              852
Positive              743
Neutral               501
Extremely Negative    472
Extremely Positive    470
Name: Sentiment, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scoring_metrics</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_std_cross_val_scores</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns mean and std of cross validation</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model :</span>
<span class="sd">        scikit-learn model</span>
<span class="sd">    X_train : numpy array or pandas DataFrame</span>
<span class="sd">        X in the training data</span>
<span class="sd">    y_train :</span>
<span class="sd">        y in the training data</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">        pandas Series with mean scores from cross_validation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">mean_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">std_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="n">out_col</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mean_scores</span><span class="p">)):</span>
        <span class="n">out_col</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="sa">f</span><span class="s2">&quot;%0.3f (+/- %0.3f)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean_scores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">std_scores</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">out_col</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">mean_scores</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="dummy-classifier">
<h3>Dummy classifier<a class="headerlink" href="#dummy-classifier" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">()</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;dummy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metrics</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>dummy</th>
      <td>0.001 (+/- 0.000)</td>
      <td>0.000 (+/- 0.000)</td>
      <td>0.280 (+/- 0.001)</td>
      <td>0.280 (+/- 0.000)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="bag-of-words-model">
<h3>Bag-of-words model<a class="headerlink" href="#bag-of-words-model" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">),</span> 
                     <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;logistic regression&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;OriginalTweet&#39;</span><span class="p">],</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metrics</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>dummy</th>
      <td>0.001 (+/- 0.000)</td>
      <td>0.000 (+/- 0.000)</td>
      <td>0.280 (+/- 0.001)</td>
      <td>0.280 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>logistic regression</th>
      <td>0.429 (+/- 0.018)</td>
      <td>0.008 (+/- 0.000)</td>
      <td>0.413 (+/- 0.011)</td>
      <td>0.999 (+/- 0.000)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="is-it-possible-to-further-improve-the-scores">
<h3>Is it possible to further improve the scores?<a class="headerlink" href="#is-it-possible-to-further-improve-the-scores" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>How about adding new features based on our intuitions? Let’s extract our own features that might be useful for this prediction task. In other words, let’s carry out <strong>feature engineering</strong>.</p></li>
<li><p>The code below adds some very basic length-related and sentiment features. We will be using a popular library called <code class="docutils literal notranslate"><span class="pre">nltk</span></code> for this exercise. If you have successfully created the course <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment on your machine, you should already have this package in the environment.</p></li>
</ul>
<ul class="simple">
<li><p>How do we extract interesting information from text?</p></li>
<li><p>We use <strong>pre-trained models</strong>!</p></li>
</ul>
<ul class="simple">
<li><p>A couple of popular libraries which include such pre-trained models.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nltk</span></code></p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">anaconda</span> <span class="n">nltk</span> 
</pre></div>
</div>
<ul class="simple">
<li><p>spaCy</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">spacy</span>
</pre></div>
</div>
<p>For emoji support:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">spacymoji</span>
</pre></div>
</div>
<ul class="simple">
<li><p>You also need to download the language model which contains all the pre-trained models. For that run the following in your course <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment or here.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>

<span class="c1"># !python -m spacy download en_core_web_md</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>

<span class="c1">#nltk.download(&quot;punkt&quot;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;vader_lexicon&quot;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;punkt&quot;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">nltk.sentiment.vader</span> <span class="kn">import</span> <span class="n">SentimentIntensityAnalyzer</span>

<span class="n">sid</span> <span class="o">=</span> <span class="n">SentimentIntensityAnalyzer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package vader_lexicon to
[nltk_data]     /Users/kvarada/nltk_data...
[nltk_data]   Package vader_lexicon is already up-to-date!
[nltk_data] Downloading package punkt to /Users/kvarada/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;CPSC 330 students are smart, sweet, and funny.&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sid</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.368, &#39;pos&#39;: 0.632, &#39;compound&#39;: 0.8225}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;CPSC 330 students are tired because of all the hard work they have been doing.&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sid</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;neg&#39;: 0.249, &#39;neu&#39;: 0.751, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.5106}
</pre></div>
</div>
</div>
</div>
</section>
<section id="spacy">
<h3><a class="reference external" href="https://spacy.io/">spaCy</a><a class="headerlink" href="#spacy" title="Permalink to this headline">#</a></h3>
<p>A useful package for text processing and feature extraction</p>
<ul class="simple">
<li><p>Active development: https://github.com/explosion/spaCy</p></li>
<li><p>Interactive lessons by Ines Montani: https://course.spacy.io/en/</p></li>
<li><p>Good documentation, easy to use, and customizable.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">en_core_web_md</span>  <span class="c1"># pre-trained model</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">en_core_web_md</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Dolly Parton is a gift to us all. </span>
<span class="s2">From writing all-time great songs like “Jolene” and “I Will Always Love You”, </span>
<span class="s2">to great performances in films like 9 to 5, to helping fund a COVID-19 vaccine, </span>
<span class="s2">she’s given us so much. Now, Netflix bring us Dolly Parton’s Christmas on the Square, </span>
<span class="s2">an original musical that stars Christine Baranski as a Scrooge-like landowner </span>
<span class="s2">who threatens to evict an entire town on Christmas Eve to make room for a new mall. </span>
<span class="s2">Directed and choreographed by the legendary Debbie Allen and counting Jennifer Lewis </span>
<span class="s2">and Parton herself amongst its cast, Christmas on the Square seems like the perfect movie</span>
<span class="s2">to save Christmas 2020. 😻 👍🏿&quot;&quot;&quot;</span>

<span class="c1"># [Adapted from here.](https://thepopbreak.com/2020/11/22/dolly-partons-christmas-on-the-square-review-not-quite-a-christmas-miracle/)</span>
</pre></div>
</div>
</div>
</div>
<p>Spacy extracts all interesting information from text with this call.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">sample_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at part-of-speech tags.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">([(</span><span class="n">token</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">pos_</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">][:</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(Dolly, &#39;PROPN&#39;), (Parton, &#39;PROPN&#39;), (is, &#39;AUX&#39;), (a, &#39;DET&#39;), (gift, &#39;NOUN&#39;), (to, &#39;ADP&#39;), (us, &#39;PRON&#39;), (all, &#39;PRON&#39;), (., &#39;PUNCT&#39;), (
, &#39;SPACE&#39;), (From, &#39;ADP&#39;), (writing, &#39;VERB&#39;), (all, &#39;DET&#39;), (-, &#39;PUNCT&#39;), (time, &#39;NOUN&#39;), (great, &#39;ADJ&#39;), (songs, &#39;NOUN&#39;), (like, &#39;ADP&#39;), (“, &#39;PUNCT&#39;), (Jolene, &#39;PROPN&#39;)]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Often we want to know who did what to whom.</p></li>
<li><p><strong>Named entities</strong> give you this information.</p></li>
<li><p>What are named entities in the text?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Named entities:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ORG means: &quot;</span><span class="p">,</span> <span class="n">spacy</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="s2">&quot;ORG&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">PERSON means: &quot;</span><span class="p">,</span> <span class="n">spacy</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="s2">&quot;PERSON&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">DATE means: &quot;</span><span class="p">,</span> <span class="n">spacy</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="s2">&quot;DATE&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Named entities:
 [(&#39;Dolly Parton&#39;, &#39;PERSON&#39;), (&#39;Jolene&#39;, &#39;WORK_OF_ART&#39;), (&#39;I Will Always Love You&#39;, &#39;WORK_OF_ART&#39;), (&#39;9&#39;, &#39;CARDINAL&#39;), (&#39;Netflix&#39;, &#39;ORG&#39;), (&#39;Dolly Parton’s&#39;, &#39;PERSON&#39;), (&#39;Christmas&#39;, &#39;DATE&#39;), (&#39;Square&#39;, &#39;FAC&#39;), (&#39;Christine Baranski&#39;, &#39;PERSON&#39;), (&#39;Christmas Eve&#39;, &#39;DATE&#39;), (&#39;Debbie Allen&#39;, &#39;PERSON&#39;), (&#39;Jennifer Lewis&#39;, &#39;PERSON&#39;), (&#39;Parton&#39;, &#39;PERSON&#39;), (&#39;Christmas&#39;, &#39;DATE&#39;), (&#39;Square&#39;, &#39;FAC&#39;), (&#39;Christmas 2020&#39;, &#39;DATE&#39;), (&#39;😻&#39;, &#39;GPE&#39;)]

ORG means:  Companies, agencies, institutions, etc.

PERSON means:  People, including fictional

DATE means:  Absolute or relative dates or periods
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">spacy</span> <span class="kn">import</span> <span class="n">displacy</span>

<span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;ent&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><span class="tex2jax_ignore"><div class="entities" style="line-height: 2.5; direction: ltr">
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Dolly Parton
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 is a gift to us all. </br>From writing all-time great songs like “
<mark class="entity" style="background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Jolene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">WORK_OF_ART</span>
</mark>
” and “
<mark class="entity" style="background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    I Will Always Love You
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">WORK_OF_ART</span>
</mark>
”, </br>to great performances in films like 
<mark class="entity" style="background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    9
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">CARDINAL</span>
</mark>
 to 5, to helping fund a COVID-19 vaccine, </br>she’s given us so much. Now, 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Netflix
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 bring us 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Dolly Parton’s
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>

<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christmas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
 on the 
<mark class="entity" style="background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Square
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">FAC</span>
</mark>
, </br>an original musical that stars 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christine Baranski
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 as a Scrooge-like landowner </br>who threatens to evict an entire town on 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christmas Eve
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
 to make room for a new mall. </br>Directed and choreographed by the legendary 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Debbie Allen
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 and counting 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Jennifer Lewis
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 </br>and 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Parton
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 herself amongst its cast, 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christmas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
 on the 
<mark class="entity" style="background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Square
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">FAC</span>
</mark>
 seems like the perfect movie</br>to save 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christmas 2020
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
. 
<mark class="entity" style="background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    😻
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">GPE</span>
</mark>
 👍🏿</div></span></div></div>
</div>
</section>
<section id="an-example-from-a-project">
<h3>An example from a project<a class="headerlink" href="#an-example-from-a-project" title="Permalink to this headline">#</a></h3>
<p>Goal: Extract and visualize inter-corporate relationships from disclosed annual 10-K reports of public companies.</p>
<p><a class="reference external" href="https://www.bbc.com/news/business-39875417">Source for the text below.</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;Heavy hitters, including Microsoft and Google, &quot;</span>
    <span class="s2">&quot;are competing for customers in cloud services with the likes of IBM and Salesforce.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;ent&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Named entities:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><span class="tex2jax_ignore"><div class="entities" style="line-height: 2.5; direction: ltr">Heavy hitters, including 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Microsoft
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 and 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Google
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
, are competing for customers in cloud services with the likes of 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    IBM
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 and 
<mark class="entity" style="background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Salesforce
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PRODUCT</span>
</mark>
.</div></span></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Named entities:
 [(&#39;Microsoft&#39;, &#39;ORG&#39;), (&#39;Google&#39;, &#39;ORG&#39;), (&#39;IBM&#39;, &#39;ORG&#39;), (&#39;Salesforce&#39;, &#39;PRODUCT&#39;)]
</pre></div>
</div>
</div>
</div>
<p>If you want emoji identification support install <a class="reference external" href="https://pypi.org/project/spacymoji/"><code class="docutils literal notranslate"><span class="pre">spacymoji</span></code></a> in the course environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">spacymoji</span>
</pre></div>
</div>
<p>After installing <code class="docutils literal notranslate"><span class="pre">spacymoji</span></code>, if it’s still complaining about module not found, my guess is that you do not have <code class="docutils literal notranslate"><span class="pre">pip</span></code> installed in your <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment. Go to your course <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment install <code class="docutils literal notranslate"><span class="pre">pip</span></code> and install the <code class="docutils literal notranslate"><span class="pre">spacymoji</span></code> package in the environment using the <code class="docutils literal notranslate"><span class="pre">pip</span></code> you just installed in the current environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="n">pip</span>
<span class="n">YOUR_MINICONDA_PATH</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">cpsc330</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">pip</span> <span class="n">install</span> <span class="n">spacymoji</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">spacymoji</span> <span class="kn">import</span> <span class="n">Emoji</span>

<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;emoji&quot;</span><span class="p">,</span> <span class="n">first</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Does the text have any emojis? If yes, extract the description.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">sample_text</span><span class="p">)</span>
<span class="n">doc</span><span class="o">.</span><span class="n">_</span><span class="o">.</span><span class="n">emoji</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;😻&#39;, 138, &#39;smiling cat face with heart-eyes&#39;),
 (&#39;👍🏿&#39;, 139, &#39;thumbs up dark skin tone&#39;)]
</pre></div>
</div>
</div>
</div>
<p><br><br><br><br></p>
</section>
</section>
<section id="simple-feature-engineering-for-our-problem">
<h2>Simple feature engineering for our problem.<a class="headerlink" href="#simple-feature-engineering-for-our-problem" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">en_core_web_md</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">en_core_web_md</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">spacymoji</span> <span class="kn">import</span> <span class="n">Emoji</span>

<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;emoji&quot;</span><span class="p">,</span> <span class="n">first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_relative_length</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">TWITTER_ALLOWED_CHARS</span><span class="o">=</span><span class="mf">280.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the relative length of text.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ------</span>
<span class="sd">    text: (str)</span>
<span class="sd">    the input text</span>

<span class="sd">    Keyword arguments:</span>
<span class="sd">    ------</span>
<span class="sd">    TWITTER_ALLOWED_CHARS: (float)</span>
<span class="sd">    the denominator for finding relative length</span>

<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    relative length of text: (float)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">/</span> <span class="n">TWITTER_ALLOWED_CHARS</span>


<span class="k">def</span> <span class="nf">get_length_in_words</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the length of the text in words.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ------</span>
<span class="sd">    text: (str)</span>
<span class="sd">    the input text</span>

<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    length of tokenized text: (int)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_sentiment</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the compound score representing the sentiment: -1 (most extreme negative) and +1 (most extreme positive)</span>
<span class="sd">    The compound score is a normalized score calculated by summing the valence scores of each word in the lexicon.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ------</span>
<span class="sd">    text: (str)</span>
<span class="sd">    the input text</span>

<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    sentiment of the text: (str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">sid</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span><span class="p">[</span><span class="s2">&quot;compound&quot;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">get_avg_word_length</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the average word length of the given text.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    text -- (str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">has_emoji</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the average word length of the given text.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    text -- (str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">doc</span><span class="o">.</span><span class="n">_</span><span class="o">.</span><span class="n">has_emoji</span> <span class="k">else</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">n_words</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_length_in_words</span><span class="p">))</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">vader_sentiment</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_sentiment</span><span class="p">))</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rel_char_len</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_relative_length</span><span class="p">))</span>

<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">n_words</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_length_in_words</span><span class="p">))</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">vader_sentiment</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_sentiment</span><span class="p">))</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rel_char_len</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_relative_length</span><span class="p">))</span>


<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">average_word_length</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_avg_word_length</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">average_word_length</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_avg_word_length</span><span class="p">))</span>

<span class="c1"># whether all letters are uppercase or not (all_caps)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">all_caps</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">all_caps</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">has_emoji</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">has_emoji</span><span class="p">))</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">has_emoji</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">has_emoji</span><span class="p">))</span>

<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UserName</th>
      <th>ScreenName</th>
      <th>Location</th>
      <th>TweetAt</th>
      <th>OriginalTweet</th>
      <th>Sentiment</th>
      <th>n_words</th>
      <th>vader_sentiment</th>
      <th>rel_char_len</th>
      <th>average_word_length</th>
      <th>all_caps</th>
      <th>has_emoji</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1927</th>
      <td>1928</td>
      <td>46880</td>
      <td>Seattle, WA</td>
      <td>13-03-2020</td>
      <td>While I don't like all of Amazon's choices, to...</td>
      <td>Positive</td>
      <td>31</td>
      <td>-0.1053</td>
      <td>0.589286</td>
      <td>5.640000</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1068</th>
      <td>1069</td>
      <td>46021</td>
      <td>NaN</td>
      <td>13-03-2020</td>
      <td>Me: shit buckets, its time to do the weekly s...</td>
      <td>Negative</td>
      <td>52</td>
      <td>-0.2500</td>
      <td>0.932143</td>
      <td>4.636364</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>803</th>
      <td>804</td>
      <td>45756</td>
      <td>The Outer Limits</td>
      <td>12-03-2020</td>
      <td>@SecPompeo @realDonaldTrump You mean the plan ...</td>
      <td>Neutral</td>
      <td>44</td>
      <td>0.0000</td>
      <td>0.910714</td>
      <td>6.741935</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2846</th>
      <td>2847</td>
      <td>47799</td>
      <td>Flagstaff, AZ</td>
      <td>15-03-2020</td>
      <td>@lauvagrande People who are sick arent panic ...</td>
      <td>Extremely Negative</td>
      <td>46</td>
      <td>-0.8481</td>
      <td>0.907143</td>
      <td>5.023810</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3768</th>
      <td>3769</td>
      <td>48721</td>
      <td>Montreal, Canada</td>
      <td>16-03-2020</td>
      <td>Coronavirus Panic: Toilet Paper Is the People...</td>
      <td>Negative</td>
      <td>21</td>
      <td>-0.5106</td>
      <td>0.500000</td>
      <td>9.846154</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3038, 12)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;all_caps&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Sentiment&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numeric_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;vader_sentiment&#39;</span><span class="p">,</span> 
                    <span class="s1">&#39;rel_char_len&#39;</span><span class="p">,</span> 
                    <span class="s1">&#39;average_word_length&#39;</span><span class="p">]</span>
<span class="n">passthrough_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;all_caps&#39;</span><span class="p">,</span> <span class="s1">&#39;has_emoji&#39;</span><span class="p">]</span> 
<span class="n">text_feature</span> <span class="o">=</span> <span class="s1">&#39;OriginalTweet&#39;</span>
<span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;UserName&#39;</span><span class="p">,</span> <span class="s1">&#39;ScreenName&#39;</span><span class="p">,</span> <span class="s1">&#39;Location&#39;</span><span class="p">,</span> <span class="s1">&#39;TweetAt&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">numeric_features</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;passthrough&quot;</span><span class="p">,</span> <span class="n">passthrough_features</span><span class="p">),</span> 
    <span class="p">(</span><span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">),</span> <span class="n">text_feature</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;drop&quot;</span><span class="p">,</span> <span class="n">drop_features</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;LR (more feats)&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metrics</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>dummy</th>
      <td>0.001 (+/- 0.000)</td>
      <td>0.000 (+/- 0.000)</td>
      <td>0.280 (+/- 0.001)</td>
      <td>0.280 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>logistic regression</th>
      <td>0.429 (+/- 0.018)</td>
      <td>0.008 (+/- 0.000)</td>
      <td>0.413 (+/- 0.011)</td>
      <td>0.999 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>LR (more feats)</th>
      <td>0.458 (+/- 0.024)</td>
      <td>0.009 (+/- 0.000)</td>
      <td>0.689 (+/- 0.007)</td>
      <td>0.998 (+/- 0.001)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,
                 ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,
                                                  StandardScaler(),
                                                  [&#x27;vader_sentiment&#x27;,
                                                   &#x27;rel_char_len&#x27;,
                                                   &#x27;average_word_length&#x27;]),
                                                 (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,
                                                  [&#x27;all_caps&#x27;, &#x27;has_emoji&#x27;]),
                                                 (&#x27;countvectorizer&#x27;,
                                                  CountVectorizer(stop_words=&#x27;english&#x27;),
                                                  &#x27;OriginalTweet&#x27;),
                                                 (&#x27;drop&#x27;, &#x27;drop&#x27;,
                                                  [&#x27;UserName&#x27;, &#x27;ScreenName&#x27;,
                                                   &#x27;Location&#x27;, &#x27;TweetAt&#x27;])])),
                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,
                 ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,
                                                  StandardScaler(),
                                                  [&#x27;vader_sentiment&#x27;,
                                                   &#x27;rel_char_len&#x27;,
                                                   &#x27;average_word_length&#x27;]),
                                                 (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,
                                                  [&#x27;all_caps&#x27;, &#x27;has_emoji&#x27;]),
                                                 (&#x27;countvectorizer&#x27;,
                                                  CountVectorizer(stop_words=&#x27;english&#x27;),
                                                  &#x27;OriginalTweet&#x27;),
                                                 (&#x27;drop&#x27;, &#x27;drop&#x27;,
                                                  [&#x27;UserName&#x27;, &#x27;ScreenName&#x27;,
                                                   &#x27;Location&#x27;, &#x27;TweetAt&#x27;])])),
                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">columntransformer: ColumnTransformer</label><div class="sk-toggleable__content"><pre>ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;, StandardScaler(),
                                 [&#x27;vader_sentiment&#x27;, &#x27;rel_char_len&#x27;,
                                  &#x27;average_word_length&#x27;]),
                                (&#x27;passthrough&#x27;, &#x27;passthrough&#x27;,
                                 [&#x27;all_caps&#x27;, &#x27;has_emoji&#x27;]),
                                (&#x27;countvectorizer&#x27;,
                                 CountVectorizer(stop_words=&#x27;english&#x27;),
                                 &#x27;OriginalTweet&#x27;),
                                (&#x27;drop&#x27;, &#x27;drop&#x27;,
                                 [&#x27;UserName&#x27;, &#x27;ScreenName&#x27;, &#x27;Location&#x27;,
                                  &#x27;TweetAt&#x27;])])</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">standardscaler</label><div class="sk-toggleable__content"><pre>[&#x27;vader_sentiment&#x27;, &#x27;rel_char_len&#x27;, &#x27;average_word_length&#x27;]</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" ><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">passthrough</label><div class="sk-toggleable__content"><pre>[&#x27;all_caps&#x27;, &#x27;has_emoji&#x27;]</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" ><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">passthrough</label><div class="sk-toggleable__content"><pre>passthrough</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" ><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">countvectorizer</label><div class="sk-toggleable__content"><pre>OriginalTweet</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" ><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">CountVectorizer</label><div class="sk-toggleable__content"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox" ><label for="sk-estimator-id-9" class="sk-toggleable__label sk-toggleable__label-arrow">drop</label><div class="sk-toggleable__content"><pre>[&#x27;UserName&#x27;, &#x27;ScreenName&#x27;, &#x27;Location&#x27;, &#x27;TweetAt&#x27;]</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox" ><label for="sk-estimator-id-10" class="sk-toggleable__label sk-toggleable__label-arrow">drop</label><div class="sk-toggleable__content"><pre>drop</pre></div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox" ><label for="sk-estimator-id-11" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv_feats</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;columntransformer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">named_transformers_</span><span class="p">[</span><span class="s1">&#39;countvectorizer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/kvarada/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feat_names</span> <span class="o">=</span> <span class="n">numeric_features</span> <span class="o">+</span> <span class="n">passthrough_features</span> <span class="o">+</span> <span class="n">cv_feats</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefs</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;logisticregression&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">feat_names</span><span class="p">,</span>
        <span class="s2">&quot;coefficients&quot;</span><span class="p">:</span> <span class="n">coefs</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;coefficients&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>features</th>
      <th>coefficients</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>vader_sentiment</td>
      <td>-6.141919</td>
    </tr>
    <tr>
      <th>11331</th>
      <td>won</td>
      <td>-1.369740</td>
    </tr>
    <tr>
      <th>2551</th>
      <td>coronapocalypse</td>
      <td>-0.809931</td>
    </tr>
    <tr>
      <th>2214</th>
      <td>closed</td>
      <td>-0.744717</td>
    </tr>
    <tr>
      <th>8661</th>
      <td>retail</td>
      <td>-0.723808</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9862</th>
      <td>stupid</td>
      <td>1.157669</td>
    </tr>
    <tr>
      <th>3299</th>
      <td>don</td>
      <td>1.159067</td>
    </tr>
    <tr>
      <th>4879</th>
      <td>hell</td>
      <td>1.311957</td>
    </tr>
    <tr>
      <th>3129</th>
      <td>die</td>
      <td>1.366538</td>
    </tr>
    <tr>
      <th>7504</th>
      <td>panic</td>
      <td>1.527156</td>
    </tr>
  </tbody>
</table>
<p>11664 rows × 2 columns</p>
</div></div></div>
</div>
<p>We get some improvements with our engineered features!</p>
<p><br><br><br><br></p>
</section>
<section id="common-features-used-in-text-classification">
<h2>Common features used in text classification<a class="headerlink" href="#common-features-used-in-text-classification" title="Permalink to this headline">#</a></h2>
<section id="bag-of-words">
<h3>Bag of words<a class="headerlink" href="#bag-of-words" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>So far for text data we have been using bag of word features.</p></li>
<li><p>They are good enough for many tasks. But …</p></li>
<li><p>This encoding throws out a lot of things we know about language</p></li>
<li><p>It assumes that word order is not that important.</p></li>
<li><p>So if you want to improve the scores further on text classification tasks you carry out <strong>feature engineering</strong>.</p></li>
</ul>
<p>Let’s look at some examples from research papers.</p>
</section>
<section id="example-label-personalized-important-e-mails">
<h3>Example: Label “Personalized” Important E-mails:<a class="headerlink" href="#example-label-personalized-important-e-mails" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36955.pdf">The Learning Behind Gmail Priority Inbox</a></p></li>
<li><p>Features: bag of words, trigrams, regular expressions, and so on.</p></li>
<li><p>There might be some “globally” important messages:</p>
<ul>
<li><p>“This is your mother, something terrible happened, give me a call ASAP.”</p></li>
</ul>
</li>
<li><p>But your “important” message may be unimportant to others.</p>
<ul>
<li><p>Similar for spam: “spam” for one user could be “not spam” for another.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Social features (e.g., percentage of sender emails that is read by the recipient)</p></li>
<li><p>Content features (e.g., recent terms the user has been using in emails)</p></li>
<li><p>Thread features (e.g., whether the user has started the thread)</p></li>
<li><p>…</p></li>
</ul>
</section>
<section id="the-learning-behind-gmail-priority-inbox">
<h3><a class="reference external" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36955.pdf">The Learning Behind Gmail Priority Inbox</a><a class="headerlink" href="#the-learning-behind-gmail-priority-inbox" title="Permalink to this headline">#</a></h3>
<p><img alt="" src="../_images/gmail_priority_inbox.png" /></p>
<!-- <img src="img/gmail_priority_inbox.png" width="1000" height="1000"> --><section id="feature-engineering-examples-automatically-identifying-good-conversations-online">
<h4>Feature engineering examples: <a class="reference external" href="http://www.courtneynapoles.com/res/icwsm17-automatically.pdf">Automatically Identifying Good Conversations Online</a><a class="headerlink" href="#feature-engineering-examples-automatically-identifying-good-conversations-online" title="Permalink to this headline">#</a></h4>
<p><img alt="" src="../_images/classifying_good_conversations_online.png" /></p>
<!-- <img src="img/classifying_good_conversations_online.png" width="800" height="800"> -->
</section>
</section>
<section id="optional-term-weighing-tf-idf">
<h3>(Optional) Term weighing (TF-IDF)<a class="headerlink" href="#optional-term-weighing-tf-idf" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>A measure of relatedness between words and documents</p></li>
<li><p>Intuition: Meaningful words may occur repeatedly in related documents, but functional words (e.g., <em>make</em>, <em>the</em>) may be distributed evenly over all documents</p></li>
</ul>
<div class="math notranslate nohighlight">
\[tf.idf(w_i,d_j) = (1+log(tf_{ij})) log\frac{D}{df_i}\]</div>
<p>where,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(tf_{ij}\)</span> → number of occurrences of the term <span class="math notranslate nohighlight">\(w_i\)</span> in document <span class="math notranslate nohighlight">\(d_j\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(D\)</span> → number of documents</p></li>
<li><p><span class="math notranslate nohighlight">\(df_i\)</span> → number of documents in which <span class="math notranslate nohighlight">\(w_i\)</span> occurs</p></li>
</ul>
<p>Check <code class="docutils literal notranslate"><span class="pre">TfidfVectorizer</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>.</p>
</section>
<section id="n-grams">
<h3>N-grams<a class="headerlink" href="#n-grams" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>Incorporating more context</p></li>
<li><p>A contiguous sequence of <em>n</em> items (characters, tokens) in text.</p>
  <blockquote>
      CPSC330 students are hard-working .
  </blockquote>    
</li>
<li><p>2-grams (bigrams): a contiguous sequence of two words</p>
<ul class="simple">
<li><p><em>CPSC330 students, students are, are hard-working, hard-working .</em></p></li>
</ul>
</li>
<li><p>3-grams (trigrams): a contiguous sequence of three words</p>
<ul class="simple">
<li><p><em>CPSC330 students are, students are hard-working, are hard-working .</em></p></li>
</ul>
</li>
</ul>
<p>You can extract ngram features using <code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code> by passing <code class="docutils literal notranslate"><span class="pre">ngram_range</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;URGENT!! As a valued network customer you have been selected to receive a $900 prize reward!&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Lol you are always so convincing.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;URGENT!! Call right away!!&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">X_counts</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">bow_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_counts</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/kvarada/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>900</th>
      <th>900 prize</th>
      <th>900 prize reward</th>
      <th>always</th>
      <th>always so</th>
      <th>always so convincing</th>
      <th>are</th>
      <th>are always</th>
      <th>are always so</th>
      <th>as</th>
      <th>...</th>
      <th>urgent call</th>
      <th>urgent call right</th>
      <th>valued</th>
      <th>valued network</th>
      <th>valued network customer</th>
      <th>you</th>
      <th>you are</th>
      <th>you are always</th>
      <th>you have</th>
      <th>you have been</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a $900 prize reward!</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing.</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>URGENT!! Call right away!!</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 61 columns</p>
</div></div></div>
</div>
</section>
<section id="aside-google-n-gram-viewer">
<h3>ASIDE: <a class="reference external" href="https://books.google.com/ngrams">Google n-gram viewer</a><a class="headerlink" href="#aside-google-n-gram-viewer" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>All Our N-gram are Belong to You</p>
<ul>
<li><p>https://ai.googleblog.com/2006/08/all-our-n-gram-are-belong-toyou.html</p></li>
</ul>
</li>
</ul>
<blockquote>
Here at Google Research we have been using word n-gram models for a variety
of R&D projects, such as statistical machine translation, speech recognition,
spelling correction, entity detection, information extraction, and others.
That's why we decided to share this enormous dataset with everyone. We
processed 1,024,908,267,229 words of running text and are publishing the
counts for all 1,176,470,663 five-word sequences that appear at least 40
times. There are 13,588,391 unique words, after discarding words that appear
less than 200 times.”
</blockquote><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://books.google.com/ngrams/&quot;</span>
<span class="n">HTML</span><span class="p">(</span><span class="s2">&quot;&lt;iframe src=</span><span class="si">%s</span><span class="s2"> width=1000 height=800&gt;&lt;/iframe&gt;&quot;</span> <span class="o">%</span> <span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/kvarada/opt/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/display.py:419: UserWarning: Consider using IPython.display.IFrame instead
  warnings.warn(&quot;Consider using IPython.display.IFrame instead&quot;)
</pre></div>
</div>
<div class="output text_html"><iframe src=https://books.google.com/ngrams/ width=1000 height=800></iframe></div></div>
</div>
</section>
<section id="id1">
<h3>Aside: <a class="reference external" href="https://books.google.com/ngrams">Google n-gram viewer</a><a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Count the occurrences of the bigram <em>smart women</em> in the corpus from 1800 to 2000</p></li>
</ul>
<p><img alt="" src="../_images/ngram_viewer_smart_woman.png" /></p>
<!-- <img src="img/ngram_viewer_smart_woman.png" width="800" height="800"> --></section>
<section id="id2">
<h3>Aside: <a class="reference external" href="https://books.google.com/ngrams">Google n-gram viewer</a><a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Trends in the word <em>challenge</em> used as a noun vs. verb</p></li>
</ul>
<p><img alt="" src="../_images/ngram_viewer_challenge_NN_VB.png" /></p>
<!-- <img src="img/ngram_viewer_challenge_NN_VB.png" width="800" height="800"> --></section>
<section id="part-of-speech-features">
<h3>Part-of-speech features<a class="headerlink" href="#part-of-speech-features" title="Permalink to this headline">#</a></h3>
<section id="part-of-speech-pos-in-english">
<h4>Part-of-speech (POS) in English<a class="headerlink" href="#part-of-speech-pos-in-english" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Part-of-speech: A kind of syntactic category that tells you some of the grammatical properties of a word.</p>
<ul>
<li><p>Noun → water, sun, cat</p></li>
<li><p>Verb → run, eat, teach</p></li>
</ul>
</li>
</ul>
<blockquote>
The ____ was running. 
</blockquote>    
<ul class="simple">
<li><p>Only a noun fits here.</p></li>
</ul>
</section>
</section>
<section id="part-of-speech-pos-features">
<h3>Part-of-speech (POS) features<a class="headerlink" href="#part-of-speech-pos-features" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>POS features use POS information for the words in text.</p></li>
</ul>
<blockquote>
    CPSC330/<span style="color:green">PROPER_NOUN</span> students/<span style="color:green">NOUN</span> are/<span style="color:green">VERB</span> hard-working/<span style="color:green">ADJECTIVE</span>
</blockquote>    
</section>
<section id="id3">
<h3>An example from a project<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Data: a bunch of documents</p></li>
<li><p>Task: identify texts with <em>permissions</em> and identify who is giving permission to whom.</p></li>
</ul>
<blockquote>
<b>You</b> may <b>disclose</b> Google confidential information when compelled to do so by law if <b>you</b> provide <b>us</b> reasonable prior notice, unless a court orders that <b>we</b> not receive notice.
</blockquote>
<ul class="simple">
<li><p>A very simple solution</p>
<ul>
<li><p>Look for pronouns and verbs.</p></li>
<li><p>Add POS tags as features in your model.</p></li>
<li><p>Maybe look up words similar to <strong>disclose</strong>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="penn-treebank-part-of-speech-tags-bonus">
<h3>Penn Treebank part-of-speech tags (bonus)<a class="headerlink" href="#penn-treebank-part-of-speech-tags-bonus" title="Permalink to this headline">#</a></h3>
<p><img alt="" src="../_images/PTB_POS.png" /></p>
<!-- <img src="img/PTB_POS.png" width="900" height="900"/> --><ul class="simple">
<li><p>You also need to download the language model which contains all the pre-trained models. For that run the following in your course <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment.</p></li>
</ul>
</section>
<section id="interim-summary">
<h3>Interim summary<a class="headerlink" href="#interim-summary" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Feature engineering is finding the useful representation of the data that can help us effectively solve our problem.</p></li>
<li><p>In the context of text data, if we want to go beyond bag-of-words and incorporate human knowledge in models, we carry out feature engineering.</p></li>
<li><p>Some common features include:</p>
<ul>
<li><p>ngram features</p></li>
<li><p>part-of-speech features</p></li>
<li><p>named entity features</p></li>
<li><p>emoticons in text</p></li>
</ul>
</li>
<li><p>These are usually extracted from pre-trained models using libraries such as <code class="docutils literal notranslate"><span class="pre">spaCy</span></code>.</p></li>
<li><p>Now a lot of this has moved to deep learning.</p></li>
<li><p>But many industries still rely on manual feature engineering.</p></li>
</ul>
<p><br><br></p>
</section>
<section id="feature-engineering">
<h3>Feature engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>The best features are application-dependent.</p></li>
<li><p>It’s hard to give general advice. But here are some guidelines.</p>
<ul>
<li><p>Ask the domain experts.</p></li>
<li><p>Go through academic papers in the discipline.</p></li>
<li><p>Often have idea of right discretization/standardization/transformation.</p></li>
<li><p>If no domain expert, cross-validation will help.</p></li>
</ul>
</li>
<li><p>If you have lots of data, use deep learning methods.</p></li>
</ul>
<blockquote>
    The algorithms we used are very standard for Kagglers ... We spent most of our efforts in feature engineering... <br>
- Xavier Conort, on winning the Flight Quest challenge on Kaggle    
</blockquote>    </section>
</section>
<section id="break-5-min">
<h2>Break (5 min)<a class="headerlink" href="#break-5-min" title="Permalink to this headline">#</a></h2>
<p><img alt="" src="../_images/eva-coffee.png" /></p>
<p><br><br><br><br></p>
</section>
<section id="feature-selection-introduction-and-motivation">
<h2>Feature selection: Introduction and motivation<a class="headerlink" href="#feature-selection-introduction-and-motivation" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>With so many ways to add new features, we can increase dimensionality of the data.</p></li>
<li><p>More features means more complex models, which means increasing the chance of overfitting.</p></li>
</ul>
<section id="what-is-feature-selection">
<h3>What is feature selection?<a class="headerlink" href="#what-is-feature-selection" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Find the features	(columns) <span class="math notranslate nohighlight">\(X\)</span> that are important for predicting	<span class="math notranslate nohighlight">\(y\)</span>, and remove the features that aren’t.</p></li>
<li><p>Given <span class="math notranslate nohighlight">\(X = \begin{bmatrix}x_1 &amp; x_2 &amp; \dots &amp; x_n\\  \\  \\  \end{bmatrix}\)</span> and <span class="math notranslate nohighlight">\(y = \begin{bmatrix}\\  \\  \\  \end{bmatrix}\)</span>, find the columns <span class="math notranslate nohighlight">\(1 \leq j \leq n\)</span> in <span class="math notranslate nohighlight">\(X\)</span> that are important for predicting <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
</ul>
</section>
<section id="why-feature-selection">
<h3>Why feature selection?<a class="headerlink" href="#why-feature-selection" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Interpretability: Models are more interpretable with fewer features. If you get the same performance with 10 features instead of 500 features, why not use the model with smaller number of features?</p></li>
<li><p>Computation: Models fit/predict faster with fewer columns.</p></li>
<li><p>Data collection: What type of new data should I collect? It may be cheaper to collect fewer columns.</p></li>
<li><p>Fundamental tradeoff: Can I reduce overfitting by removing useless features?</p></li>
</ul>
<p>Feature selection can often result in better performing (less overfit), easier to understand, and faster model.</p>
</section>
<section id="how-do-we-carry-out-feature-selection">
<h3>How do we carry out feature selection?<a class="headerlink" href="#how-do-we-carry-out-feature-selection" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>There are a number of ways.</p></li>
<li><p>You could use domain knowledge to discard features.</p></li>
<li><p>We are briefly going to look at two automatic feature selection methods from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>:</p>
<ul>
<li><p>Model-based selection</p></li>
<li><p>Recursive feature elimination</p></li>
<li><p>Forward/backward selection</p></li>
</ul>
</li>
<li><p>Very related to looking at feature importances.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>

<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(284, 30)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_all_feats</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">pipe_lr_all_feats</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_lr_all_feats</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.001463
score_time     0.000120
test_score     0.968233
train_score    0.987681
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-based-selection">
<h3>Model-based selection<a class="headerlink" href="#model-based-selection" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Use a supervised machine learning model to judge the importance of each feature.</p></li>
<li><p>Keep only the most important once.</p></li>
<li><p>Supervised machine learning model used for feature selection can be different that the one used as the final estimator.</p></li>
<li><p>Use a model which has some way to calculate feature importances.</p></li>
</ul>
<ul class="simple">
<li><p>To use model-based selection, we use <code class="docutils literal notranslate"><span class="pre">SelectFromModel</span></code> transformer.</p></li>
<li><p>It selects features which have the feature importances greater than the provided threshold.</p></li>
<li><p>Below I’m using <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> for feature selection with threahold “median” of feature importances.</p></li>
<li><p>Approximately how many features will be selected?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectFromModel</span>

<span class="n">select_rf</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> 
    <span class="n">threshold</span><span class="o">=</span><span class="s2">&quot;median&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can put the feature selection transformer in a pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_model_based</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">select_rf</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_lr_model_based</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.055977
score_time     0.004577
test_score     0.950564
train_score    0.974480
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_model_based</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">select_rf</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_lr_model_based</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.053640
score_time     0.004332
test_score     0.950564
train_score    0.974480
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_model_based</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pipe_lr_model_based</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;selectfrommodel&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(284, 15)
</pre></div>
</div>
</div>
</div>
<p>Similar results with only 15 features instead of 30 features.</p>
</section>
<section id="recursive-feature-elimination-rfe">
<h3>Recursive feature elimination (RFE)<a class="headerlink" href="#recursive-feature-elimination-rfe" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Build a series of models</p></li>
<li><p>At each iteration, discard the least important feature according to the model.</p></li>
<li><p>Computationally expensive</p></li>
<li><p>Basic idea</p>
<ul>
<li><p>fit model</p></li>
<li><p>find least important feature</p></li>
<li><p>remove</p></li>
<li><p>iterate.</p></li>
</ul>
</li>
</ul>
</section>
<section id="rfe-algorithm">
<h3>RFE algorithm<a class="headerlink" href="#rfe-algorithm" title="Permalink to this headline">#</a></h3>
<ol class="simple">
<li><p>Decide <span class="math notranslate nohighlight">\(k\)</span>, the number of features to select.</p></li>
<li><p>Assign importances to features, e.g. by fitting a model and looking at <code class="docutils literal notranslate"><span class="pre">coef_</span></code> or <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code>.</p></li>
<li><p>Remove the least important feature.</p></li>
<li><p>Repeat steps 2-3 until only <span class="math notranslate nohighlight">\(k\)</span> features are remaining.</p></li>
</ol>
<p>Note that this is <strong>not</strong> the same as just removing all the less important features in one shot!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>

<span class="c1"># create ranking of features</span>
<span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="n">n_features_to_select</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">rfe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rfe</span><span class="o">.</span><span class="n">ranking_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([16, 12, 19, 13, 23, 20, 10,  1,  9, 22,  2, 25,  5,  7, 15,  4, 26,
       18, 21,  8,  1,  1,  1,  6, 14, 24,  3,  1, 17, 11])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[False False False False False False False  True False False False False
 False False False False False False False False  True  True  True False
 False False False  True False False]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;selected features: &quot;</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>selected features:  [&#39;mean concave points&#39; &#39;worst radius&#39; &#39;worst texture&#39; &#39;worst perimeter&#39;
 &#39;worst concave points&#39;]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>How do we know what value to pass to <code class="docutils literal notranslate"><span class="pre">n_features_to_select</span></code>?</p></li>
</ul>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">RFECV</span></code> which uses cross-validation to select number of features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFECV</span>

<span class="n">rfe_cv</span> <span class="o">=</span> <span class="n">RFECV</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">),</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">rfe_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rfe_cv</span><span class="o">.</span><span class="n">support_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">rfe_cv</span><span class="o">.</span><span class="n">support_</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[False  True False  True False False  True  True  True False  True False
  True  True False  True False False False  True  True  True  True  True
 False False  True  True False  True]
[&#39;mean texture&#39; &#39;mean area&#39; &#39;mean concavity&#39; &#39;mean concave points&#39;
 &#39;mean symmetry&#39; &#39;radius error&#39; &#39;perimeter error&#39; &#39;area error&#39;
 &#39;compactness error&#39; &#39;fractal dimension error&#39; &#39;worst radius&#39;
 &#39;worst texture&#39; &#39;worst perimeter&#39; &#39;worst area&#39; &#39;worst concavity&#39;
 &#39;worst concave points&#39; &#39;worst fractal dimension&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rfe_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">RFECV</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">),</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">rfe_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.360329
score_time     0.002597
test_score     0.943609
train_score    1.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Slow because there is cross validation within cross validation</p></li>
<li><p>Not a big improvement in scores compared to all features on this toy case</p></li>
</ul>
<p><br><br></p>
</section>
<section id="search-and-score">
<h3>Search and score<a class="headerlink" href="#search-and-score" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Define a <strong>scoring function</strong> <span class="math notranslate nohighlight">\(f(S)\)</span> that measures the quality of the set of features <span class="math notranslate nohighlight">\(S\)</span>.</p></li>
<li><p>Now <strong>search</strong> for the set of features <span class="math notranslate nohighlight">\(S\)</span> with the best score.</p></li>
</ul>
</section>
<section id="general-idea-of-search-and-score-methods">
<h3>General idea of search and score methods<a class="headerlink" href="#general-idea-of-search-and-score-methods" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Example: Suppose you have three features: <span class="math notranslate nohighlight">\(A, B, C\)</span></p>
<ul>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{A\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S= \{B\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{C\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{A,B\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{A,C\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{B,C\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{A,B,C\}\)</span></p></li>
</ul>
</li>
<li><p>Return <span class="math notranslate nohighlight">\(S\)</span> with the best score.</p></li>
<li><p>How many distinct combinations we have to try out?</p></li>
</ul>
</section>
<section id="forward-or-backward-selection">
<h3>Forward or backward selection<a class="headerlink" href="#forward-or-backward-selection" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Also called wrapper methods</p></li>
<li><p>Shrink or grow feature set by removing or adding one feature at a time</p></li>
<li><p>Makes the decision based on whether adding/removing the feature improves the CV score or not</p></li>
</ul>
<p><img alt="" src="../_images/forward_selection.png" /></p>
<!-- <img src='img/forward_selection.png' width="1000" height="1000" /> --><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SequentialFeatureSelector</span>

<span class="n">pipe_forward</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">SequentialFeatureSelector</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span> 
                              <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span> 
                              <span class="n">n_features_to_select</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> 
                              <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_forward</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       1.577675
score_time     0.002616
test_score     0.933020
train_score    1.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_forward</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">SequentialFeatureSelector</span><span class="p">(</span>
        <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span> 
                           <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">,</span> 
                           <span class="n">n_features_to_select</span><span class="o">=</span><span class="mi">15</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_forward</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       2.028239
score_time     0.002643
test_score     0.950627
train_score    1.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="other-ways-to-search">
<h3>Other ways to search<a class="headerlink" href="#other-ways-to-search" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Stochastic local search</p>
<ul>
<li><p>Inject randomness so that we can explore new parts of the search space</p></li>
<li><p>Simulated annealing</p></li>
<li><p>Genetic algorithms</p></li>
</ul>
</li>
</ul>
</section>
<section id="warnings-about-feature-selection">
<h3>Warnings about feature selection<a class="headerlink" href="#warnings-about-feature-selection" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>A feature’s relevance is only defined in the context of other features.</p>
<ul>
<li><p>Adding/removing features can make features relevant/irrelevant.</p></li>
</ul>
</li>
<li><p>If features can be predicted from other features, you cannot know which one to pick.</p></li>
<li><p>Relevance for features does not have a causal relationship.</p></li>
<li><p>Don’t be overconfident.</p>
<ul>
<li><p>The methods we have seen probably do not discover the ground truth and how the world really works.</p></li>
<li><p>They simply tell you which features help in predicting <span class="math notranslate nohighlight">\(y_i\)</span> for the data you have.</p></li>
</ul>
</li>
</ul>
</section>
<section id="iclicker-exercise-13-1">
<h3>(iClicker) Exercise 13.1<a class="headerlink" href="#iclicker-exercise-13-1" title="Permalink to this headline">#</a></h3>
<p><strong>iClicker cloud join link: https://join.iclicker.com/3DP5H</strong></p>
<p><strong>Select all of the following statements which are TRUE.</strong></p>
<ul class="simple">
<li><p>(A) Simple association-based feature selection approaches do not take into account the interaction between features.</p></li>
<li><p>(B) You can carry out feature selection using linear models by pruning the features which have very small weights (i.e., coefficients less than a threshold).</p></li>
<li><p>(C) Forward search is guaranteed to find the best feature set.</p></li>
<li><p>(D) The order of features removed given by <code class="docutils literal notranslate"><span class="pre">rfe.ranking_</span></code> is the same as the order of original feature importances given by the model.</p></li>
</ul>
</section>
<section id="optional-problems-with-feature-selection">
<h3>(Optional) Problems with feature selection<a class="headerlink" href="#optional-problems-with-feature-selection" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>The term ‘relevance’ is not clearly defined.</p></li>
<li><p>What all things can go wrong with feature selection?</p></li>
<li><p>Attribution: From CPSC 340.</p></li>
</ul>
<section id="example-is-relevance-clearly-defined">
<h4>Example: Is “Relevance” clearly defined?<a class="headerlink" href="#example-is-relevance-clearly-defined" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Consider a supervised classification task of predicting whether someone has particular genetic variation (SNP)</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/sex_mom_dad.png"><img alt="../_images/sex_mom_dad.png" src="../_images/sex_mom_dad.png" style="width: 600px; height: 600px;" /></a>
<ul class="simple">
<li><p>True model: You almost have the same value as your biological mom.</p></li>
</ul>
</section>
<section id="is-relevance-clearly-defined">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#is-relevance-clearly-defined" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>True model: You almost have the same value for SNP as your biological mom.</p>
<ul>
<li><p>(SNP = biological mom) with very high probability</p></li>
<li><p>(SNP != biological mom) with very low probability</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../_images/SNP.png"><img alt="../_images/SNP.png" src="../_images/SNP.png" style="width: 400px; height: 400px;" /></a>
</section>
<section id="id4">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>What if “mom” feature is repeated?</p></li>
<li><p>Should we pick both? Should we pick one of them because it predicts the other?</p></li>
<li><p>Dependence, collinearity for linear models</p>
<ul>
<li><p>If a feature can be predicted from the other, don’t know which one to pick.</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../_images/sex_mom_mom2_dad.png"><img alt="../_images/sex_mom_mom2_dad.png" src="../_images/sex_mom_mom2_dad.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id5">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>What if we add (maternal) “grandma” feature?</p></li>
<li><p>Is it relevant?</p>
<ul>
<li><p>We can predict SNP accurately using this feature</p></li>
</ul>
</li>
<li><p>Conditional independence</p>
<ul>
<li><p>But grandma is irrelevant given biological mom feature</p></li>
<li><p>Relevant features may become irrelevant given other features</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../_images/sex_mom_dad_grandma.png"><img alt="../_images/sex_mom_dad_grandma.png" src="../_images/sex_mom_dad_grandma.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id6">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id6" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>What if we do not know biological mom feature and we just have grandma feature</p></li>
<li><p>It becomes relevant now.</p>
<ul>
<li><p>Without mom feature this is the best we can do.</p></li>
</ul>
</li>
<li><p>General problem (“taco Tuesday” problem)</p>
<ul>
<li><p>Features can become relevant due to missing information</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../_images/sex_dad_grandma.png"><img alt="../_images/sex_dad_grandma.png" src="../_images/sex_dad_grandma.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id7">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Are there any relevant features now?</p></li>
<li><p>They may have some common maternal ancestor.</p></li>
<li><p>What if mom likes dad because they share SNP?</p></li>
<li><p>General problem (Confounding)</p>
<ul>
<li><p>Hidden features can make irrelevant features relevant.</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../_images/sex_dad.png"><img alt="../_images/sex_dad.png" src="../_images/sex_dad.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id8">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id8" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Now what if we have “sibling” feature?</p></li>
<li><p>The feature is relevant in predicting SNP but not the cause of SNP.</p></li>
<li><p>General problem (non causality)</p>
<ul>
<li><p>the relevant feature may not be causal</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../_images/sex_dad_sibling.png"><img alt="../_images/sex_dad_sibling.png" src="../_images/sex_dad_sibling.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id9">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id9" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>What if you are given “baby” feature?</p></li>
<li><p>Now the sex feature becomes relevant.</p>
<ul>
<li><p>“baby” feature is relevant when sex == F</p></li>
</ul>
</li>
<li><p>General problem (context specific relevance)</p>
<ul>
<li><p>adding a feature can make an irrelevant feature relevant</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../_images/sex_dad_baby.png"><img alt="../_images/sex_dad_baby.png" src="../_images/sex_dad_baby.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id10">
<h4>Warnings about feature selection<a class="headerlink" href="#id10" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>A feature is only relevant in the context of other features.</p>
<ul>
<li><p>Adding/removing features can make features relevant/irrelevant.</p></li>
</ul>
</li>
<li><p>Confounding factors can make irrelevant features the most relevant.</p></li>
<li><p>If features can be predicted from other other features, you cannot know which one to pick.</p></li>
<li><p>Relevance for features does not have a causal relationship.</p></li>
<li><p>Is feature selection completely hopeless?</p>
<ul>
<li><p>It is messy but we still need to do it. So we try to do our best!</p></li>
</ul>
</li>
</ul>
</section>
<section id="general-advice-on-finding-relevant-features">
<h4>General advice on finding relevant features<a class="headerlink" href="#general-advice-on-finding-relevant-features" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Try forward selection.</p></li>
<li><p>Try other feature selection methods (e.g., <code class="docutils literal notranslate"><span class="pre">RFE</span></code>, simulated annealing, genetic algorithms)</p></li>
<li><p>Talk to domain experts; they probably have an idea why certain features are relevant.</p></li>
<li><p>Don’t be overconfident.</p>
<ul>
<li><p>The methods we have seen probably do not discover the ground truth and how the world really works.</p></li>
<li><p>They simply tell you which features help in predicting <span class="math notranslate nohighlight">\(y_i\)</span>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="relevant-resources">
<h4>Relevant resources<a class="headerlink" href="#relevant-resources" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Genome-wide_association_study">Genome-wide association study</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/feature_selection.html">sklearn feature selection</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=ioXKxulmwVQ">PyData: A Practical Guide to Dimensionality Reduction Techniques</a></p></li>
</ul>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-cpsc330-py"
        },
        kernelOptions: {
            kernelName: "conda-env-cpsc330-py",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-cpsc330-py'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="12_feat-importances.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Lecture 12: Feature importances</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../attribution.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Attributions</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Varada Kolhatkar<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>